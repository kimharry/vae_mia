{'async_loading': True,
 'batch_size': 16,
 'cuda': True,
 'dataloader_workers': 4,
 'dataset': 'CIFAR10',
 'experiment_dir': 'VAE_CIFAR10_mse_loss_ld_512',
 'generate_result_split': True,
 'generate_result_total': True,
 'input_shape': {'channels': 3, 'hight': 32, 'width': 32},
 'learning_rate': 0.01,
 'learning_rate_decay': 0.99,
 'loss': 'mse',
 'num_classes': 10,
 'num_epochs': 500,
 'num_split_models': 3,
 'pin_memory': True,
 'resume': True,
 'resume_from': '240322_1.pth.tar',
 'seed': 1,
 'shuffle': True,
 'test_every': 5,
 'to_test_split': True,
 'to_test_total': False,
 'to_train_split': True,
 'to_train_total': False,
 'weight_decay': 0.0005}


Experiment directories created!
Loading Data...
Files already downloaded and verified
Files already downloaded and verified
Data loaded successfully

Loading checkpoint '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/240322_1.pth.tar'
No checkpoint exists from '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/'. Skipping...

Loading checkpoint '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/240322_1.pth.tar'
No checkpoint exists from '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/'. Skipping...

Training...
epoch 0...
epoch 0: - loss: 2546.7364839453126
learning rate: 0.01
testing...
====> Test set loss: 125.6134
epoch 1...
epoch 1: - loss: 2199.8434431640626
learning rate: 0.0099
epoch 2...
epoch 2: - loss: 2147.6503723828123
learning rate: 0.009801
epoch 3...
epoch 3: - loss: 2021.2155255859375
learning rate: 0.00970299
epoch 4...
epoch 4: - loss: 1952.2903717578124
learning rate: 0.0096059601
epoch 5...
epoch 5: - loss: 1910.712646953125
learning rate: 0.009509900499
testing...
====> Test set loss: 103.9807
epoch 6...
epoch 6: - loss: 1873.3049102734376
learning rate: 0.00941480149401
epoch 7...
epoch 7: - loss: 1856.4571343359376
learning rate: 0.0093206534790699
epoch 8...
epoch 8: - loss: 1838.7728285546875
learning rate: 0.0092274469442792
epoch 9...
epoch 9: - loss: 1836.9244619140625
learning rate: 0.009135172474836408
epoch 10...
epoch 10: - loss: 1826.2901115625
learning rate: 0.009043820750088045
testing...
====> Test set loss: 102.8955
epoch 11...
epoch 11: - loss: 1809.9135998046875
learning rate: 0.008953382542587164
epoch 12...
epoch 12: - loss: 1794.9523306640624
learning rate: 0.008863848717161293
epoch 13...
epoch 13: - loss: 1783.3814314453125
learning rate: 0.008775210229989679
epoch 14...
epoch 14: - loss: 1776.5378262109375
learning rate: 0.008687458127689783
epoch 15...
epoch 15: - loss: 1771.4140716015625
learning rate: 0.008600583546412884
testing...
====> Test set loss: 103.6737
epoch 16...
epoch 16: - loss: 1763.499233828125
learning rate: 0.008514577710948755
epoch 17...
epoch 17: - loss: 1757.582260859375
learning rate: 0.008429431933839267
epoch 18...
epoch 18: - loss: 1750.143185859375
learning rate: 0.008345137614500875
epoch 19...
epoch 19: - loss: 1743.15598390625
learning rate: 0.008261686238355867
epoch 20...
epoch 20: - loss: 1735.0427321484376
learning rate: 0.008179069375972308
testing...
====> Test set loss: 103.0253
epoch 21...
epoch 21: - loss: 1731.2189259375
learning rate: 0.008097278682212584
epoch 22...
epoch 22: - loss: 1724.5033152734375
learning rate: 0.00801630589539046
epoch 23...
epoch 23: - loss: 1718.69498140625
learning rate: 0.007936142836436554
epoch 24...
epoch 24: - loss: 1721.728350859375
learning rate: 0.007856781408072187
epoch 25...
epoch 25: - loss: 1717.3745151171875
learning rate: 0.007778213593991467
testing...
====> Test set loss: 103.8441
epoch 26...
epoch 26: - loss: 1712.2058826953125
learning rate: 0.007700431458051551
epoch 27...
epoch 27: - loss: 1712.9244178515626
learning rate: 0.007623427143471036
epoch 28...
epoch 28: - loss: 1711.6742306640624
learning rate: 0.007547192872036326
epoch 29...
epoch 29: - loss: 1713.8632954296875
learning rate: 0.007471720943315961
epoch 30...
epoch 30: - loss: 1708.9669763671875
learning rate: 0.007397003733882802
testing...
====> Test set loss: 103.8666
epoch 31...
epoch 31: - loss: 1713.2142458984374
learning rate: 0.007323033696543975
epoch 32...
epoch 32: - loss: 1706.318107109375
learning rate: 0.007249803359578534
epoch 33...
epoch 33: - loss: 1704.986312109375
learning rate: 0.00717730532598275
epoch 34...
epoch 34: - loss: 1700.7441591015624
learning rate: 0.007105532272722921
epoch 35...
epoch 35: - loss: 1703.1639442578125
learning rate: 0.007034476949995692
testing...
====> Test set loss: 100.5625
epoch 36...
epoch 36: - loss: 1696.6938035546875
learning rate: 0.006964132180495734
epoch 37...
epoch 37: - loss: 1699.361160703125
learning rate: 0.006894490858690777
epoch 38...
epoch 38: - loss: 1697.184238046875
learning rate: 0.006825545950103869
epoch 39...
epoch 39: - loss: 1697.1588617578125
learning rate: 0.006757290490602831
epoch 40...
epoch 40: - loss: 1700.051214296875
learning rate: 0.006689717585696803
testing...
====> Test set loss: 100.1579
epoch 41...
epoch 41: - loss: 1691.12521125
learning rate: 0.0066228204098398346
epoch 42...
epoch 42: - loss: 1693.0724823828125
learning rate: 0.006556592205741436
epoch 43...
epoch 43: - loss: 1688.3659536328125
learning rate: 0.006491026283684022
epoch 44...
epoch 44: - loss: 1692.3242869921876
learning rate: 0.0064261160208471816
epoch 45...
epoch 45: - loss: 1687.489418125
learning rate: 0.00636185486063871
testing...
====> Test set loss: 98.3865
epoch 46...
epoch 46: - loss: 1682.9683570703125
learning rate: 0.006298236312032322
epoch 47...
epoch 47: - loss: 1688.3370939453125
learning rate: 0.006235253948912
epoch 48...
epoch 48: - loss: 1685.7537672265626
learning rate: 0.00617290140942288
epoch 49...
epoch 49: - loss: 1685.481390078125
learning rate: 0.00611117239532865
epoch 50...
epoch 50: - loss: 1680.557221171875
learning rate: 0.006050060671375364
testing...
====> Test set loss: 100.2211
epoch 51...
epoch 51: - loss: 1682.321049921875
learning rate: 0.00598956006466161
epoch 52...
epoch 52: - loss: 1681.9136283984376
learning rate: 0.005929664464014994
epoch 53...
epoch 53: - loss: 1683.068213984375
learning rate: 0.0058703678193748445
epoch 54...
epoch 54: - loss: 1682.0054680859375
learning rate: 0.005811664141181096
epoch 55...
epoch 55: - loss: 1681.3283801953125
learning rate: 0.005753547499769285
testing...
====> Test set loss: 103.7688
epoch 56...
epoch 56: - loss: 1678.6255911328126
learning rate: 0.005696012024771592
epoch 57...
epoch 57: - loss: 1675.607943125
learning rate: 0.005639051904523875
epoch 58...
epoch 58: - loss: 1676.6368541796876
learning rate: 0.005582661385478637
epoch 59...
epoch 59: - loss: 1676.190809609375
learning rate: 0.005526834771623851
epoch 60...
epoch 60: - loss: 1675.3090644921874
learning rate: 0.005471566423907613
testing...
====> Test set loss: 101.2165
epoch 61...
epoch 61: - loss: 1675.6526373828126
learning rate: 0.0054168507596685355
epoch 62...
epoch 62: - loss: 1672.119533203125
learning rate: 0.00536268225207185
epoch 63...
epoch 63: - loss: 1674.2286275
learning rate: 0.005309055429551132
epoch 64...
epoch 64: - loss: 1672.418135859375
learning rate: 0.00525596487525562
epoch 65...
epoch 65: - loss: 1668.356644765625
learning rate: 0.005203405226503064
testing...
====> Test set loss: 98.9043
epoch 66...
epoch 66: - loss: 1669.858018515625
learning rate: 0.005151371174238033
epoch 67...
epoch 67: - loss: 1671.0752708984376
learning rate: 0.005099857462495653
epoch 68...
epoch 68: - loss: 1670.4624355078124
learning rate: 0.005048858887870696
epoch 69...
epoch 69: - loss: 1667.722324296875
learning rate: 0.004998370298991989
epoch 70...
epoch 70: - loss: 1668.0134842578125
learning rate: 0.00494838659600207
testing...
====> Test set loss: 103.0350
epoch 71...
epoch 71: - loss: 1667.5175956640626
learning rate: 0.0048989027300420495
epoch 72...
epoch 72: - loss: 1667.1540584765626
learning rate: 0.004849913702741629
epoch 73...
epoch 73: - loss: 1663.8350473046876
learning rate: 0.004801414565714212
epoch 74...
epoch 74: - loss: 1667.5169
learning rate: 0.0047534004200570695
epoch 75...
epoch 75: - loss: 1664.920265234375
learning rate: 0.004705866415856499
testing...
====> Test set loss: 98.2123
epoch 76...
epoch 76: - loss: 1662.442578125
learning rate: 0.004658807751697934
epoch 77...
epoch 77: - loss: 1663.323010234375
learning rate: 0.004612219674180955
epoch 78...
epoch 78: - loss: 1662.2976065625
learning rate: 0.004566097477439145
epoch 79...
epoch 79: - loss: 1664.1265423046875
learning rate: 0.004520436502664754
epoch 80...
epoch 80: - loss: 1657.568149375
learning rate: 0.004475232137638106
testing...
====> Test set loss: 99.1407
epoch 81...
epoch 81: - loss: 1661.329370234375
learning rate: 0.004430479816261725
epoch 82...
epoch 82: - loss: 1660.2740719140625
learning rate: 0.004386175018099108
epoch 83...
epoch 83: - loss: 1661.3154772265625
learning rate: 0.004342313267918117
epoch 84...
epoch 84: - loss: 1658.4754701171876
learning rate: 0.004298890135238935
epoch 85...
epoch 85: - loss: 1660.81170765625
learning rate: 0.004255901233886546
testing...
====> Test set loss: 99.3191
epoch 86...
epoch 86: - loss: 1656.9542773046876
learning rate: 0.0042133422215476805
epoch 87...
epoch 87: - loss: 1655.77030734375
learning rate: 0.004171208799332204
epoch 88...
epoch 88: - loss: 1656.1712080859375
learning rate: 0.004129496711338882
epoch 89...
epoch 89: - loss: 1653.798902109375
learning rate: 0.0040882017442254925
epoch 90...
epoch 90: - loss: 1655.174482109375
learning rate: 0.0040473197267832375
testing...
====> Test set loss: 100.2049
epoch 91...
epoch 91: - loss: 1656.782387890625
learning rate: 0.004006846529515405
epoch 92...
epoch 92: - loss: 1654.38564984375
learning rate: 0.003966778064220251
epoch 93...
epoch 93: - loss: 1654.728781953125
learning rate: 0.003927110283578048
epoch 94...
epoch 94: - loss: 1652.6346856640625
learning rate: 0.003887839180742268
epoch 95...
epoch 95: - loss: 1649.3618403515625
learning rate: 0.0038489607889348456
testing...
====> Test set loss: 102.2382
epoch 96...
epoch 96: - loss: 1653.351193515625
learning rate: 0.003810471181045497
epoch 97...
epoch 97: - loss: 1652.968131796875
learning rate: 0.003772366469235042
epoch 98...
epoch 98: - loss: 1648.0436968359375
learning rate: 0.003734642804542692
epoch 99...
epoch 99: - loss: 1650.7190126953126
learning rate: 0.0036972963764972644
epoch 100...
epoch 100: - loss: 1651.138806328125
learning rate: 0.003660323412732292
testing...
====> Test set loss: 98.8427
epoch 101...
epoch 101: - loss: 1649.9298873828125
learning rate: 0.003623720178604969
epoch 102...
epoch 102: - loss: 1650.627135703125
learning rate: 0.0035874829768189195
epoch 103...
epoch 103: - loss: 1646.059518828125
learning rate: 0.00355160814705073
epoch 104...
epoch 104: - loss: 1648.1722410546874
learning rate: 0.0035160920655802224
epoch 105...
epoch 105: - loss: 1648.11160390625
learning rate: 0.00348093114492442
testing...
====> Test set loss: 98.6251
epoch 106...
epoch 106: - loss: 1646.83089078125
learning rate: 0.003446121833475176
epoch 107...
epoch 107: - loss: 1645.810945625
learning rate: 0.0034116606151404247
epoch 108...
epoch 108: - loss: 1645.9248226171876
learning rate: 0.00337754400898902
epoch 109...
epoch 109: - loss: 1645.3899835546874
learning rate: 0.0033437685688991296
epoch 110...
epoch 110: - loss: 1646.205771015625
learning rate: 0.0033103308832101385
testing...
====> Test set loss: 98.4513
epoch 111...
epoch 111: - loss: 1646.059800546875
learning rate: 0.003277227574378037
epoch 112...
epoch 112: - loss: 1644.6294040625
learning rate: 0.003244455298634257
epoch 113...
epoch 113: - loss: 1645.8483190234374
learning rate: 0.003212010745647914
epoch 114...
epoch 114: - loss: 1643.2128190234375
learning rate: 0.003179890638191435
epoch 115...
epoch 115: - loss: 1642.517634921875
learning rate: 0.0031480917318095205
testing...
====> Test set loss: 99.0137
epoch 116...
epoch 116: - loss: 1642.9814059375
learning rate: 0.003116610814491425
epoch 117...
epoch 117: - loss: 1644.587965
learning rate: 0.003085444706346511
epoch 118...
epoch 118: - loss: 1641.0560336328124
learning rate: 0.003054590259283046
epoch 119...
epoch 119: - loss: 1643.692217421875
learning rate: 0.0030240443566902156
epoch 120...
epoch 120: - loss: 1642.5701726171876
learning rate: 0.002993803913123313
testing...
====> Test set loss: 100.8399
epoch 121...
epoch 121: - loss: 1639.953761796875
learning rate: 0.0029638658739920797
epoch 122...
epoch 122: - loss: 1638.6923922265626
learning rate: 0.002934227215252159
epoch 123...
epoch 123: - loss: 1640.0243687890625
learning rate: 0.002904884943099638
epoch 124...
epoch 124: - loss: 1640.0552580859376
learning rate: 0.002875836093668641
epoch 125...
epoch 125: - loss: 1639.3728182421876
learning rate: 0.0028470777327319545
testing...
====> Test set loss: 98.4530
epoch 126...
epoch 126: - loss: 1639.108891484375
learning rate: 0.002818606955404635
epoch 127...
epoch 127: - loss: 1639.487172734375
learning rate: 0.0027904208858505887
epoch 128...
epoch 128: - loss: 1636.5141849609374
learning rate: 0.002762516676992083
epoch 129...
epoch 129: - loss: 1635.9461724609375
learning rate: 0.0027348915102221624
epoch 130...
epoch 130: - loss: 1638.03996265625
learning rate: 0.0027075425951199406
testing...
====> Test set loss: 98.9643
epoch 131...
epoch 131: - loss: 1638.6578388671876
learning rate: 0.002680467169168741
epoch 132...
epoch 132: - loss: 1634.4932119921875
learning rate: 0.0026536624974770532
epoch 133...
epoch 133: - loss: 1638.6625573046874
learning rate: 0.0026271258725022828
epoch 134...
epoch 134: - loss: 1634.8225569140625
learning rate: 0.0026008546137772605
epoch 135...
epoch 135: - loss: 1636.9269965234375
learning rate: 0.0025748460676394873
testing...
====> Test set loss: 97.7964
epoch 136...
epoch 136: - loss: 1634.4760773046876
learning rate: 0.002549097606963093
epoch 137...
epoch 137: - loss: 1636.315670859375
learning rate: 0.002523606630893462
epoch 138...
epoch 138: - loss: 1634.3873902734374
learning rate: 0.002498370564584527
epoch 139...
epoch 139: - loss: 1635.2541763671875
learning rate: 0.0024733868589386816
epoch 140...
epoch 140: - loss: 1634.943511953125
learning rate: 0.0024486529903492947
testing...
====> Test set loss: 98.5255
epoch 141...
epoch 141: - loss: 1632.72691125
learning rate: 0.002424166460445802
epoch 142...
epoch 142: - loss: 1632.6418971875
learning rate: 0.002399924795841344
epoch 143...
epoch 143: - loss: 1632.8652973828125
learning rate: 0.0023759255478829305
epoch 144...
epoch 144: - loss: 1631.075205625
learning rate: 0.002352166292404101
epoch 145...
epoch 145: - loss: 1632.3081744921874
learning rate: 0.00232864462948006
testing...
====> Test set loss: 98.7977
epoch 146...
epoch 146: - loss: 1632.9675487890624
learning rate: 0.0023053581831852595
epoch 147...
epoch 147: - loss: 1632.7389757421874
learning rate: 0.002282304601353407
epoch 148...
epoch 148: - loss: 1632.8578923242187
learning rate: 0.002259481555339873
epoch 149...
epoch 149: - loss: 1630.9166985546874
learning rate: 0.002236886739786474
epoch 150...
epoch 150: - loss: 1628.6192929296874
learning rate: 0.0022145178723886093
testing...
====> Test set loss: 98.5214
epoch 151...
epoch 151: - loss: 1633.513396484375
learning rate: 0.002192372693664723
epoch 152...
epoch 152: - loss: 1631.114066875
learning rate: 0.002170448966728076
epoch 153...
epoch 153: - loss: 1630.693019765625
learning rate: 0.002148744477060795
epoch 154...
epoch 154: - loss: 1628.52304984375
learning rate: 0.002127257032290187
epoch 155...
epoch 155: - loss: 1627.399726875
learning rate: 0.002105984461967285
testing...
====> Test set loss: 99.6752
epoch 156...
epoch 156: - loss: 1628.5494726953125
learning rate: 0.0020849246173476124
epoch 157...
epoch 157: - loss: 1631.285287265625
learning rate: 0.002064075371174136
epoch 158...
epoch 158: - loss: 1626.8760771484374
learning rate: 0.002043434617462395
epoch 159...
epoch 159: - loss: 1626.4717480859374
learning rate: 0.002023000271287771
epoch 160...
epoch 160: - loss: 1628.739771640625
learning rate: 0.002002770268574893
testing...
====> Test set loss: 101.2006
epoch 161...
epoch 161: - loss: 1626.8396584765626
learning rate: 0.001982742565889144
epoch 162...
epoch 162: - loss: 1626.702347578125
learning rate: 0.0019629151402302527
epoch 163...
epoch 163: - loss: 1626.6855366796874
learning rate: 0.0019432859888279502
epoch 164...
epoch 164: - loss: 1626.808264375
learning rate: 0.0019238531289396707
epoch 165...
epoch 165: - loss: 1627.99105328125
learning rate: 0.001904614597650274
testing...
====> Test set loss: 98.8553
epoch 166...
epoch 166: - loss: 1624.1551102734375
learning rate: 0.001885568451673771
epoch 167...
epoch 167: - loss: 1627.3507611328125
learning rate: 0.0018667127671570336
epoch 168...
epoch 168: - loss: 1624.5519763085938
learning rate: 0.001848045639485463
epoch 169...
epoch 169: - loss: 1625.3222852734375
learning rate: 0.0018295651830906084
epoch 170...
epoch 170: - loss: 1627.1968537109376
learning rate: 0.0018112695312597024
testing...
====> Test set loss: 98.5546
epoch 171...
epoch 171: - loss: 1624.5144708984376
learning rate: 0.0017931568359471053
epoch 172...
epoch 172: - loss: 1623.2274262890626
learning rate: 0.0017752252675876344
epoch 173...
epoch 173: - loss: 1623.6744664453124
learning rate: 0.0017574730149117579
epoch 174...
epoch 174: - loss: 1621.544781875
learning rate: 0.0017398982847626403
epoch 175...
epoch 175: - loss: 1624.910394453125
learning rate: 0.001722499301915014
testing...
====> Test set loss: 98.7175
epoch 176...
epoch 176: - loss: 1622.21312390625
learning rate: 0.0017052743088958636
epoch 177...
epoch 177: - loss: 1623.027605234375
learning rate: 0.001688221565806905
epoch 178...
epoch 178: - loss: 1622.486982734375
learning rate: 0.0016713393501488361
epoch 179...
epoch 179: - loss: 1623.063156640625
learning rate: 0.0016546259566473476
epoch 180...
epoch 180: - loss: 1620.9143267578124
learning rate: 0.0016380796970808743
testing...
====> Test set loss: 97.6304
epoch 181...
epoch 181: - loss: 1623.339196640625
learning rate: 0.0016216989001100655
epoch 182...
epoch 182: - loss: 1621.3012022070313
learning rate: 0.0016054819111089647
epoch 183...
epoch 183: - loss: 1621.4360562109375
learning rate: 0.001589427091997875
epoch 184...
epoch 184: - loss: 1622.715266171875
learning rate: 0.0015735328210778963
epoch 185...
epoch 185: - loss: 1623.1968730078124
learning rate: 0.0015577974928671174
testing...
====> Test set loss: 98.5666
epoch 186...
epoch 186: - loss: 1618.0638945703124
learning rate: 0.001542219517938446
epoch 187...
epoch 187: - loss: 1621.9778754296874
learning rate: 0.0015267973227590618
epoch 188...
epoch 188: - loss: 1621.39818375
learning rate: 0.001511529349531471
epoch 189...
epoch 189: - loss: 1620.6270923828124
learning rate: 0.0014964140560361563
epoch 190...
epoch 190: - loss: 1620.629753984375
learning rate: 0.0014814499154757947
testing...
====> Test set loss: 97.9664
epoch 191...
epoch 191: - loss: 1621.7534455078126
learning rate: 0.0014666354163210369
epoch 192...
epoch 192: - loss: 1621.629048828125
learning rate: 0.0014519690621578264
epoch 193...
epoch 193: - loss: 1616.8857771875
learning rate: 0.001437449371536248
epoch 194...
epoch 194: - loss: 1617.73819171875
learning rate: 0.0014230748778208857
epoch 195...
epoch 195: - loss: 1620.253278125
learning rate: 0.0014088441290426767
testing...
====> Test set loss: 98.2501
epoch 196...
epoch 196: - loss: 1616.0757074609376
learning rate: 0.00139475568775225
epoch 197...
epoch 197: - loss: 1620.6602470703126
learning rate: 0.0013808081308747276
epoch 198...
epoch 198: - loss: 1617.47295984375
learning rate: 0.0013670000495659802
epoch 199...
epoch 199: - loss: 1617.355722109375
learning rate: 0.0013533300490703203
epoch 200...
epoch 200: - loss: 1616.4261896484375
learning rate: 0.0013397967485796172
testing...
====> Test set loss: 99.0116
epoch 201...
epoch 201: - loss: 1618.08969375
learning rate: 0.001326398781093821
epoch 202...
epoch 202: - loss: 1618.03507640625
learning rate: 0.0013131347932828826
epoch 203...
epoch 203: - loss: 1616.886707265625
learning rate: 0.001300003445350054
epoch 204...
epoch 204: - loss: 1617.0407787890624
learning rate: 0.0012870034108965534
epoch 205...
epoch 205: - loss: 1616.806956484375
learning rate: 0.0012741333767875879
testing...
====> Test set loss: 99.1984
epoch 206...
epoch 206: - loss: 1616.0003291796875
learning rate: 0.0012613920430197118
epoch 207...
epoch 207: - loss: 1616.420880625
learning rate: 0.0012487781225895148
epoch 208...
epoch 208: - loss: 1614.8856698046875
learning rate: 0.0012362903413636196
epoch 209...
epoch 209: - loss: 1615.14316328125
learning rate: 0.0012239274379499834
epoch 210...
epoch 210: - loss: 1615.3461390625
learning rate: 0.0012116881635704836
testing...
====> Test set loss: 98.3993
epoch 211...
epoch 211: - loss: 1613.291184453125
learning rate: 0.0011995712819347787
epoch 212...
epoch 212: - loss: 1615.6236734765625
learning rate: 0.001187575569115431
epoch 213...
epoch 213: - loss: 1614.2077065234375
learning rate: 0.0011756998134242766
epoch 214...
epoch 214: - loss: 1615.17210578125
learning rate: 0.001163942815290034
epoch 215...
epoch 215: - loss: 1615.2947691015625
learning rate: 0.0011523033871371335
testing...
====> Test set loss: 99.1449
epoch 216...
epoch 216: - loss: 1614.389816875
learning rate: 0.001140780353265762
epoch 217...
epoch 217: - loss: 1613.9309882421876
learning rate: 0.0011293725497331045
epoch 218...
epoch 218: - loss: 1613.7945312890624
learning rate: 0.0011180788242357734
epoch 219...
epoch 219: - loss: 1613.74848859375
learning rate: 0.0011068980359934158
epoch 220...
epoch 220: - loss: 1613.771263046875
learning rate: 0.0010958290556334815
testing...
====> Test set loss: 99.1465
epoch 221...
epoch 221: - loss: 1613.0825906640625
learning rate: 0.0010848707650771467
epoch 222...
epoch 222: - loss: 1612.3515974609375
learning rate: 0.0010740220574263753
epoch 223...
epoch 223: - loss: 1613.3990803515626
learning rate: 0.0010632818368521114
epoch 224...
epoch 224: - loss: 1611.759415
learning rate: 0.0010526490184835904
epoch 225...
epoch 225: - loss: 1613.7554510351563
learning rate: 0.0010421225282987545
testing...
====> Test set loss: 97.9620
epoch 226...
epoch 226: - loss: 1612.0624715234376
learning rate: 0.0010317013030157669
epoch 227...
epoch 227: - loss: 1612.870827265625
learning rate: 0.0010213842899856093
epoch 228...
epoch 228: - loss: 1613.6458195703126
learning rate: 0.0010111704470857532
epoch 229...
epoch 229: - loss: 1611.806001953125
learning rate: 0.0010010587426148956
epoch 230...
epoch 230: - loss: 1612.6668991796876
learning rate: 0.0009910481551887466
testing...
====> Test set loss: 97.9981
epoch 231...
epoch 231: - loss: 1613.10470546875
learning rate: 0.0009811376736368592
epoch 232...
epoch 232: - loss: 1608.9149657421874
learning rate: 0.0009713262969004904
epoch 233...
epoch 233: - loss: 1613.3940133203125
learning rate: 0.0009616130339314856
epoch 234...
epoch 234: - loss: 1611.578752578125
learning rate: 0.0009519969035921708
epoch 235...
epoch 235: - loss: 1613.240982421875
learning rate: 0.000942476934556249
testing...
====> Test set loss: 98.2740
epoch 236...
epoch 236: - loss: 1612.0208529296874
learning rate: 0.0009330521652106866
epoch 237...
epoch 237: - loss: 1610.677204140625
learning rate: 0.0009237216435585797
epoch 238...
epoch 238: - loss: 1612.8688221484374
learning rate: 0.0009144844271229938
epoch 239...
epoch 239: - loss: 1612.0749432421876
learning rate: 0.0009053395828517639
epoch 240...
epoch 240: - loss: 1612.2768258984374
learning rate: 0.0008962861870232462
testing...
====> Test set loss: 100.0187
epoch 241...
epoch 241: - loss: 1612.007181484375
learning rate: 0.0008873233251530139
epoch 242...
epoch 242: - loss: 1610.716609765625
learning rate: 0.0008784500919014836
epoch 243...
epoch 243: - loss: 1608.976777109375
learning rate: 0.0008696655909824688
epoch 244...
epoch 244: - loss: 1607.676513359375
learning rate: 0.000860968935072644
epoch 245...
epoch 245: - loss: 1607.3246105078124
learning rate: 0.0008523592457219175
testing...
====> Test set loss: 99.0494
epoch 246...
epoch 246: - loss: 1607.2501123046875
learning rate: 0.0008438356532646984
epoch 247...
epoch 247: - loss: 1606.8895212109376
learning rate: 0.0008353972967320516
epoch 248...
epoch 248: - loss: 1606.8678055859375
learning rate: 0.0008270433237647309
epoch 249...
epoch 249: - loss: 1607.444518359375
learning rate: 0.0008187728905270836
epoch 250...
epoch 250: - loss: 1606.66226671875
learning rate: 0.0008105851616218128
testing...
====> Test set loss: 97.7631
epoch 251...
epoch 251: - loss: 1605.301178125
learning rate: 0.0008024793100055947
epoch 252...
epoch 252: - loss: 1606.66740859375
learning rate: 0.0007944545169055387
epoch 253...
epoch 253: - loss: 1605.682958671875
learning rate: 0.0007865099717364833
epoch 254...
epoch 254: - loss: 1604.3023749609374
learning rate: 0.0007786448720191185
epoch 255...
epoch 255: - loss: 1606.2257503710937
learning rate: 0.0007708584232989273
testing...
====> Test set loss: 98.1626
epoch 256...
epoch 256: - loss: 1604.1153162109374
learning rate: 0.000763149839065938
epoch 257...
epoch 257: - loss: 1606.5877141796875
learning rate: 0.0007555183406752786
epoch 258...
epoch 258: - loss: 1603.98650234375
learning rate: 0.0007479631572685258
epoch 259...
epoch 259: - loss: 1604.7446052734374
learning rate: 0.0007404835256958406
epoch 260...
epoch 260: - loss: 1604.8750778125
learning rate: 0.0007330786904388821
testing...
====> Test set loss: 98.8092
epoch 261...
epoch 261: - loss: 1602.8168164453125
learning rate: 0.0007257479035344933
epoch 262...
epoch 262: - loss: 1603.3609181640625
learning rate: 0.0007184904244991483
epoch 263...
epoch 263: - loss: 1605.10662640625
learning rate: 0.0007113055202541569
epoch 264...
epoch 264: - loss: 1603.4344530078124
learning rate: 0.0007041924650516154
epoch 265...
epoch 265: - loss: 1601.9193640234375
learning rate: 0.0006971505404010992
testing...
====> Test set loss: 98.9049
epoch 266...
epoch 266: - loss: 1603.29338171875
learning rate: 0.0006901790349970881
epoch 267...
epoch 267: - loss: 1603.50185484375
learning rate: 0.0006832772446471172
epoch 268...
epoch 268: - loss: 1602.8426456640625
learning rate: 0.000676444472200646
epoch 269...
epoch 269: - loss: 1603.185028203125
learning rate: 0.0006696800274786397
epoch 270...
epoch 270: - loss: 1600.6681510546875
learning rate: 0.0006629832272038532
testing...
====> Test set loss: 98.9483
epoch 271...
epoch 271: - loss: 1601.93805546875
learning rate: 0.0006563533949318147
epoch 272...
epoch 272: - loss: 1603.3153965625
learning rate: 0.0006497898609824965
epoch 273...
epoch 273: - loss: 1602.2346966796874
learning rate: 0.0006432919623726716
epoch 274...
epoch 274: - loss: 1603.2135340234374
learning rate: 0.0006368590427489448
epoch 275...
epoch 275: - loss: 1600.972745546875
learning rate: 0.0006304904523214554
testing...
====> Test set loss: 97.6720
epoch 276...
epoch 276: - loss: 1601.9285394921876
learning rate: 0.0006241855477982409
epoch 277...
epoch 277: - loss: 1602.534005859375
learning rate: 0.0006179436923202584
epoch 278...
epoch 278: - loss: 1601.092534375
learning rate: 0.0006117642553970558
epoch 279...
epoch 279: - loss: 1600.7838916015626
learning rate: 0.0006056466128430852
epoch 280...
epoch 280: - loss: 1603.262845859375
learning rate: 0.0005995901467146544
testing...
====> Test set loss: 98.3672
epoch 281...
epoch 281: - loss: 1601.690348046875
learning rate: 0.0005935942452475079
epoch 282...
epoch 282: - loss: 1600.68992671875
learning rate: 0.0005876583027950328
epoch 283...
epoch 283: - loss: 1600.8964053125
learning rate: 0.0005817817197670825
epoch 284...
epoch 284: - loss: 1601.1893011328125
learning rate: 0.0005759639025694117
epoch 285...
epoch 285: - loss: 1598.578378359375
learning rate: 0.0005702042635437175
testing...
====> Test set loss: 98.0123
epoch 286...
epoch 286: - loss: 1601.3376948828125
learning rate: 0.0005645022209082803
epoch 287...
epoch 287: - loss: 1598.916341328125
learning rate: 0.0005588571986991975
epoch 288...
epoch 288: - loss: 1599.57912765625
learning rate: 0.0005532686267122054
epoch 289...
epoch 289: - loss: 1598.659021328125
learning rate: 0.0005477359404450834
epoch 290...
epoch 290: - loss: 1598.7934073046874
learning rate: 0.0005422585810406326
testing...
====> Test set loss: 97.6700
epoch 291...
epoch 291: - loss: 1598.7217409765624
learning rate: 0.0005368359952302263
epoch 292...
epoch 292: - loss: 1598.9587840625
learning rate: 0.000531467635277924
epoch 293...
epoch 293: - loss: 1599.70689265625
learning rate: 0.0005261529589251448
epoch 294...
epoch 294: - loss: 1599.9295880859374
learning rate: 0.0005208914293358933
epoch 295...
epoch 295: - loss: 1598.3767503125
learning rate: 0.0005156825150425344
testing...
====> Test set loss: 98.8096
epoch 296...
epoch 296: - loss: 1599.2100337109375
learning rate: 0.000510525689892109
epoch 297...
epoch 297: - loss: 1596.1945398046876
learning rate: 0.000505420432993188
epoch 298...
epoch 298: - loss: 1598.2870394140625
learning rate: 0.000500366228663256
epoch 299...
epoch 299: - loss: 1598.7301052734374
learning rate: 0.0004953625663766235
epoch 300...
epoch 300: - loss: 1596.798831171875
learning rate: 0.0004904089407128572
testing...
====> Test set loss: 98.2221
epoch 301...
epoch 301: - loss: 1598.614470390625
learning rate: 0.0004855048513057287
epoch 302...
epoch 302: - loss: 1598.7949926171875
learning rate: 0.0004806498027926714
epoch 303...
epoch 303: - loss: 1598.579369765625
learning rate: 0.0004758433047647447
epoch 304...
epoch 304: - loss: 1597.8454530859376
learning rate: 0.0004710848717170972
epoch 305...
epoch 305: - loss: 1597.0695462890626
learning rate: 0.0004663740229999262
testing...
====> Test set loss: 98.3321
epoch 306...
epoch 306: - loss: 1596.393451171875
learning rate: 0.000461710282769927
epoch 307...
epoch 307: - loss: 1599.6161874609375
learning rate: 0.00045709317994222767
epoch 308...
epoch 308: - loss: 1597.43071390625
learning rate: 0.0004525222481428054
epoch 309...
epoch 309: - loss: 1600.0538475390624
learning rate: 0.0004479970256613774
epoch 310...
epoch 310: - loss: 1597.787455078125
learning rate: 0.00044351705540476356
testing...
====> Test set loss: 97.4600
epoch 311...
epoch 311: - loss: 1595.6956202734375
learning rate: 0.00043908188485071594
epoch 312...
epoch 312: - loss: 1596.3223087890624
learning rate: 0.00043469106600220876
epoch 313...
epoch 313: - loss: 1596.1170103515626
learning rate: 0.0004303441553421867
epoch 314...
epoch 314: - loss: 1597.0398890234376
learning rate: 0.0004260407137887648
epoch 315...
epoch 315: - loss: 1595.780790703125
learning rate: 0.0004217803066508771
testing...
====> Test set loss: 97.7466
epoch 316...
epoch 316: - loss: 1598.5695428515626
learning rate: 0.0004175625035843684
epoch 317...
epoch 317: - loss: 1595.13188796875
learning rate: 0.00041338687854852474
epoch 318...
epoch 318: - loss: 1596.0706267578125
learning rate: 0.00040925300976303944
epoch 319...
epoch 319: - loss: 1596.855907421875
learning rate: 0.000405160479665409
epoch 320...
epoch 320: - loss: 1595.7083344726564
learning rate: 0.000401108874868755
testing...
====> Test set loss: 97.8139
epoch 321...
epoch 321: - loss: 1596.130537734375
learning rate: 0.0003970977861200674
epoch 322...
epoch 322: - loss: 1594.731258203125
learning rate: 0.0003931268082588667
epoch 323...
epoch 323: - loss: 1595.706301640625
learning rate: 0.00038919554017627806
epoch 324...
epoch 324: - loss: 1596.1933791015624
learning rate: 0.00038530358477451525
epoch 325...
epoch 325: - loss: 1595.7009737109374
learning rate: 0.0003814505489267701
testing...
====> Test set loss: 99.2153
epoch 326...
epoch 326: - loss: 1595.2689075
learning rate: 0.00037763604343750244
epoch 327...
epoch 327: - loss: 1594.822967734375
learning rate: 0.0003738596830031274
epoch 328...
epoch 328: - loss: 1594.152738203125
learning rate: 0.0003701210861730961
epoch 329...
epoch 329: - loss: 1593.511669375
learning rate: 0.0003664198753113651
epoch 330...
epoch 330: - loss: 1595.2024315625
learning rate: 0.00036275567655825146
testing...
====> Test set loss: 98.0978
epoch 331...
epoch 331: - loss: 1594.09367796875
learning rate: 0.000359128119792669
epoch 332...
epoch 332: - loss: 1594.2695750585938
learning rate: 0.00035553683859474225
epoch 333...
epoch 333: - loss: 1594.992741171875
learning rate: 0.0003519814702087949
epoch 334...
epoch 334: - loss: 1595.5133215234375
learning rate: 0.0003484616555067069
epoch 335...
epoch 335: - loss: 1595.28625078125
learning rate: 0.0003449770389516398
testing...
====> Test set loss: 99.0501
epoch 336...
epoch 336: - loss: 1593.6049209765624
learning rate: 0.0003415272685621234
epoch 337...
epoch 337: - loss: 1595.249920390625
learning rate: 0.0003381119958765022
epoch 338...
epoch 338: - loss: 1596.4273744140626
learning rate: 0.0003347308759177372
epoch 339...
epoch 339: - loss: 1594.36953140625
learning rate: 0.0003313835671585598
epoch 340...
epoch 340: - loss: 1594.5130355078124
learning rate: 0.0003280697314869742
testing...
====> Test set loss: 98.3544
epoch 341...
epoch 341: - loss: 1594.484834140625
learning rate: 0.00032478903417210446
epoch 342...
epoch 342: - loss: 1593.110869453125
learning rate: 0.0003215411438303834
epoch 343...
epoch 343: - loss: 1591.69686640625
learning rate: 0.00031832573239207955
epoch 344...
epoch 344: - loss: 1592.8813937890625
learning rate: 0.0003151424750681588
epoch 345...
epoch 345: - loss: 1593.1921075
learning rate: 0.0003119910503174772
testing...
====> Test set loss: 97.9365
epoch 346...
epoch 346: - loss: 1591.9818952734374
learning rate: 0.0003088711398143024
epoch 347...
epoch 347: - loss: 1591.809723046875
learning rate: 0.00030578242841615937
epoch 348...
epoch 348: - loss: 1593.0214698046875
learning rate: 0.0003027246041319978
epoch 349...
epoch 349: - loss: 1591.7102427734376
learning rate: 0.0002996973580906778
epoch 350...
epoch 350: - loss: 1594.79210515625
learning rate: 0.00029670038450977103
testing...
====> Test set loss: 98.4374
epoch 351...
epoch 351: - loss: 1593.15533765625
learning rate: 0.0002937333806646733
epoch 352...
epoch 352: - loss: 1591.9743090625
learning rate: 0.0002907960468580266
epoch 353...
epoch 353: - loss: 1592.8296490234375
learning rate: 0.0002878880863894463
epoch 354...
epoch 354: - loss: 1592.0891030078126
learning rate: 0.00028500920552555184
epoch 355...
epoch 355: - loss: 1590.878950625
learning rate: 0.0002821591134702963
testing...
====> Test set loss: 97.9720
epoch 356...
epoch 356: - loss: 1592.4739076953124
learning rate: 0.00027933752233559334
epoch 357...
epoch 357: - loss: 1591.6122268359375
learning rate: 0.0002765441471122374
epoch 358...
epoch 358: - loss: 1590.97117078125
learning rate: 0.00027377870564111506
epoch 359...
epoch 359: - loss: 1591.8697213671876
learning rate: 0.0002710409185847039
epoch 360...
epoch 360: - loss: 1592.7710473046875
learning rate: 0.00026833050939885686
testing...
====> Test set loss: 99.4740
epoch 361...
epoch 361: - loss: 1593.6831758203125
learning rate: 0.00026564720430486826
epoch 362...
epoch 362: - loss: 1591.820692890625
learning rate: 0.0002629907322618196
epoch 363...
epoch 363: - loss: 1592.26010140625
learning rate: 0.0002603608249392014
epoch 364...
epoch 364: - loss: 1592.3735067578125
learning rate: 0.00025775721668980933
epoch 365...
epoch 365: - loss: 1592.4929075
learning rate: 0.00025517964452291124
testing...
====> Test set loss: 98.3930
epoch 366...
epoch 366: - loss: 1593.1745842578125
learning rate: 0.00025262784807768214
epoch 367...
epoch 367: - loss: 1591.2222036328126
learning rate: 0.00025010156959690536
epoch 368...
epoch 368: - loss: 1590.358138515625
learning rate: 0.0002476005539009363
epoch 369...
epoch 369: - loss: 1591.97116546875
learning rate: 0.00024512454836192693
epoch 370...
epoch 370: - loss: 1589.6178437109374
learning rate: 0.00024267330287830764
testing...
====> Test set loss: 98.0871
epoch 371...
epoch 371: - loss: 1589.4589845703124
learning rate: 0.00024024656984952456
epoch 372...
epoch 372: - loss: 1591.9848630859376
learning rate: 0.0002378441041510293
epoch 373...
epoch 373: - loss: 1590.2527807421875
learning rate: 0.000235465663109519
epoch 374...
epoch 374: - loss: 1588.5495684765624
learning rate: 0.00023311100647842382
epoch 375...
epoch 375: - loss: 1592.2440696875
learning rate: 0.0002307798964136396
testing...
====> Test set loss: 98.0756
epoch 376...
epoch 376: - loss: 1590.5173340625
learning rate: 0.00022847209744950318
epoch 377...
epoch 377: - loss: 1591.0818751171876
learning rate: 0.00022618737647500813
epoch 378...
epoch 378: - loss: 1592.5626003515624
learning rate: 0.00022392550271025806
epoch 379...
epoch 379: - loss: 1590.63645109375
learning rate: 0.00022168624768315547
epoch 380...
epoch 380: - loss: 1591.1620977734376
learning rate: 0.00021946938520632395
testing...
====> Test set loss: 97.2982
epoch 381...
epoch 381: - loss: 1589.3211799023438
learning rate: 0.0002172746913542607
epoch 382...
epoch 382: - loss: 1590.5640053125
learning rate: 0.00021510194444071808
epoch 383...
epoch 383: - loss: 1588.9653055859376
learning rate: 0.00021295092499631088
epoch 384...
epoch 384: - loss: 1590.357169609375
learning rate: 0.0002108214157463478
epoch 385...
epoch 385: - loss: 1590.820938125
learning rate: 0.0002087132015888843
testing...
====> Test set loss: 99.5121
epoch 386...
epoch 386: - loss: 1589.5395496875
learning rate: 0.00020662606957299546
epoch 387...
epoch 387: - loss: 1590.4750694140625
learning rate: 0.0002045598088772655
epoch 388...
epoch 388: - loss: 1588.628968671875
learning rate: 0.00020251421078849283
epoch 389...
epoch 389: - loss: 1589.517439609375
learning rate: 0.00020048906868060792
epoch 390...
epoch 390: - loss: 1590.58015109375
learning rate: 0.00019848417799380185
testing...
====> Test set loss: 97.9754
epoch 391...
epoch 391: - loss: 1591.1636391015625
learning rate: 0.00019649933621386381
epoch 392...
epoch 392: - loss: 1590.098653203125
learning rate: 0.00019453434285172518
epoch 393...
epoch 393: - loss: 1588.14132828125
learning rate: 0.0001925889994232079
epoch 394...
epoch 394: - loss: 1588.9494823046875
learning rate: 0.00019066310942897582
epoch 395...
epoch 395: - loss: 1588.3077871875
learning rate: 0.0001887564783346861
testing...
====> Test set loss: 98.6299
epoch 396...
epoch 396: - loss: 1589.733306484375
learning rate: 0.00018686891355133923
epoch 397...
epoch 397: - loss: 1588.173008046875
learning rate: 0.00018500022441582582
epoch 398...
epoch 398: - loss: 1588.572952421875
learning rate: 0.00018315022217166757
epoch 399...
epoch 399: - loss: 1590.0217319140625
learning rate: 0.00018131871994995087
epoch 400...
epoch 400: - loss: 1588.13526328125
learning rate: 0.00017950553275045136
testing...
====> Test set loss: 98.2331
epoch 401...
epoch 401: - loss: 1590.2265880664063
learning rate: 0.00017771047742294686
epoch 402...
epoch 402: - loss: 1586.7350590234375
learning rate: 0.0001759333726487174
epoch 403...
epoch 403: - loss: 1587.7124087890625
learning rate: 0.00017417403892223024
epoch 404...
epoch 404: - loss: 1587.9062163671874
learning rate: 0.0001724322985330079
epoch 405...
epoch 405: - loss: 1588.957020625
learning rate: 0.00017070797554767783
testing...
====> Test set loss: 98.4479
epoch 406...
epoch 406: - loss: 1587.8717285546875
learning rate: 0.00016900089579220107
epoch 407...
epoch 407: - loss: 1589.8416508203125
learning rate: 0.00016731088683427902
epoch 408...
epoch 408: - loss: 1587.44090375
learning rate: 0.00016563777796593627
epoch 409...
epoch 409: - loss: 1589.48628765625
learning rate: 0.00016398140018627689
epoch 410...
epoch 410: - loss: 1588.5723147265626
learning rate: 0.00016234158618441412
testing...
====> Test set loss: 97.9243
epoch 411...
epoch 411: - loss: 1588.47860921875
learning rate: 0.00016071817032256997
epoch 412...
epoch 412: - loss: 1589.156972734375
learning rate: 0.00015911098861934425
epoch 413...
epoch 413: - loss: 1588.3318297265625
learning rate: 0.0001575198787331508
epoch 414...
epoch 414: - loss: 1588.67982421875
learning rate: 0.00015594467994581933
epoch 415...
epoch 415: - loss: 1586.974556875
learning rate: 0.00015438523314636112
testing...
====> Test set loss: 97.7457
epoch 416...
epoch 416: - loss: 1587.9038359375
learning rate: 0.00015284138081489752
epoch 417...
epoch 417: - loss: 1587.431992578125
learning rate: 0.00015131296700674854
epoch 418...
epoch 418: - loss: 1588.865408046875
learning rate: 0.00014979983733668105
epoch 419...
epoch 419: - loss: 1586.8485296679687
learning rate: 0.00014830183896331423
epoch 420...
epoch 420: - loss: 1587.809015234375
learning rate: 0.00014681882057368108
testing...
====> Test set loss: 97.5672
epoch 421...
epoch 421: - loss: 1586.6020253515626
learning rate: 0.00014535063236794426
epoch 422...
epoch 422: - loss: 1587.58627828125
learning rate: 0.00014389712604426485
epoch 423...
epoch 423: - loss: 1588.42424828125
learning rate: 0.0001424581547838222
epoch 424...
epoch 424: - loss: 1587.179023125
learning rate: 0.00014103357323598398
epoch 425...
epoch 425: - loss: 1587.7784694140626
learning rate: 0.00013962323750362412
testing...
====> Test set loss: 98.0673
epoch 426...
epoch 426: - loss: 1588.695720390625
learning rate: 0.00013822700512858787
epoch 427...
epoch 427: - loss: 1586.9531544921874
learning rate: 0.00013684473507730199
epoch 428...
epoch 428: - loss: 1587.0631182421876
learning rate: 0.00013547628772652898
epoch 429...
epoch 429: - loss: 1587.4519005078125
learning rate: 0.0001341215248492637
epoch 430...
epoch 430: - loss: 1587.8221013671875
learning rate: 0.00013278030960077106
testing...
====> Test set loss: 98.2533
epoch 431...
epoch 431: - loss: 1586.532885625
learning rate: 0.00013145250650476334
epoch 432...
epoch 432: - loss: 1587.3803919921875
learning rate: 0.00013013798143971572
epoch 433...
epoch 433: - loss: 1587.6557065625
learning rate: 0.00012883660162531853
epoch 434...
epoch 434: - loss: 1588.220762421875
learning rate: 0.00012754823560906536
epoch 435...
epoch 435: - loss: 1588.0606503515626
learning rate: 0.0001262727532529747
testing...
====> Test set loss: 97.6687
epoch 436...
epoch 436: - loss: 1586.2496127734375
learning rate: 0.00012501002572044495
epoch 437...
epoch 437: - loss: 1587.3901518359376
learning rate: 0.0001237599254632405
epoch 438...
epoch 438: - loss: 1587.752750546875
learning rate: 0.0001225223262086081
epoch 439...
epoch 439: - loss: 1587.685793984375
learning rate: 0.00012129710294652202
epoch 440...
epoch 440: - loss: 1587.5357467578126
learning rate: 0.0001200841319170568
testing...
====> Test set loss: 98.1518
epoch 441...
epoch 441: - loss: 1588.03644828125
learning rate: 0.00011888329059788622
epoch 442...
epoch 442: - loss: 1587.1685249609375
learning rate: 0.00011769445769190735
epoch 443...
epoch 443: - loss: 1587.5044712109375
learning rate: 0.00011651751311498829
epoch 444...
epoch 444: - loss: 1588.0177478125
learning rate: 0.0001153523379838384
epoch 445...
epoch 445: - loss: 1585.8183585546874
learning rate: 0.00011419881460400001
testing...
====> Test set loss: 97.7745
epoch 446...
epoch 446: - loss: 1587.3298316015625
learning rate: 0.00011305682645796001
epoch 447...
epoch 447: - loss: 1584.5656382421876
learning rate: 0.00011192625819338041
epoch 448...
epoch 448: - loss: 1587.3712321484375
learning rate: 0.00011080699561144662
epoch 449...
epoch 449: - loss: 1585.3199033984374
learning rate: 0.00010969892565533215
epoch 450...
epoch 450: - loss: 1585.9846686328126
learning rate: 0.00010860193639877883
testing...
====> Test set loss: 97.6938
epoch 451...
epoch 451: - loss: 1587.6386652734375
learning rate: 0.00010751591703479103
epoch 452...
epoch 452: - loss: 1586.64343765625
learning rate: 0.00010644075786444312
epoch 453...
epoch 453: - loss: 1584.6146754296874
learning rate: 0.0001053763502857987
epoch 454...
epoch 454: - loss: 1583.308229375
learning rate: 0.0001043225867829407
epoch 455...
epoch 455: - loss: 1583.73765765625
learning rate: 0.0001032793609151113
testing...
====> Test set loss: 97.8086
epoch 456...
epoch 456: - loss: 1587.2505996484374
learning rate: 0.00010224656730596018
epoch 457...
epoch 457: - loss: 1584.14993140625
learning rate: 0.00010122410163290057
epoch 458...
epoch 458: - loss: 1588.006967734375
learning rate: 0.00010021186061657157
epoch 459...
epoch 459: - loss: 1585.59404609375
learning rate: 9.920974201040587e-05
epoch 460...
epoch 460: - loss: 1588.016269140625
learning rate: 9.821764459030179e-05
testing...
====> Test set loss: 98.0157
epoch 461...
epoch 461: - loss: 1583.5150864453126
learning rate: 9.723546814439878e-05
epoch 462...
epoch 462: - loss: 1584.7648771875
learning rate: 9.62631134629548e-05
epoch 463...
epoch 463: - loss: 1585.2217841015624
learning rate: 9.530048232832524e-05
epoch 464...
epoch 464: - loss: 1585.083783359375
learning rate: 9.434747750504199e-05
epoch 465...
epoch 465: - loss: 1585.534183125
learning rate: 9.340400272999157e-05
testing...
====> Test set loss: 97.9837
epoch 466...
epoch 466: - loss: 1585.461422890625
learning rate: 9.246996270269165e-05
epoch 467...
epoch 467: - loss: 1584.1740001171875
learning rate: 9.154526307566473e-05
epoch 468...
epoch 468: - loss: 1584.71349765625
learning rate: 9.062981044490809e-05
epoch 469...
epoch 469: - loss: 1586.1464934765625
learning rate: 8.9723512340459e-05
epoch 470...
epoch 470: - loss: 1586.1205456640625
learning rate: 8.882627721705441e-05
testing...
====> Test set loss: 98.4989
epoch 471...
epoch 471: - loss: 1584.2374877734376
learning rate: 8.793801444488386e-05
epoch 472...
epoch 472: - loss: 1585.551850703125
learning rate: 8.705863430043502e-05
epoch 473...
epoch 473: - loss: 1586.4898446484376
learning rate: 8.618804795743068e-05
epoch 474...
epoch 474: - loss: 1586.613286171875
learning rate: 8.532616747785637e-05
epoch 475...
epoch 475: - loss: 1584.420101953125
learning rate: 8.447290580307781e-05
testing...
====> Test set loss: 97.8917
epoch 476...
epoch 476: - loss: 1584.3508039453125
learning rate: 8.362817674504702e-05
epoch 477...
epoch 477: - loss: 1582.6840006640625
learning rate: 8.279189497759656e-05
epoch 478...
epoch 478: - loss: 1584.348463125
learning rate: 8.196397602782058e-05
epoch 479...
epoch 479: - loss: 1583.4715255859376
learning rate: 8.114433626754238e-05
epoch 480...
epoch 480: - loss: 1583.9345877734374
learning rate: 8.033289290486696e-05
testing...
====> Test set loss: 97.8260
epoch 481...
epoch 481: - loss: 1585.24859640625
learning rate: 7.95295639758183e-05
epoch 482...
epoch 482: - loss: 1583.64347640625
learning rate: 7.87342683360601e-05
epoch 483...
epoch 483: - loss: 1585.4329909765625
learning rate: 7.79469256526995e-05
epoch 484...
epoch 484: - loss: 1585.8046251171875
learning rate: 7.716745639617251e-05
epoch 485...
epoch 485: - loss: 1584.2224323046876
learning rate: 7.639578183221078e-05
testing...
====> Test set loss: 98.8525
epoch 486...
epoch 486: - loss: 1584.4165586328124
learning rate: 7.563182401388867e-05
epoch 487...
epoch 487: - loss: 1585.2706218359374
learning rate: 7.487550577374979e-05
epoch 488...
epoch 488: - loss: 1586.1931599609375
learning rate: 7.412675071601228e-05
epoch 489...
epoch 489: - loss: 1583.5582235546874
learning rate: 7.338548320885217e-05
epoch 490...
epoch 490: - loss: 1582.6046897265626
learning rate: 7.265162837676363e-05
testing...
====> Test set loss: 97.9620
epoch 491...
epoch 491: - loss: 1583.6869879296876
learning rate: 7.1925112092996e-05
epoch 492...
epoch 492: - loss: 1583.0427882421875
learning rate: 7.120586097206604e-05
epoch 493...
epoch 493: - loss: 1582.6856890234376
learning rate: 7.049380236234538e-05
epoch 494...
epoch 494: - loss: 1584.742696015625
learning rate: 6.978886433872192e-05
epoch 495...
epoch 495: - loss: 1582.781670390625
learning rate: 6.90909756953347e-05
testing...
====> Test set loss: 98.0112
epoch 496...
epoch 496: - loss: 1583.805249140625
learning rate: 6.840006593838136e-05
epoch 497...
epoch 497: - loss: 1582.204300859375
learning rate: 6.771606527899755e-05
epoch 498...
epoch 498: - loss: 1583.5045799609375
learning rate: 6.703890462620757e-05
epoch 499...
epoch 499: - loss: 1585.062074453125
learning rate: 6.636851557994549e-05
Training Finished

Testing on training data...
testing...
====> Test on training set loss: 467.4073
Testing Finished

