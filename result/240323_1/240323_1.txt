{'__learning_rate_decay': 0.99,
 'async_loading': True,
 'batch_size': 64,
 'cuda': True,
 'dataloader_workers': 4,
 'dataset': 'CIFAR10',
 'experiment_dir': 'VAE_CIFAR10_mse_loss_ld_512',
 'gamma': 0.1,
 'generate_result_split': True,
 'generate_result_total': False,
 'input_shape': {'channels': 3, 'hight': 32, 'width': 32},
 'learning_rate': 0.01,
 'learning_rate_decay_epochs': [50, 100, 150],
 'loss': 'mse',
 'num_classes': 10,
 'num_epochs': 300,
 'num_split_models': 3,
 'pin_memory': True,
 'resume': True,
 'resume_from': '240323_1',
 'seed': 1,
 'shuffle': True,
 'test_every': 5,
 'to_test_split': True,
 'to_test_total': False,
 'to_train_split': True,
 'to_train_total': False,
 'weight_decay': 0.0005}


Experiment directories created!
Loading Data...
Files already downloaded and verified
Files already downloaded and verified
Data loaded successfully

Loading checkpoint '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/240323_1_total.pth.tar'
No checkpoint exists from '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/'. Skipping...

Loading checkpoint '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/240323_1_split.pth.tar'
No checkpoint exists from '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/'. Skipping...

Training...
epoch 0...
epoch 0: - loss: 11115.639661549912
learning rate: 0.01
testing...
====> Test set loss: 139.1099
epoch 1...
epoch 1: - loss: 8532.995227394202
learning rate: 0.01
epoch 2...
epoch 2: - loss: 8110.471988141384
learning rate: 0.01
epoch 3...
epoch 3: - loss: 7612.961368024196
learning rate: 0.01
epoch 4...
epoch 4: - loss: 7359.385608565777
learning rate: 0.01
epoch 5...
epoch 5: - loss: 7078.785939872722
learning rate: 0.01
testing...
====> Test set loss: 108.5663
epoch 6...
epoch 6: - loss: 6928.842752832281
learning rate: 0.01
epoch 7...
epoch 7: - loss: 6799.209983728121
learning rate: 0.01
epoch 8...
epoch 8: - loss: 6710.746145263048
learning rate: 0.01
epoch 9...
epoch 9: - loss: 6656.0501301563
learning rate: 0.01
epoch 10...
epoch 10: - loss: 6619.632752245345
learning rate: 0.01
testing...
====> Test set loss: 95.7705
epoch 11...
epoch 11: - loss: 6554.941989440137
learning rate: 0.01
epoch 12...
epoch 12: - loss: 6525.880431816706
learning rate: 0.01
epoch 13...
epoch 13: - loss: 6517.727272911755
learning rate: 0.01
epoch 14...
epoch 14: - loss: 6475.405948258422
learning rate: 0.01
epoch 15...
epoch 15: - loss: 6473.838709838555
learning rate: 0.01
testing...
====> Test set loss: 93.7623
epoch 16...
epoch 16: - loss: 6431.225744379146
learning rate: 0.01
epoch 17...
epoch 17: - loss: 6416.45373269786
learning rate: 0.01
epoch 18...
epoch 18: - loss: 6400.612393352381
learning rate: 0.01
epoch 19...
epoch 19: - loss: 6382.548982664142
learning rate: 0.01
epoch 20...
epoch 20: - loss: 6345.877077692915
learning rate: 0.01
testing...
====> Test set loss: 95.4366
epoch 21...
epoch 21: - loss: 6357.848228044827
learning rate: 0.01
epoch 22...
epoch 22: - loss: 6309.638635503667
learning rate: 0.01
epoch 23...
epoch 23: - loss: 6284.660262710298
learning rate: 0.01
epoch 24...
epoch 24: - loss: 6250.900145547774
learning rate: 0.01
epoch 25...
epoch 25: - loss: 6254.301281550961
learning rate: 0.01
testing...
====> Test set loss: 93.5105
epoch 26...
epoch 26: - loss: 6222.04881688579
learning rate: 0.01
epoch 27...
epoch 27: - loss: 6236.368440671955
learning rate: 0.01
epoch 28...
epoch 28: - loss: 6195.232918585658
learning rate: 0.01
epoch 29...
epoch 29: - loss: 6208.995356176821
learning rate: 0.01
epoch 30...
epoch 30: - loss: 6186.880341434723
learning rate: 0.01
testing...
====> Test set loss: 93.4489
epoch 31...
epoch 31: - loss: 6176.388514682155
learning rate: 0.01
epoch 32...
epoch 32: - loss: 6182.953294836957
learning rate: 0.01
epoch 33...
epoch 33: - loss: 6151.074119626409
learning rate: 0.01
epoch 34...
epoch 34: - loss: 6144.668679005655
learning rate: 0.01
epoch 35...
epoch 35: - loss: 6144.271150476792
learning rate: 0.01
testing...
====> Test set loss: 94.0112
epoch 36...
epoch 36: - loss: 6134.812340621753
learning rate: 0.01
epoch 37...
epoch 37: - loss: 6132.379840197161
learning rate: 0.01
epoch 38...
epoch 38: - loss: 6140.717288902653
learning rate: 0.01
epoch 39...
epoch 39: - loss: 6123.924216346058
learning rate: 0.01
epoch 40...
epoch 40: - loss: 6128.4520461919055
learning rate: 0.01
testing...
====> Test set loss: 93.1469
epoch 41...
epoch 41: - loss: 6122.608050021979
learning rate: 0.01
epoch 42...
epoch 42: - loss: 6110.794920313999
learning rate: 0.01
epoch 43...
epoch 43: - loss: 6108.627253773877
learning rate: 0.01
epoch 44...
epoch 44: - loss: 6102.13794413613
learning rate: 0.01
epoch 45...
epoch 45: - loss: 6100.425557870694
learning rate: 0.01
testing...
====> Test set loss: 100.9892
epoch 46...
epoch 46: - loss: 6118.818606637627
learning rate: 0.01
epoch 47...
epoch 47: - loss: 6089.666049342631
learning rate: 0.01
epoch 48...
epoch 48: - loss: 6091.2871004772915
learning rate: 0.01
epoch 49...
epoch 49: - loss: 6106.01922779132
learning rate: 0.01
epoch 50...
epoch 50: - loss: 6097.852505344869
learning rate: 0.001
testing...
====> Test set loss: 91.0225
epoch 51...
epoch 51: - loss: 5934.426331346907
learning rate: 0.001
epoch 52...
epoch 52: - loss: 5912.616619763777
learning rate: 0.001
epoch 53...
epoch 53: - loss: 5898.222117704504
learning rate: 0.001
epoch 54...
epoch 54: - loss: 5890.372279174492
learning rate: 0.001
epoch 55...
epoch 55: - loss: 5890.466399756234
learning rate: 0.001
testing...
====> Test set loss: 89.1488
epoch 56...
epoch 56: - loss: 5882.639772537114
learning rate: 0.001
epoch 57...
epoch 57: - loss: 5878.46238048973
learning rate: 0.001
epoch 58...
epoch 58: - loss: 5876.524715023577
learning rate: 0.001
epoch 59...
epoch 59: - loss: 5878.285029808883
learning rate: 0.001
epoch 60...
epoch 60: - loss: 5876.206990039562
learning rate: 0.001
testing...
====> Test set loss: 89.1699
epoch 61...
epoch 61: - loss: 5876.583263036236
learning rate: 0.001
epoch 62...
epoch 62: - loss: 5879.891398164013
learning rate: 0.001
epoch 63...
epoch 63: - loss: 5873.294418920336
learning rate: 0.001
epoch 64...
epoch 64: - loss: 5870.987826218081
learning rate: 0.001
epoch 65...
epoch 65: - loss: 5872.88734861408
learning rate: 0.001
testing...
====> Test set loss: 89.4359
epoch 66...
epoch 66: - loss: 5872.784760223935
learning rate: 0.001
epoch 67...
epoch 67: - loss: 5863.200450067935
learning rate: 0.001
epoch 68...
epoch 68: - loss: 5860.781783706392
learning rate: 0.001
epoch 69...
epoch 69: - loss: 5864.770846862012
learning rate: 0.001
epoch 70...
epoch 70: - loss: 5858.750723680267
learning rate: 0.001
testing...
====> Test set loss: 90.8266
epoch 71...
epoch 71: - loss: 5857.34968492747
learning rate: 0.001
epoch 72...
epoch 72: - loss: 5856.986144707331
learning rate: 0.001
epoch 73...
epoch 73: - loss: 5862.4419266878795
learning rate: 0.001
epoch 74...
epoch 74: - loss: 5855.160975463555
learning rate: 0.001
epoch 75...
epoch 75: - loss: 5851.16768620874
learning rate: 0.001
testing...
====> Test set loss: 89.8099
epoch 76...
epoch 76: - loss: 5854.728518747002
learning rate: 0.001
epoch 77...
epoch 77: - loss: 5860.660289247323
learning rate: 0.001
epoch 78...
epoch 78: - loss: 5850.037763278503
learning rate: 0.001
epoch 79...
epoch 79: - loss: 5850.670859100263
learning rate: 0.001
epoch 80...
epoch 80: - loss: 5851.260744997303
learning rate: 0.001
testing...
====> Test set loss: 89.6346
epoch 81...
epoch 81: - loss: 5848.680026705612
learning rate: 0.001
epoch 82...
epoch 82: - loss: 5848.031675528992
learning rate: 0.001
epoch 83...
epoch 83: - loss: 5848.077151247303
learning rate: 0.001
epoch 84...
epoch 84: - loss: 5847.106414404671
learning rate: 0.001
epoch 85...
epoch 85: - loss: 5849.207440856778
learning rate: 0.001
testing...
====> Test set loss: 89.6511
epoch 86...
epoch 86: - loss: 5846.468488220059
learning rate: 0.001
epoch 87...
epoch 87: - loss: 5850.190969793998
learning rate: 0.001
epoch 88...
epoch 88: - loss: 5838.883415670956
learning rate: 0.001
epoch 89...
epoch 89: - loss: 5847.621109516114
learning rate: 0.001
epoch 90...
epoch 90: - loss: 5845.593071276575
learning rate: 0.001
testing...
====> Test set loss: 89.8202
epoch 91...
epoch 91: - loss: 5844.215009372253
learning rate: 0.001
epoch 92...
epoch 92: - loss: 5843.569601307745
learning rate: 0.001
epoch 93...
epoch 93: - loss: 5847.9980467189
learning rate: 0.001
epoch 94...
epoch 94: - loss: 5836.708119892403
learning rate: 0.001
epoch 95...
epoch 95: - loss: 5833.865059542839
learning rate: 0.001
testing...
====> Test set loss: 89.5807
epoch 96...
epoch 96: - loss: 5837.685356745024
learning rate: 0.001
epoch 97...
epoch 97: - loss: 5840.944837175062
learning rate: 0.001
epoch 98...
epoch 98: - loss: 5836.424363236293
learning rate: 0.001
epoch 99...
epoch 99: - loss: 5838.563201045746
learning rate: 0.001
epoch 100...
epoch 100: - loss: 5824.596477381713
learning rate: 0.00010000000000000002
testing...
====> Test set loss: 89.2913
epoch 101...
epoch 101: - loss: 5811.017684741399
learning rate: 0.00010000000000000002
epoch 102...
epoch 102: - loss: 5816.479543700548
learning rate: 0.00010000000000000002
epoch 103...
epoch 103: - loss: 5819.95170339599
learning rate: 0.00010000000000000002
epoch 104...
epoch 104: - loss: 5814.165609452426
learning rate: 0.00010000000000000002
epoch 105...
epoch 105: - loss: 5809.987102225614
learning rate: 0.00010000000000000002
testing...
====> Test set loss: 89.0676
epoch 106...
epoch 106: - loss: 5802.427820230079
learning rate: 0.00010000000000000002
epoch 107...
epoch 107: - loss: 5803.276198599345
learning rate: 0.00010000000000000002
epoch 108...
epoch 108: - loss: 5808.232993825927
learning rate: 0.00010000000000000002
epoch 109...
epoch 109: - loss: 5810.469278867287
learning rate: 0.00010000000000000002
epoch 110...
epoch 110: - loss: 5807.4922204371305
learning rate: 0.00010000000000000002
testing...
====> Test set loss: 89.1244
epoch 111...
epoch 111: - loss: 5807.745604844349
learning rate: 0.00010000000000000002
epoch 112...
epoch 112: - loss: 5812.195510122782
learning rate: 0.00010000000000000002
epoch 113...
epoch 113: - loss: 5805.4509903305325
learning rate: 0.00010000000000000002
epoch 114...
epoch 114: - loss: 5805.492756172824
learning rate: 0.00010000000000000002
epoch 115...
epoch 115: - loss: 5803.920418429558
learning rate: 0.00010000000000000002
testing...
====> Test set loss: 88.9972
epoch 116...
epoch 116: - loss: 5805.198683638707
learning rate: 0.00010000000000000002
epoch 117...
epoch 117: - loss: 5814.595832219819
learning rate: 0.00010000000000000002
epoch 118...
epoch 118: - loss: 5809.735583371214
learning rate: 0.00010000000000000002
epoch 119...
epoch 119: - loss: 5801.657579036625
learning rate: 0.00010000000000000002
epoch 120...
epoch 120: - loss: 5804.990228755395
learning rate: 0.00010000000000000002
testing...
====> Test set loss: 89.0070
epoch 121...
epoch 121: - loss: 5794.603942090593
learning rate: 0.00010000000000000002
epoch 122...
epoch 122: - loss: 5800.684522077556
learning rate: 0.00010000000000000002
epoch 123...
epoch 123: - loss: 5811.002644180337
learning rate: 0.00010000000000000002
epoch 124...
epoch 124: - loss: 5802.003717368826
learning rate: 0.00010000000000000002
epoch 125...
epoch 125: - loss: 5799.710043982776
learning rate: 0.00010000000000000002
testing...
====> Test set loss: 89.2803
epoch 126...
epoch 126: - loss: 5808.192007547754
learning rate: 0.00010000000000000002
epoch 127...
epoch 127: - loss: 5800.02409905241
learning rate: 0.00010000000000000002
epoch 128...
epoch 128: - loss: 5804.977371879246
learning rate: 0.00010000000000000002
epoch 129...
epoch 129: - loss: 5797.136842537414
learning rate: 0.00010000000000000002
epoch 130...
epoch 130: - loss: 5802.597075869665
learning rate: 0.00010000000000000002
testing...
====> Test set loss: 89.0383
epoch 131...
epoch 131: - loss: 5797.6542448936525
learning rate: 0.00010000000000000002
epoch 132...
epoch 132: - loss: 5803.906851922155
learning rate: 0.00010000000000000002
epoch 133...
epoch 133: - loss: 5802.267171328025
learning rate: 0.00010000000000000002
epoch 134...
epoch 134: - loss: 5793.58965986403
learning rate: 0.00010000000000000002
epoch 135...
epoch 135: - loss: 5808.673159704184
learning rate: 0.00010000000000000002
testing...
====> Test set loss: 89.0039
epoch 136...
epoch 136: - loss: 5792.455711735484
learning rate: 0.00010000000000000002
epoch 137...
epoch 137: - loss: 5794.8045788542995
learning rate: 0.00010000000000000002
epoch 138...
epoch 138: - loss: 5802.666827970149
learning rate: 0.00010000000000000002
epoch 139...
epoch 139: - loss: 5801.329548008912
learning rate: 0.00010000000000000002
epoch 140...
epoch 140: - loss: 5799.504223913793
learning rate: 0.00010000000000000002
testing...
====> Test set loss: 89.1541
epoch 141...
epoch 141: - loss: 5798.368957051231
learning rate: 0.00010000000000000002
epoch 142...
epoch 142: - loss: 5797.068459903493
learning rate: 0.00010000000000000002
epoch 143...
epoch 143: - loss: 5800.1557167619085
learning rate: 0.00010000000000000002
epoch 144...
epoch 144: - loss: 5795.010091718201
learning rate: 0.00010000000000000002
epoch 145...
epoch 145: - loss: 5801.065936856868
learning rate: 0.00010000000000000002
testing...
====> Test set loss: 89.2912
epoch 146...
epoch 146: - loss: 5787.793861955023
learning rate: 0.00010000000000000002
epoch 147...
epoch 147: - loss: 5795.46388935372
learning rate: 0.00010000000000000002
epoch 148...
epoch 148: - loss: 5794.5470020655175
learning rate: 0.00010000000000000002
epoch 149...
epoch 149: - loss: 5792.339089474105
learning rate: 0.00010000000000000002
epoch 150...
epoch 150: - loss: 5803.122219075937
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.5149
epoch 151...
epoch 151: - loss: 5791.442986607856
learning rate: 1.0000000000000003e-05
epoch 152...
epoch 152: - loss: 5786.577291581332
learning rate: 1.0000000000000003e-05
epoch 153...
epoch 153: - loss: 5797.10323308374
learning rate: 1.0000000000000003e-05
epoch 154...
epoch 154: - loss: 5781.210626548514
learning rate: 1.0000000000000003e-05
epoch 155...
epoch 155: - loss: 5788.482338829724
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.1146
epoch 156...
epoch 156: - loss: 5786.729207929138
learning rate: 1.0000000000000003e-05
epoch 157...
epoch 157: - loss: 5784.53644782259
learning rate: 1.0000000000000003e-05
epoch 158...
epoch 158: - loss: 5789.017419527254
learning rate: 1.0000000000000003e-05
epoch 159...
epoch 159: - loss: 5790.6998355016685
learning rate: 1.0000000000000003e-05
epoch 160...
epoch 160: - loss: 5784.914121661955
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.1435
epoch 161...
epoch 161: - loss: 5793.086666955972
learning rate: 1.0000000000000003e-05
epoch 162...
epoch 162: - loss: 5788.450278045576
learning rate: 1.0000000000000003e-05
epoch 163...
epoch 163: - loss: 5790.204029756434
learning rate: 1.0000000000000003e-05
epoch 164...
epoch 164: - loss: 5786.66423608336
learning rate: 1.0000000000000003e-05
epoch 165...
epoch 165: - loss: 5791.044941231417
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.1314
epoch 166...
epoch 166: - loss: 5795.775026599465
learning rate: 1.0000000000000003e-05
epoch 167...
epoch 167: - loss: 5793.760644937111
learning rate: 1.0000000000000003e-05
epoch 168...
epoch 168: - loss: 5791.580966178719
learning rate: 1.0000000000000003e-05
epoch 169...
epoch 169: - loss: 5790.338040481138
learning rate: 1.0000000000000003e-05
epoch 170...
epoch 170: - loss: 5785.635050976063
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.1514
epoch 171...
epoch 171: - loss: 5785.264915680947
learning rate: 1.0000000000000003e-05
epoch 172...
epoch 172: - loss: 5788.389462522228
learning rate: 1.0000000000000003e-05
epoch 173...
epoch 173: - loss: 5788.53083727122
learning rate: 1.0000000000000003e-05
epoch 174...
epoch 174: - loss: 5789.1375428026595
learning rate: 1.0000000000000003e-05
epoch 175...
epoch 175: - loss: 5786.166177813049
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.1678
epoch 176...
epoch 176: - loss: 5791.57938410376
learning rate: 1.0000000000000003e-05
epoch 177...
epoch 177: - loss: 5780.914402173913
learning rate: 1.0000000000000003e-05
epoch 178...
epoch 178: - loss: 5794.748332069963
learning rate: 1.0000000000000003e-05
epoch 179...
epoch 179: - loss: 5786.797945066486
learning rate: 1.0000000000000003e-05
epoch 180...
epoch 180: - loss: 5796.909815639486
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.0734
epoch 181...
epoch 181: - loss: 5790.6870396606755
learning rate: 1.0000000000000003e-05
epoch 182...
epoch 182: - loss: 5794.600398149027
learning rate: 1.0000000000000003e-05
epoch 183...
epoch 183: - loss: 5790.752324018942
learning rate: 1.0000000000000003e-05
epoch 184...
epoch 184: - loss: 5787.463913237042
learning rate: 1.0000000000000003e-05
epoch 185...
epoch 185: - loss: 5788.368441296356
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.1075
epoch 186...
epoch 186: - loss: 5793.072712695812
learning rate: 1.0000000000000003e-05
epoch 187...
epoch 187: - loss: 5787.925735356558
learning rate: 1.0000000000000003e-05
epoch 188...
epoch 188: - loss: 5785.418976220329
learning rate: 1.0000000000000003e-05
epoch 189...
epoch 189: - loss: 5793.714118820932
learning rate: 1.0000000000000003e-05
epoch 190...
epoch 190: - loss: 5794.904100032719
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.0037
epoch 191...
epoch 191: - loss: 5785.4023398474965
learning rate: 1.0000000000000003e-05
epoch 192...
epoch 192: - loss: 5795.980893966792
learning rate: 1.0000000000000003e-05
epoch 193...
epoch 193: - loss: 5791.489437327666
learning rate: 1.0000000000000003e-05
epoch 194...
epoch 194: - loss: 5786.253646499361
learning rate: 1.0000000000000003e-05
epoch 195...
epoch 195: - loss: 5791.318218104369
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.1368
epoch 196...
epoch 196: - loss: 5786.576904609075
learning rate: 1.0000000000000003e-05
epoch 197...
epoch 197: - loss: 5791.733605894591
learning rate: 1.0000000000000003e-05
epoch 198...
epoch 198: - loss: 5788.076798304877
learning rate: 1.0000000000000003e-05
epoch 199...
epoch 199: - loss: 5791.233965705423
learning rate: 1.0000000000000003e-05
epoch 200...
epoch 200: - loss: 5790.7381832191095
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.5970
epoch 201...
epoch 201: - loss: 5781.6107283882475
learning rate: 1.0000000000000003e-05
epoch 202...
epoch 202: - loss: 5786.317204546136
learning rate: 1.0000000000000003e-05
epoch 203...
epoch 203: - loss: 5788.058056921605
learning rate: 1.0000000000000003e-05
epoch 204...
epoch 204: - loss: 5793.075586655561
learning rate: 1.0000000000000003e-05
epoch 205...
epoch 205: - loss: 5786.336814002308
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.1303
epoch 206...
epoch 206: - loss: 5787.454283575268
learning rate: 1.0000000000000003e-05
epoch 207...
epoch 207: - loss: 5786.967834472656
learning rate: 1.0000000000000003e-05
epoch 208...
epoch 208: - loss: 5792.177089057005
learning rate: 1.0000000000000003e-05
epoch 209...
epoch 209: - loss: 5785.061984089025
learning rate: 1.0000000000000003e-05
epoch 210...
epoch 210: - loss: 5779.39548564628
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.0219
epoch 211...
epoch 211: - loss: 5783.424419120145
learning rate: 1.0000000000000003e-05
epoch 212...
epoch 212: - loss: 5795.551969484295
learning rate: 1.0000000000000003e-05
epoch 213...
epoch 213: - loss: 5799.276406212536
learning rate: 1.0000000000000003e-05
epoch 214...
epoch 214: - loss: 5786.964352346748
learning rate: 1.0000000000000003e-05
epoch 215...
epoch 215: - loss: 5782.184643367367
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 88.9350
epoch 216...
epoch 216: - loss: 5786.641405656819
learning rate: 1.0000000000000003e-05
epoch 217...
epoch 217: - loss: 5790.6490174120345
learning rate: 1.0000000000000003e-05
epoch 218...
epoch 218: - loss: 5782.4551761558905
learning rate: 1.0000000000000003e-05
epoch 219...
epoch 219: - loss: 5786.339889799542
learning rate: 1.0000000000000003e-05
epoch 220...
epoch 220: - loss: 5786.268226721098
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.1261
epoch 221...
epoch 221: - loss: 5790.9741426355695
learning rate: 1.0000000000000003e-05
epoch 222...
epoch 222: - loss: 5782.095881547464
learning rate: 1.0000000000000003e-05
epoch 223...
epoch 223: - loss: 5785.701603491898
learning rate: 1.0000000000000003e-05
epoch 224...
epoch 224: - loss: 5786.562118647348
learning rate: 1.0000000000000003e-05
epoch 225...
epoch 225: - loss: 5780.664023474964
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.1890
epoch 226...
epoch 226: - loss: 5782.842613590953
learning rate: 1.0000000000000003e-05
epoch 227...
epoch 227: - loss: 5790.380799744745
learning rate: 1.0000000000000003e-05
epoch 228...
epoch 228: - loss: 5782.746351627437
learning rate: 1.0000000000000003e-05
epoch 229...
epoch 229: - loss: 5780.970230453764
learning rate: 1.0000000000000003e-05
epoch 230...
epoch 230: - loss: 5784.916655479489
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.0860
epoch 231...
epoch 231: - loss: 5774.581137576676
learning rate: 1.0000000000000003e-05
epoch 232...
epoch 232: - loss: 5778.230873049372
learning rate: 1.0000000000000003e-05
epoch 233...
epoch 233: - loss: 5778.068901666899
learning rate: 1.0000000000000003e-05
epoch 234...
epoch 234: - loss: 5778.311586189758
learning rate: 1.0000000000000003e-05
epoch 235...
epoch 235: - loss: 5782.962328196181
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.1275
epoch 236...
epoch 236: - loss: 5779.740688938619
learning rate: 1.0000000000000003e-05
epoch 237...
epoch 237: - loss: 5786.844262164572
learning rate: 1.0000000000000003e-05
epoch 238...
epoch 238: - loss: 5782.325115389226
learning rate: 1.0000000000000003e-05
epoch 239...
epoch 239: - loss: 5782.560175200558
learning rate: 1.0000000000000003e-05
epoch 240...
epoch 240: - loss: 5784.783341429727
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.2119
epoch 241...
epoch 241: - loss: 5783.258758466872
learning rate: 1.0000000000000003e-05
epoch 242...
epoch 242: - loss: 5783.2822176647915
learning rate: 1.0000000000000003e-05
epoch 243...
epoch 243: - loss: 5787.423185616808
learning rate: 1.0000000000000003e-05
epoch 244...
epoch 244: - loss: 5783.5890303121505
learning rate: 1.0000000000000003e-05
epoch 245...
epoch 245: - loss: 5785.428514407419
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.0634
epoch 246...
epoch 246: - loss: 5787.218295592481
learning rate: 1.0000000000000003e-05
epoch 247...
epoch 247: - loss: 5779.523671025815
learning rate: 1.0000000000000003e-05
epoch 248...
epoch 248: - loss: 5779.162101882193
learning rate: 1.0000000000000003e-05
epoch 249...
epoch 249: - loss: 5782.779023699748
learning rate: 1.0000000000000003e-05
epoch 250...
epoch 250: - loss: 5780.912746575787
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.2878
epoch 251...
epoch 251: - loss: 5781.247559998651
learning rate: 1.0000000000000003e-05
epoch 252...
epoch 252: - loss: 5782.624093994765
learning rate: 1.0000000000000003e-05
epoch 253...
epoch 253: - loss: 5784.52882982337
learning rate: 1.0000000000000003e-05
epoch 254...
epoch 254: - loss: 5791.13163004141
learning rate: 1.0000000000000003e-05
epoch 255...
epoch 255: - loss: 5780.986916934743
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.1031
epoch 256...
epoch 256: - loss: 5782.012951472836
learning rate: 1.0000000000000003e-05
epoch 257...
epoch 257: - loss: 5779.994474367108
learning rate: 1.0000000000000003e-05
epoch 258...
epoch 258: - loss: 5785.703097214175
learning rate: 1.0000000000000003e-05
epoch 259...
epoch 259: - loss: 5777.252405815417
learning rate: 1.0000000000000003e-05
epoch 260...
epoch 260: - loss: 5779.603350627148
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.2143
epoch 261...
epoch 261: - loss: 5776.843700360154
learning rate: 1.0000000000000003e-05
epoch 262...
epoch 262: - loss: 5777.99778634386
learning rate: 1.0000000000000003e-05
epoch 263...
epoch 263: - loss: 5774.277831562949
learning rate: 1.0000000000000003e-05
epoch 264...
epoch 264: - loss: 5778.618645475343
learning rate: 1.0000000000000003e-05
epoch 265...
epoch 265: - loss: 5775.925698516924
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.2008
epoch 266...
epoch 266: - loss: 5779.69461801046
learning rate: 1.0000000000000003e-05
epoch 267...
epoch 267: - loss: 5771.053486465493
learning rate: 1.0000000000000003e-05
epoch 268...
epoch 268: - loss: 5781.2598586606855
learning rate: 1.0000000000000003e-05
epoch 269...
epoch 269: - loss: 5774.883497779631
learning rate: 1.0000000000000003e-05
epoch 270...
epoch 270: - loss: 5775.211239241578
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.3856
epoch 271...
epoch 271: - loss: 5779.866011285416
learning rate: 1.0000000000000003e-05
epoch 272...
epoch 272: - loss: 5768.105512458041
learning rate: 1.0000000000000003e-05
epoch 273...
epoch 273: - loss: 5775.29662492757
learning rate: 1.0000000000000003e-05
epoch 274...
epoch 274: - loss: 5776.398648547394
learning rate: 1.0000000000000003e-05
epoch 275...
epoch 275: - loss: 5776.284096173923
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.0908
epoch 276...
epoch 276: - loss: 5776.532202991379
learning rate: 1.0000000000000003e-05
epoch 277...
epoch 277: - loss: 5779.400284476902
learning rate: 1.0000000000000003e-05
epoch 278...
epoch 278: - loss: 5771.630199383591
learning rate: 1.0000000000000003e-05
epoch 279...
epoch 279: - loss: 5771.169610611313
learning rate: 1.0000000000000003e-05
epoch 280...
epoch 280: - loss: 5773.444393850654
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.2267
epoch 281...
epoch 281: - loss: 5775.07368707291
learning rate: 1.0000000000000003e-05
epoch 282...
epoch 282: - loss: 5765.596354687001
learning rate: 1.0000000000000003e-05
epoch 283...
epoch 283: - loss: 5769.4357156192555
learning rate: 1.0000000000000003e-05
epoch 284...
epoch 284: - loss: 5775.8108125574445
learning rate: 1.0000000000000003e-05
epoch 285...
epoch 285: - loss: 5772.044766087057
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 88.9007
epoch 286...
epoch 286: - loss: 5772.028886956022
learning rate: 1.0000000000000003e-05
epoch 287...
epoch 287: - loss: 5779.737268316167
learning rate: 1.0000000000000003e-05
epoch 288...
epoch 288: - loss: 5780.344857998821
learning rate: 1.0000000000000003e-05
epoch 289...
epoch 289: - loss: 5775.326704956991
learning rate: 1.0000000000000003e-05
epoch 290...
epoch 290: - loss: 5769.34712488511
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.1508
epoch 291...
epoch 291: - loss: 5770.476229382293
learning rate: 1.0000000000000003e-05
epoch 292...
epoch 292: - loss: 5780.282065311051
learning rate: 1.0000000000000003e-05
epoch 293...
epoch 293: - loss: 5764.449995504316
learning rate: 1.0000000000000003e-05
epoch 294...
epoch 294: - loss: 5773.87211370834
learning rate: 1.0000000000000003e-05
epoch 295...
epoch 295: - loss: 5768.420397512138
learning rate: 1.0000000000000003e-05
testing...
====> Test set loss: 89.0238
epoch 296...
epoch 296: - loss: 5773.174339509072
learning rate: 1.0000000000000003e-05
epoch 297...
epoch 297: - loss: 5767.360723861343
learning rate: 1.0000000000000003e-05
epoch 298...
epoch 298: - loss: 5778.893242175012
learning rate: 1.0000000000000003e-05
epoch 299...
epoch 299: - loss: 5762.024704096567
learning rate: 1.0000000000000003e-05
Training Finished

Testing on training data...
testing...
====> Test on training set loss: 414.9585
Testing Finished

