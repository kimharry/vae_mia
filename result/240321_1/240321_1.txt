{'async_loading': True,
 'batch_size': 64,
 'cuda': True,
 'dataloader_workers': 4,
 'dataset': 'CIFAR10',
 'experiment_dir': 'VAE_CIFAR10_mse_loss_ld_512',
 'generate_result_split': True,
 'generate_result_total': False,
 'input_shape': {'channels': 3, 'hight': 32, 'width': 32},
 'learning_rate': 0.01,
 'learning_rate_decay': 0.99,
 'loss': 'mse',
 'num_classes': 10,
 'num_epochs': 300,
 'num_split_models': 3,
 'pin_memory': True,
 'resume': True,
 'resume_from': '240321_1.pth.tar',
 'seed': 1,
 'shuffle': True,
 'test_every': 5,
 'to_test_split': True,
 'to_test_total': False,
 'to_train_split': True,
 'to_train_total': False,
 'weight_decay': 0.0005}


Experiment directories created!
Loading Data...
Files already downloaded and verified
Files already downloaded and verified
Data loaded successfully

Loading checkpoint '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/240321_1.pth.tar'
No checkpoint exists from '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/'. Skipping...

Loading checkpoint '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/240321_1.pth.tar'
No checkpoint exists from '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/'. Skipping...

Training...
epoch 0...
epoch 0: - loss: 11021.854881813459
learning rate: 0.01
testing...
====> Test set loss: 124.9182
epoch 1...
epoch 1: - loss: 8472.296838160366
learning rate: 0.0099
epoch 2...
epoch 2: - loss: 8088.077039011299
learning rate: 0.009801
epoch 3...
epoch 3: - loss: 7621.534324080133
learning rate: 0.00970299
epoch 4...
epoch 4: - loss: 7197.270021716652
learning rate: 0.0096059601
epoch 5...
epoch 5: - loss: 7033.4279958427405
learning rate: 0.009509900499
testing...
====> Test set loss: 99.2981
epoch 6...
epoch 6: - loss: 6950.090376831991
learning rate: 0.00941480149401
epoch 7...
epoch 7: - loss: 6885.882670448869
learning rate: 0.0093206534790699
epoch 8...
epoch 8: - loss: 6796.156664445882
learning rate: 0.0092274469442792
epoch 9...
epoch 9: - loss: 6738.8476056735535
learning rate: 0.009135172474836408
epoch 10...
epoch 10: - loss: 6688.422810664262
learning rate: 0.009043820750088045
testing...
====> Test set loss: 99.8497
epoch 11...
epoch 11: - loss: 6652.4495248623825
learning rate: 0.008953382542587164
epoch 12...
epoch 12: - loss: 6630.036728334549
learning rate: 0.008863848717161293
epoch 13...
epoch 13: - loss: 6569.007392434512
learning rate: 0.008775210229989679
epoch 14...
epoch 14: - loss: 6514.953575036715
learning rate: 0.008687458127689783
epoch 15...
epoch 15: - loss: 6462.448814918927
learning rate: 0.008600583546412884
testing...
====> Test set loss: 96.9644
epoch 16...
epoch 16: - loss: 6441.098911139056
learning rate: 0.008514577710948755
epoch 17...
epoch 17: - loss: 6388.692278849804
learning rate: 0.008429431933839267
epoch 18...
epoch 18: - loss: 6373.916442402793
learning rate: 0.008345137614500875
epoch 19...
epoch 19: - loss: 6343.270751953125
learning rate: 0.008261686238355867
epoch 20...
epoch 20: - loss: 6313.542672784127
learning rate: 0.008179069375972308
testing...
====> Test set loss: 92.9642
epoch 21...
epoch 21: - loss: 6286.088355491229
learning rate: 0.008097278682212584
epoch 22...
epoch 22: - loss: 6279.873928996913
learning rate: 0.00801630589539046
epoch 23...
epoch 23: - loss: 6277.605997305087
learning rate: 0.007936142836436554
epoch 24...
epoch 24: - loss: 6266.510052224864
learning rate: 0.007856781408072187
epoch 25...
epoch 25: - loss: 6246.590086797924
learning rate: 0.007778213593991467
testing...
====> Test set loss: 92.1113
epoch 26...
epoch 26: - loss: 6218.181514808284
learning rate: 0.007700431458051551
epoch 27...
epoch 27: - loss: 6236.41157707351
learning rate: 0.007623427143471036
epoch 28...
epoch 28: - loss: 6203.505140377737
learning rate: 0.007547192872036326
epoch 29...
epoch 29: - loss: 6200.602102918698
learning rate: 0.007471720943315961
epoch 30...
epoch 30: - loss: 6206.582213574968
learning rate: 0.007397003733882802
testing...
====> Test set loss: 94.0467
epoch 31...
epoch 31: - loss: 6186.086045365199
learning rate: 0.007323033696543975
epoch 32...
epoch 32: - loss: 6180.203631857167
learning rate: 0.007249803359578534
epoch 33...
epoch 33: - loss: 6170.001041187959
learning rate: 0.00717730532598275
epoch 34...
epoch 34: - loss: 6166.622414669418
learning rate: 0.007105532272722921
epoch 35...
epoch 35: - loss: 6151.283833457381
learning rate: 0.007034476949995692
testing...
====> Test set loss: 175.6940
epoch 36...
epoch 36: - loss: 6143.805990936201
learning rate: 0.006964132180495734
epoch 37...
epoch 37: - loss: 6126.90648852102
learning rate: 0.006894490858690777
epoch 38...
epoch 38: - loss: 6100.075979403523
learning rate: 0.006825545950103869
epoch 39...
epoch 39: - loss: 6105.925583627218
learning rate: 0.006757290490602831
epoch 40...
epoch 40: - loss: 6099.988824478501
learning rate: 0.006689717585696803
testing...
====> Test set loss: 91.4625
epoch 41...
epoch 41: - loss: 6093.008202125959
learning rate: 0.0066228204098398346
epoch 42...
epoch 42: - loss: 6085.2756867469725
learning rate: 0.006556592205741436
epoch 43...
epoch 43: - loss: 6071.0944913195835
learning rate: 0.006491026283684022
epoch 44...
epoch 44: - loss: 6078.891208658438
learning rate: 0.0064261160208471816
epoch 45...
epoch 45: - loss: 6079.78162916725
learning rate: 0.00636185486063871
testing...
====> Test set loss: 91.8677
epoch 46...
epoch 46: - loss: 6067.63314873971
learning rate: 0.006298236312032322
epoch 47...
epoch 47: - loss: 6060.009907832231
learning rate: 0.006235253948912
epoch 48...
epoch 48: - loss: 6053.031634474654
learning rate: 0.00617290140942288
epoch 49...
epoch 49: - loss: 6058.179061070123
learning rate: 0.00611117239532865
epoch 50...
epoch 50: - loss: 6053.2404513542
learning rate: 0.006050060671375364
testing...
====> Test set loss: 92.1585
epoch 51...
epoch 51: - loss: 6046.605872893272
learning rate: 0.00598956006466161
epoch 52...
epoch 52: - loss: 6041.255661283917
learning rate: 0.005929664464014994
epoch 53...
epoch 53: - loss: 6044.971567139296
learning rate: 0.0058703678193748445
epoch 54...
epoch 54: - loss: 6035.597018112612
learning rate: 0.005811664141181096
epoch 55...
epoch 55: - loss: 6025.380086367088
learning rate: 0.005753547499769285
testing...
====> Test set loss: 90.5224
epoch 56...
epoch 56: - loss: 6038.538081254495
learning rate: 0.005696012024771592
epoch 57...
epoch 57: - loss: 6031.957371860514
learning rate: 0.005639051904523875
epoch 58...
epoch 58: - loss: 6032.1397889276295
learning rate: 0.005582661385478637
epoch 59...
epoch 59: - loss: 6034.3101862836675
learning rate: 0.005526834771623851
epoch 60...
epoch 60: - loss: 6025.075583377457
learning rate: 0.005471566423907613
testing...
====> Test set loss: 90.9665
epoch 61...
epoch 61: - loss: 6014.645908365469
learning rate: 0.0054168507596685355
epoch 62...
epoch 62: - loss: 6020.375056196051
learning rate: 0.00536268225207185
epoch 63...
epoch 63: - loss: 6016.324046415441
learning rate: 0.005309055429551132
epoch 64...
epoch 64: - loss: 6005.371151975353
learning rate: 0.00525596487525562
epoch 65...
epoch 65: - loss: 5996.651220297264
learning rate: 0.005203405226503064
testing...
====> Test set loss: 91.8461
epoch 66...
epoch 66: - loss: 6003.453498391544
learning rate: 0.005151371174238033
epoch 67...
epoch 67: - loss: 5990.539005211247
learning rate: 0.005099857462495653
epoch 68...
epoch 68: - loss: 6000.9891038977585
learning rate: 0.005048858887870696
epoch 69...
epoch 69: - loss: 5984.439890205403
learning rate: 0.004998370298991989
epoch 70...
epoch 70: - loss: 6000.686882780031
learning rate: 0.00494838659600207
testing...
====> Test set loss: 90.5392
epoch 71...
epoch 71: - loss: 5981.806313595199
learning rate: 0.0048989027300420495
epoch 72...
epoch 72: - loss: 5985.057169804488
learning rate: 0.004849913702741629
epoch 73...
epoch 73: - loss: 5976.6094892653055
learning rate: 0.004801414565714212
epoch 74...
epoch 74: - loss: 5976.429635830852
learning rate: 0.0047534004200570695
epoch 75...
epoch 75: - loss: 5969.70533850004
learning rate: 0.004705866415856499
testing...
====> Test set loss: 90.7010
epoch 76...
epoch 76: - loss: 5973.366075754775
learning rate: 0.004658807751697934
epoch 77...
epoch 77: - loss: 5968.779906446061
learning rate: 0.004612219674180955
epoch 78...
epoch 78: - loss: 5958.220033923683
learning rate: 0.004566097477439145
epoch 79...
epoch 79: - loss: 5957.323273875829
learning rate: 0.004520436502664754
epoch 80...
epoch 80: - loss: 5965.6415339711375
learning rate: 0.004475232137638106
testing...
====> Test set loss: 90.4158
epoch 81...
epoch 81: - loss: 5954.634520235574
learning rate: 0.004430479816261725
epoch 82...
epoch 82: - loss: 5953.691670683644
learning rate: 0.004386175018099108
epoch 83...
epoch 83: - loss: 5947.846964101962
learning rate: 0.004342313267918117
epoch 84...
epoch 84: - loss: 5943.788509593291
learning rate: 0.004298890135238935
epoch 85...
epoch 85: - loss: 5946.236300651375
learning rate: 0.004255901233886546
testing...
====> Test set loss: 92.4567
epoch 86...
epoch 86: - loss: 5937.819543238491
learning rate: 0.0042133422215476805
epoch 87...
epoch 87: - loss: 5938.030947790122
learning rate: 0.004171208799332204
epoch 88...
epoch 88: - loss: 5945.664236395561
learning rate: 0.004129496711338882
epoch 89...
epoch 89: - loss: 5930.591522763148
learning rate: 0.0040882017442254925
epoch 90...
epoch 90: - loss: 5923.747884530851
learning rate: 0.0040473197267832375
testing...
====> Test set loss: 91.1300
epoch 91...
epoch 91: - loss: 5926.099908150675
learning rate: 0.004006846529515405
epoch 92...
epoch 92: - loss: 5934.30146465643
learning rate: 0.003966778064220251
epoch 93...
epoch 93: - loss: 5929.361456751519
learning rate: 0.003927110283578048
epoch 94...
epoch 94: - loss: 5912.017007578974
learning rate: 0.003887839180742268
epoch 95...
epoch 95: - loss: 5919.853425086917
learning rate: 0.0038489607889348456
testing...
====> Test set loss: 90.4261
epoch 96...
epoch 96: - loss: 5925.0138526389665
learning rate: 0.003810471181045497
epoch 97...
epoch 97: - loss: 5911.594969766524
learning rate: 0.003772366469235042
epoch 98...
epoch 98: - loss: 5903.160178884521
learning rate: 0.003734642804542692
epoch 99...
epoch 99: - loss: 5912.945905056146
learning rate: 0.0036972963764972644
epoch 100...
epoch 100: - loss: 5899.8004638984075
learning rate: 0.003660323412732292
testing...
====> Test set loss: 89.8633
epoch 101...
epoch 101: - loss: 5907.347134563319
learning rate: 0.003623720178604969
epoch 102...
epoch 102: - loss: 5903.878977275565
learning rate: 0.0035874829768189195
epoch 103...
epoch 103: - loss: 5903.240466652014
learning rate: 0.00355160814705073
epoch 104...
epoch 104: - loss: 5896.798087898118
learning rate: 0.0035160920655802224
epoch 105...
epoch 105: - loss: 5887.85436199998
learning rate: 0.00348093114492442
testing...
====> Test set loss: 90.1015
epoch 106...
epoch 106: - loss: 5888.458388540751
learning rate: 0.003446121833475176
epoch 107...
epoch 107: - loss: 5899.601677233606
learning rate: 0.0034116606151404247
epoch 108...
epoch 108: - loss: 5893.897776415891
learning rate: 0.00337754400898902
epoch 109...
epoch 109: - loss: 5884.295197079554
learning rate: 0.0033437685688991296
epoch 110...
epoch 110: - loss: 5892.404844318205
learning rate: 0.0033103308832101385
testing...
====> Test set loss: 90.0102
epoch 111...
epoch 111: - loss: 5867.362827779082
learning rate: 0.003277227574378037
epoch 112...
epoch 112: - loss: 5884.188240070782
learning rate: 0.003244455298634257
epoch 113...
epoch 113: - loss: 5882.572683192885
learning rate: 0.003212010745647914
epoch 114...
epoch 114: - loss: 5869.944408836267
learning rate: 0.003179890638191435
epoch 115...
epoch 115: - loss: 5873.232500237272
learning rate: 0.0031480917318095205
testing...
====> Test set loss: 91.5026
epoch 116...
epoch 116: - loss: 5874.374445376189
learning rate: 0.003116610814491425
epoch 117...
epoch 117: - loss: 5862.93968103121
learning rate: 0.003085444706346511
epoch 118...
epoch 118: - loss: 5864.297155980259
learning rate: 0.003054590259283046
epoch 119...
epoch 119: - loss: 5866.422313953604
learning rate: 0.0030240443566902156
epoch 120...
epoch 120: - loss: 5864.991837679578
learning rate: 0.002993803913123313
testing...
====> Test set loss: 90.2402
epoch 121...
epoch 121: - loss: 5866.92058342741
learning rate: 0.0029638658739920797
epoch 122...
epoch 122: - loss: 5860.1255628971185
learning rate: 0.002934227215252159
epoch 123...
epoch 123: - loss: 5860.014276919158
learning rate: 0.002904884943099638
epoch 124...
epoch 124: - loss: 5854.719159450678
learning rate: 0.002875836093668641
epoch 125...
epoch 125: - loss: 5862.833742419777
learning rate: 0.0028470777327319545
testing...
====> Test set loss: 89.8418
epoch 126...
epoch 126: - loss: 5850.977784764126
learning rate: 0.002818606955404635
epoch 127...
epoch 127: - loss: 5856.299508409427
learning rate: 0.0027904208858505887
epoch 128...
epoch 128: - loss: 5844.911799360114
learning rate: 0.002762516676992083
epoch 129...
epoch 129: - loss: 5846.1793969976325
learning rate: 0.0027348915102221624
epoch 130...
epoch 130: - loss: 5842.310573724225
learning rate: 0.0027075425951199406
testing...
====> Test set loss: 90.4512
epoch 131...
epoch 131: - loss: 5844.483393910596
learning rate: 0.002680467169168741
epoch 132...
epoch 132: - loss: 5843.6488037109375
learning rate: 0.0026536624974770532
epoch 133...
epoch 133: - loss: 5837.701451762558
learning rate: 0.0026271258725022828
epoch 134...
epoch 134: - loss: 5837.422199063899
learning rate: 0.0026008546137772605
epoch 135...
epoch 135: - loss: 5839.685070457361
learning rate: 0.0025748460676394873
testing...
====> Test set loss: 89.7203
epoch 136...
epoch 136: - loss: 5828.83106623891
learning rate: 0.002549097606963093
epoch 137...
epoch 137: - loss: 5837.051645420396
learning rate: 0.002523606630893462
epoch 138...
epoch 138: - loss: 5824.493665143962
learning rate: 0.002498370564584527
epoch 139...
epoch 139: - loss: 5827.78961571891
learning rate: 0.0024733868589386816
epoch 140...
epoch 140: - loss: 5823.371780746733
learning rate: 0.0024486529903492947
testing...
====> Test set loss: 89.9596
epoch 141...
epoch 141: - loss: 5823.226423258671
learning rate: 0.002424166460445802
epoch 142...
epoch 142: - loss: 5824.106577685422
learning rate: 0.002399924795841344
epoch 143...
epoch 143: - loss: 5829.705079998202
learning rate: 0.0023759255478829305
epoch 144...
epoch 144: - loss: 5818.462963367667
learning rate: 0.002352166292404101
epoch 145...
epoch 145: - loss: 5816.416552921695
learning rate: 0.00232864462948006
testing...
====> Test set loss: 89.6377
epoch 146...
epoch 146: - loss: 5826.102100264996
learning rate: 0.0023053581831852595
epoch 147...
epoch 147: - loss: 5809.45717205233
learning rate: 0.002282304601353407
epoch 148...
epoch 148: - loss: 5815.472676543019
learning rate: 0.002259481555339873
epoch 149...
epoch 149: - loss: 5814.124843587656
learning rate: 0.002236886739786474
epoch 150...
epoch 150: - loss: 5808.643850497273
learning rate: 0.0022145178723886093
testing...
====> Test set loss: 90.1501
epoch 151...
epoch 151: - loss: 5797.935048603341
learning rate: 0.002192372693664723
epoch 152...
epoch 152: - loss: 5804.489599671815
learning rate: 0.002170448966728076
epoch 153...
epoch 153: - loss: 5807.120479964235
learning rate: 0.002148744477060795
epoch 154...
epoch 154: - loss: 5804.060939779062
learning rate: 0.002127257032290187
epoch 155...
epoch 155: - loss: 5796.40708560407
learning rate: 0.002105984461967285
testing...
====> Test set loss: 89.4352
epoch 156...
epoch 156: - loss: 5806.307453282349
learning rate: 0.0020849246173476124
epoch 157...
epoch 157: - loss: 5803.769844699089
learning rate: 0.002064075371174136
epoch 158...
epoch 158: - loss: 5793.311965513108
learning rate: 0.002043434617462395
epoch 159...
epoch 159: - loss: 5794.958888529512
learning rate: 0.002023000271287771
epoch 160...
epoch 160: - loss: 5793.113852108226
learning rate: 0.002002770268574893
testing...
====> Test set loss: 89.7300
epoch 161...
epoch 161: - loss: 5787.9465653597545
learning rate: 0.001982742565889144
epoch 162...
epoch 162: - loss: 5796.883231472786
learning rate: 0.0019629151402302527
epoch 163...
epoch 163: - loss: 5787.354243988271
learning rate: 0.0019432859888279502
epoch 164...
epoch 164: - loss: 5793.657175673853
learning rate: 0.0019238531289396707
epoch 165...
epoch 165: - loss: 5792.9191805554165
learning rate: 0.001904614597650274
testing...
====> Test set loss: 90.3512
epoch 166...
epoch 166: - loss: 5790.45090010465
learning rate: 0.001885568451673771
epoch 167...
epoch 167: - loss: 5783.208967516184
learning rate: 0.0018667127671570336
epoch 168...
epoch 168: - loss: 5785.995118748501
learning rate: 0.001848045639485463
epoch 169...
epoch 169: - loss: 5788.442633197131
learning rate: 0.0018295651830906084
epoch 170...
epoch 170: - loss: 5786.261259503377
learning rate: 0.0018112695312597024
testing...
====> Test set loss: 89.2684
epoch 171...
epoch 171: - loss: 5780.2180441151495
learning rate: 0.0017931568359471053
epoch 172...
epoch 172: - loss: 5779.9551365064535
learning rate: 0.0017752252675876344
epoch 173...
epoch 173: - loss: 5774.75535954234
learning rate: 0.0017574730149117579
epoch 174...
epoch 174: - loss: 5777.553729981718
learning rate: 0.0017398982847626403
epoch 175...
epoch 175: - loss: 5776.890312643613
learning rate: 0.001722499301915014
testing...
====> Test set loss: 89.3226
epoch 176...
epoch 176: - loss: 5782.751499810182
learning rate: 0.0017052743088958636
epoch 177...
epoch 177: - loss: 5769.086680536685
learning rate: 0.001688221565806905
epoch 178...
epoch 178: - loss: 5776.74505178154
learning rate: 0.0016713393501488361
epoch 179...
epoch 179: - loss: 5768.765653410226
learning rate: 0.0016546259566473476
epoch 180...
epoch 180: - loss: 5770.484484738401
learning rate: 0.0016380796970808743
testing...
====> Test set loss: 89.3440
epoch 181...
epoch 181: - loss: 5778.679956616648
learning rate: 0.0016216989001100655
epoch 182...
epoch 182: - loss: 5776.338211722996
learning rate: 0.0016054819111089647
epoch 183...
epoch 183: - loss: 5769.117993445043
learning rate: 0.001589427091997875
epoch 184...
epoch 184: - loss: 5772.595739184133
learning rate: 0.0015735328210778963
epoch 185...
epoch 185: - loss: 5767.964924922075
learning rate: 0.0015577974928671174
testing...
====> Test set loss: 89.5313
epoch 186...
epoch 186: - loss: 5771.699416372782
learning rate: 0.001542219517938446
epoch 187...
epoch 187: - loss: 5769.736400243267
learning rate: 0.0015267973227590618
epoch 188...
epoch 188: - loss: 5763.7110050913625
learning rate: 0.001511529349531471
epoch 189...
epoch 189: - loss: 5767.007032467581
learning rate: 0.0014964140560361563
epoch 190...
epoch 190: - loss: 5764.970471472387
learning rate: 0.0014814499154757947
testing...
====> Test set loss: 89.4080
epoch 191...
epoch 191: - loss: 5770.077577400695
learning rate: 0.0014666354163210369
epoch 192...
epoch 192: - loss: 5759.513502194143
learning rate: 0.0014519690621578264
epoch 193...
epoch 193: - loss: 5762.007775504266
learning rate: 0.001437449371536248
epoch 194...
epoch 194: - loss: 5761.555726190357
learning rate: 0.0014230748778208857
epoch 195...
epoch 195: - loss: 5756.270568067155
learning rate: 0.0014088441290426767
testing...
====> Test set loss: 89.5154
epoch 196...
epoch 196: - loss: 5754.447445452366
learning rate: 0.00139475568775225
epoch 197...
epoch 197: - loss: 5754.653534325797
learning rate: 0.0013808081308747276
epoch 198...
epoch 198: - loss: 5757.663731879896
learning rate: 0.0013670000495659802
epoch 199...
epoch 199: - loss: 5761.32456560452
learning rate: 0.0013533300490703203
epoch 200...
epoch 200: - loss: 5753.189772818095
learning rate: 0.0013397967485796172
testing...
====> Test set loss: 91.5778
epoch 201...
epoch 201: - loss: 5758.882394151615
learning rate: 0.001326398781093821
epoch 202...
epoch 202: - loss: 5751.8545796035805
learning rate: 0.0013131347932828826
epoch 203...
epoch 203: - loss: 5750.288023029142
learning rate: 0.001300003445350054
epoch 204...
epoch 204: - loss: 5746.237127669937
learning rate: 0.0012870034108965534
epoch 205...
epoch 205: - loss: 5759.459572872543
learning rate: 0.0012741333767875879
testing...
====> Test set loss: 89.4160
epoch 206...
epoch 206: - loss: 5746.2412310744185
learning rate: 0.0012613920430197118
epoch 207...
epoch 207: - loss: 5753.730929557625
learning rate: 0.0012487781225895148
epoch 208...
epoch 208: - loss: 5751.432641383022
learning rate: 0.0012362903413636196
epoch 209...
epoch 209: - loss: 5748.871906407349
learning rate: 0.0012239274379499834
epoch 210...
epoch 210: - loss: 5741.855999490489
learning rate: 0.0012116881635704836
testing...
====> Test set loss: 89.5376
epoch 211...
epoch 211: - loss: 5746.937323606838
learning rate: 0.0011995712819347787
epoch 212...
epoch 212: - loss: 5746.443155039911
learning rate: 0.001187575569115431
epoch 213...
epoch 213: - loss: 5738.4952993563675
learning rate: 0.0011756998134242766
epoch 214...
epoch 214: - loss: 5743.63204198969
learning rate: 0.001163942815290034
epoch 215...
epoch 215: - loss: 5747.090001723345
learning rate: 0.0011523033871371335
testing...
====> Test set loss: 89.3900
epoch 216...
epoch 216: - loss: 5742.183385824608
learning rate: 0.001140780353265762
epoch 217...
epoch 217: - loss: 5735.894897148737
learning rate: 0.0011293725497331045
epoch 218...
epoch 218: - loss: 5749.361635017883
learning rate: 0.0011180788242357734
epoch 219...
epoch 219: - loss: 5748.373077158428
learning rate: 0.0011068980359934158
epoch 220...
epoch 220: - loss: 5736.492052629475
learning rate: 0.0010958290556334815
testing...
====> Test set loss: 89.4140
epoch 221...
epoch 221: - loss: 5739.568340642983
learning rate: 0.0010848707650771467
epoch 222...
epoch 222: - loss: 5735.331747303839
learning rate: 0.0010740220574263753
epoch 223...
epoch 223: - loss: 5735.744622662244
learning rate: 0.0010632818368521114
epoch 224...
epoch 224: - loss: 5731.474611560402
learning rate: 0.0010526490184835904
epoch 225...
epoch 225: - loss: 5736.992197490409
learning rate: 0.0010421225282987545
testing...
====> Test set loss: 89.7708
epoch 226...
epoch 226: - loss: 5732.656791511399
learning rate: 0.0010317013030157669
epoch 227...
epoch 227: - loss: 5729.315413296985
learning rate: 0.0010213842899856093
epoch 228...
epoch 228: - loss: 5740.105498877328
learning rate: 0.0010111704470857532
epoch 229...
epoch 229: - loss: 5732.022047740419
learning rate: 0.0010010587426148956
epoch 230...
epoch 230: - loss: 5732.600720495824
learning rate: 0.0009910481551887466
testing...
====> Test set loss: 91.1316
epoch 231...
epoch 231: - loss: 5732.976962740769
learning rate: 0.0009811376736368592
epoch 232...
epoch 232: - loss: 5729.8664419657125
learning rate: 0.0009713262969004904
epoch 233...
epoch 233: - loss: 5727.950503922484
learning rate: 0.0009616130339314856
epoch 234...
epoch 234: - loss: 5731.574895912424
learning rate: 0.0009519969035921708
epoch 235...
epoch 235: - loss: 5725.5601169752035
learning rate: 0.000942476934556249
testing...
====> Test set loss: 89.6078
epoch 236...
epoch 236: - loss: 5727.972567116818
learning rate: 0.0009330521652106866
epoch 237...
epoch 237: - loss: 5721.464143953055
learning rate: 0.0009237216435585797
epoch 238...
epoch 238: - loss: 5728.598945793288
learning rate: 0.0009144844271229938
epoch 239...
epoch 239: - loss: 5722.32972018737
learning rate: 0.0009053395828517639
epoch 240...
epoch 240: - loss: 5728.982657586217
learning rate: 0.0008962861870232462
testing...
====> Test set loss: 89.2171
epoch 241...
epoch 241: - loss: 5725.345580742487
learning rate: 0.0008873233251530139
epoch 242...
epoch 242: - loss: 5724.663425611413
learning rate: 0.0008784500919014836
epoch 243...
epoch 243: - loss: 5723.0446568169555
learning rate: 0.0008696655909824688
epoch 244...
epoch 244: - loss: 5725.424461423284
learning rate: 0.000860968935072644
epoch 245...
epoch 245: - loss: 5712.028724611872
learning rate: 0.0008523592457219175
testing...
====> Test set loss: 90.8961
epoch 246...
epoch 246: - loss: 5723.701885877058
learning rate: 0.0008438356532646984
epoch 247...
epoch 247: - loss: 5723.270161894581
learning rate: 0.0008353972967320516
epoch 248...
epoch 248: - loss: 5722.392519431346
learning rate: 0.0008270433237647309
epoch 249...
epoch 249: - loss: 5720.454468397838
learning rate: 0.0008187728905270836
epoch 250...
epoch 250: - loss: 5724.783752909707
learning rate: 0.0008105851616218128
testing...
====> Test set loss: 89.3937
epoch 251...
epoch 251: - loss: 5718.421441666001
learning rate: 0.0008024793100055947
epoch 252...
epoch 252: - loss: 5718.393703607037
learning rate: 0.0007944545169055387
epoch 253...
epoch 253: - loss: 5721.902031861912
learning rate: 0.0007865099717364833
epoch 254...
epoch 254: - loss: 5714.488954978221
learning rate: 0.0007786448720191185
epoch 255...
epoch 255: - loss: 5726.288207383412
learning rate: 0.0007708584232989273
testing...
====> Test set loss: 89.3582
epoch 256...
epoch 256: - loss: 5723.011969134631
learning rate: 0.000763149839065938
epoch 257...
epoch 257: - loss: 5715.015308585009
learning rate: 0.0007555183406752786
epoch 258...
epoch 258: - loss: 5712.444307839474
learning rate: 0.0007479631572685258
epoch 259...
epoch 259: - loss: 5720.007485626299
learning rate: 0.0007404835256958406
epoch 260...
epoch 260: - loss: 5712.317971622243
learning rate: 0.0007330786904388821
testing...
====> Test set loss: 89.9036
epoch 261...
epoch 261: - loss: 5711.905583140186
learning rate: 0.0007257479035344933
epoch 262...
epoch 262: - loss: 5708.526758998861
learning rate: 0.0007184904244991483
epoch 263...
epoch 263: - loss: 5712.788586550661
learning rate: 0.0007113055202541569
epoch 264...
epoch 264: - loss: 5715.350437954564
learning rate: 0.0007041924650516154
epoch 265...
epoch 265: - loss: 5711.93505874985
learning rate: 0.0006971505404010992
testing...
====> Test set loss: 89.4514
epoch 266...
epoch 266: - loss: 5708.648399723766
learning rate: 0.0006901790349970881
epoch 267...
epoch 267: - loss: 5717.834768934323
learning rate: 0.0006832772446471172
epoch 268...
epoch 268: - loss: 5710.037789971627
learning rate: 0.000676444472200646
epoch 269...
epoch 269: - loss: 5710.7093099999
learning rate: 0.0006696800274786397
epoch 270...
epoch 270: - loss: 5710.186735109295
learning rate: 0.0006629832272038532
testing...
====> Test set loss: 90.1591
epoch 271...
epoch 271: - loss: 5708.843156195053
learning rate: 0.0006563533949318147
epoch 272...
epoch 272: - loss: 5707.063007949868
learning rate: 0.0006497898609824965
epoch 273...
epoch 273: - loss: 5700.8105387577925
learning rate: 0.0006432919623726716
epoch 274...
epoch 274: - loss: 5708.57358966642
learning rate: 0.0006368590427489448
epoch 275...
epoch 275: - loss: 5714.127634814328
learning rate: 0.0006304904523214554
testing...
====> Test set loss: 89.4449
epoch 276...
epoch 276: - loss: 5706.062385110294
learning rate: 0.0006241855477982409
epoch 277...
epoch 277: - loss: 5701.777189991359
learning rate: 0.0006179436923202584
epoch 278...
epoch 278: - loss: 5705.12915616633
learning rate: 0.0006117642553970558
epoch 279...
epoch 279: - loss: 5705.183473552889
learning rate: 0.0006056466128430852
epoch 280...
epoch 280: - loss: 5703.482001653413
learning rate: 0.0005995901467146544
testing...
====> Test set loss: 89.4722
epoch 281...
epoch 281: - loss: 5709.935197366778
learning rate: 0.0005935942452475079
epoch 282...
epoch 282: - loss: 5702.574057654651
learning rate: 0.0005876583027950328
epoch 283...
epoch 283: - loss: 5711.801556599415
learning rate: 0.0005817817197670825
epoch 284...
epoch 284: - loss: 5700.19601807265
learning rate: 0.0005759639025694117
epoch 285...
epoch 285: - loss: 5705.182804195472
learning rate: 0.0005702042635437175
testing...
====> Test set loss: 89.5238
epoch 286...
epoch 286: - loss: 5701.1768438236795
learning rate: 0.0005645022209082803
epoch 287...
epoch 287: - loss: 5700.225892362082
learning rate: 0.0005588571986991975
epoch 288...
epoch 288: - loss: 5702.791955347866
learning rate: 0.0005532686267122054
epoch 289...
epoch 289: - loss: 5704.774949173793
learning rate: 0.0005477359404450834
epoch 290...
epoch 290: - loss: 5701.152397760649
learning rate: 0.0005422585810406326
testing...
====> Test set loss: 89.6254
epoch 291...
epoch 291: - loss: 5704.640287667589
learning rate: 0.0005368359952302263
epoch 292...
epoch 292: - loss: 5701.700736511699
learning rate: 0.000531467635277924
epoch 293...
epoch 293: - loss: 5703.123297259631
learning rate: 0.0005261529589251448
epoch 294...
epoch 294: - loss: 5700.122379390785
learning rate: 0.0005208914293358933
epoch 295...
epoch 295: - loss: 5699.733068129595
learning rate: 0.0005156825150425344
testing...
====> Test set loss: 89.1814
epoch 296...
epoch 296: - loss: 5699.54103747902
learning rate: 0.000510525689892109
epoch 297...
epoch 297: - loss: 5699.8871523962
learning rate: 0.000505420432993188
epoch 298...
epoch 298: - loss: 5699.659246030061
learning rate: 0.000500366228663256
epoch 299...
epoch 299: - loss: 5690.235214506573
learning rate: 0.0004953625663766235
Training Finished

Testing on training data...
testing...
====> Test on training set loss: 407.5055
Testing Finished

