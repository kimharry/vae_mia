{'async_loading': True,
 'batch_size': 32,
 'cuda': True,
 'dataloader_workers': 4,
 'dataset': 'CIFAR10',
 'experiment_dir': 'VAE_CIFAR10_mse_loss_ld_512',
 'generate_result': True,
 'input_shape': {'channels': 3, 'hight': 32, 'width': 32},
 'learning_rate': 0.001,
 'learning_rate_decay': 0.99,
 'loss': 'mse',
 'num_classes': 10,
 'num_epochs': 200,
 'pin_memory': True,
 'resume': True,
 'resume_from': '240306_1.pth.tar',
 'seed': 1,
 'shuffle': True,
 'test_every': 20,
 'to_test': True,
 'to_train': True,
 'weight_decay': 0.0005}


Experiment directories created!
Loading Data...
Files already downloaded and verified
Files already downloaded and verified
Data loaded successfully

Loading checkpoint '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/240306_1.pth.tar'
No checkpoint exists from '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/'. Skipping...

Training...
epoch 0...
epoch 0: - loss: 5923.711697413078
learning rate: 0.001
testing...
====> Test set loss: 141.1044
epoch 1...
epoch 1: - loss: 4395.120693409359
learning rate: 0.00099
epoch 2...
epoch 2: - loss: 4116.82509753129
learning rate: 0.0009801
epoch 3...
epoch 3: - loss: 3914.9345715621002
learning rate: 0.0009702990000000001
epoch 4...
epoch 4: - loss: 3823.102257277671
learning rate: 0.0009605960099999999
epoch 5...
epoch 5: - loss: 3723.037468947437
learning rate: 0.0009509900498999999
epoch 6...
epoch 6: - loss: 3633.659920466076
learning rate: 0.000941480149401
epoch 7...
epoch 7: - loss: 3550.548222537538
learning rate: 0.0009320653479069899
epoch 8...
epoch 8: - loss: 3511.0596335735063
learning rate: 0.0009227446944279201
epoch 9...
epoch 9: - loss: 3480.8719572236882
learning rate: 0.0009135172474836409
epoch 10...
epoch 10: - loss: 3453.501414078745
learning rate: 0.0009043820750088044
epoch 11...
epoch 11: - loss: 3436.9920469199856
learning rate: 0.0008953382542587164
epoch 12...
epoch 12: - loss: 3413.4087538862564
learning rate: 0.0008863848717161292
epoch 13...
epoch 13: - loss: 3399.1823878077766
learning rate: 0.0008775210229989679
epoch 14...
epoch 14: - loss: 3376.2226888958035
learning rate: 0.0008687458127689783
epoch 15...
epoch 15: - loss: 3353.9141868352126
learning rate: 0.0008600583546412885
epoch 16...
epoch 16: - loss: 3330.018203627964
learning rate: 0.0008514577710948756
epoch 17...
epoch 17: - loss: 3322.9243991141584
learning rate: 0.0008429431933839268
epoch 18...
epoch 18: - loss: 3299.769540543901
learning rate: 0.0008345137614500875
epoch 19...
epoch 19: - loss: 3288.9226420982786
learning rate: 0.0008261686238355867
epoch 20...
epoch 20: - loss: 3278.4520163703864
learning rate: 0.0008179069375972307
testing...
====> Test set loss: 97.6574
epoch 21...
epoch 21: - loss: 3267.0429361041965
learning rate: 0.0008097278682212584
epoch 22...
epoch 22: - loss: 3255.3710774270985
learning rate: 0.0008016305895390458
epoch 23...
epoch 23: - loss: 3248.023992166257
learning rate: 0.0007936142836436554
epoch 24...
epoch 24: - loss: 3237.6051928226716
learning rate: 0.0007856781408072188
epoch 25...
epoch 25: - loss: 3225.1643386616283
learning rate: 0.0007778213593991467
epoch 26...
epoch 26: - loss: 3211.2375942042295
learning rate: 0.0007700431458051552
epoch 27...
epoch 27: - loss: 3200.24540865673
learning rate: 0.0007623427143471036
epoch 28...
epoch 28: - loss: 3187.6551708140896
learning rate: 0.0007547192872036326
epoch 29...
epoch 29: - loss: 3181.302209933446
learning rate: 0.0007471720943315962
epoch 30...
epoch 30: - loss: 3173.469033659229
learning rate: 0.0007397003733882802
epoch 31...
epoch 31: - loss: 3167.5840540402073
learning rate: 0.0007323033696543975
epoch 32...
epoch 32: - loss: 3161.3456679018964
learning rate: 0.0007249803359578534
epoch 33...
epoch 33: - loss: 3157.7689698671425
learning rate: 0.0007177305325982749
epoch 34...
epoch 34: - loss: 3147.1220712497
learning rate: 0.0007105532272722921
epoch 35...
epoch 35: - loss: 3142.085910164997
learning rate: 0.0007034476949995691
epoch 36...
epoch 36: - loss: 3135.2266341177074
learning rate: 0.0006964132180495735
epoch 37...
epoch 37: - loss: 3124.0195828741053
learning rate: 0.0006894490858690778
epoch 38...
epoch 38: - loss: 3118.301422763466
learning rate: 0.0006825545950103869
epoch 39...
epoch 39: - loss: 3117.7967619892884
learning rate: 0.0006757290490602831
epoch 40...
epoch 40: - loss: 3109.1081393016734
learning rate: 0.0006689717585696802
testing...
====> Test set loss: 93.6514
epoch 41...
epoch 41: - loss: 3111.949538647633
learning rate: 0.0006622820409839835
epoch 42...
epoch 42: - loss: 3103.986543602922
learning rate: 0.0006556592205741436
epoch 43...
epoch 43: - loss: 3107.003924134902
learning rate: 0.0006491026283684022
epoch 44...
epoch 44: - loss: 3093.2342613644882
learning rate: 0.0006426116020847181
epoch 45...
epoch 45: - loss: 3090.019388795585
learning rate: 0.000636185486063871
epoch 46...
epoch 46: - loss: 3083.5844853865515
learning rate: 0.0006298236312032323
epoch 47...
epoch 47: - loss: 3083.5839891391006
learning rate: 0.0006235253948911999
epoch 48...
epoch 48: - loss: 3081.2158182819
learning rate: 0.0006172901409422879
epoch 49...
epoch 49: - loss: 3072.4742351197615
learning rate: 0.000611117239532865
epoch 50...
epoch 50: - loss: 3074.4758578817277
learning rate: 0.0006050060671375364
epoch 51...
epoch 51: - loss: 3071.9930340259866
learning rate: 0.000598956006466161
epoch 52...
epoch 52: - loss: 3063.914141693408
learning rate: 0.0005929664464014994
epoch 53...
epoch 53: - loss: 3059.3777891855857
learning rate: 0.0005870367819374845
epoch 54...
epoch 54: - loss: 3056.938691962322
learning rate: 0.0005811664141181095
epoch 55...
epoch 55: - loss: 3055.343439786768
learning rate: 0.0005753547499769285
epoch 56...
epoch 56: - loss: 3055.24296803148
learning rate: 0.0005696012024771592
epoch 57...
epoch 57: - loss: 3051.5568713324237
learning rate: 0.0005639051904523875
epoch 58...
epoch 58: - loss: 3048.9033632675046
learning rate: 0.0005582661385478637
epoch 59...
epoch 59: - loss: 3046.3076827915065
learning rate: 0.0005526834771623851
epoch 60...
epoch 60: - loss: 3037.2266931613135
learning rate: 0.0005471566423907613
testing...
====> Test set loss: 93.5027
epoch 61...
epoch 61: - loss: 3035.7943509639417
learning rate: 0.0005416850759668536
epoch 62...
epoch 62: - loss: 3034.5981575739515
learning rate: 0.0005362682252071849
epoch 63...
epoch 63: - loss: 3030.870273075116
learning rate: 0.0005309055429551132
epoch 64...
epoch 64: - loss: 3023.545499815059
learning rate: 0.000525596487525562
epoch 65...
epoch 65: - loss: 3026.9449865105667
learning rate: 0.0005203405226503064
epoch 66...
epoch 66: - loss: 3024.7051434947066
learning rate: 0.0005151371174238034
epoch 67...
epoch 67: - loss: 3019.653059302273
learning rate: 0.0005099857462495653
epoch 68...
epoch 68: - loss: 3021.6133627864083
learning rate: 0.0005048858887870696
epoch 69...
epoch 69: - loss: 3018.569813597149
learning rate: 0.0004998370298991989
epoch 70...
epoch 70: - loss: 3017.8277081021574
learning rate: 0.000494838659600207
epoch 71...
epoch 71: - loss: 3018.7979453606094
learning rate: 0.000489890273004205
epoch 72...
epoch 72: - loss: 3011.7316032307162
learning rate: 0.00048499137027416283
epoch 73...
epoch 73: - loss: 3013.2474248865365
learning rate: 0.0004801414565714212
epoch 74...
epoch 74: - loss: 3015.9816852357244
learning rate: 0.00047534004200570695
epoch 75...
epoch 75: - loss: 3008.355594178613
learning rate: 0.0004705866415856499
epoch 76...
epoch 76: - loss: 3004.6343708294594
learning rate: 0.0004658807751697934
epoch 77...
epoch 77: - loss: 3003.8489702045345
learning rate: 0.00046122196741809544
epoch 78...
epoch 78: - loss: 3000.7759496648573
learning rate: 0.0004566097477439145
epoch 79...
epoch 79: - loss: 3003.2004159450225
learning rate: 0.0004520436502664754
epoch 80...
epoch 80: - loss: 3000.7627748964082
learning rate: 0.0004475232137638106
testing...
====> Test set loss: 92.5976
epoch 81...
epoch 81: - loss: 2997.509245713247
learning rate: 0.0004430479816261725
epoch 82...
epoch 82: - loss: 2997.1834793334883
learning rate: 0.00043861750180991077
epoch 83...
epoch 83: - loss: 2991.398332064989
learning rate: 0.00043423132679181164
epoch 84...
epoch 84: - loss: 2993.073711880948
learning rate: 0.0004298890135238935
epoch 85...
epoch 85: - loss: 2994.6582904408087
learning rate: 0.0004255901233886546
epoch 86...
epoch 86: - loss: 2992.105149086667
learning rate: 0.00042133422215476804
epoch 87...
epoch 87: - loss: 2990.0684043606047
learning rate: 0.00041712087993322035
epoch 88...
epoch 88: - loss: 2985.4411587510745
learning rate: 0.0004129496711338882
epoch 89...
epoch 89: - loss: 2985.9201686710253
learning rate: 0.00040882017442254927
epoch 90...
epoch 90: - loss: 2983.3966201128137
learning rate: 0.0004047319726783238
epoch 91...
epoch 91: - loss: 2983.161843366373
learning rate: 0.00040068465295154055
epoch 92...
epoch 92: - loss: 2980.1746174036807
learning rate: 0.0003966778064220251
epoch 93...
epoch 93: - loss: 2976.5226927383237
learning rate: 0.0003927110283578049
epoch 94...
epoch 94: - loss: 2978.3350557509098
learning rate: 0.0003887839180742268
epoch 95...
epoch 95: - loss: 2976.4258359200057
learning rate: 0.00038489607889348454
epoch 96...
epoch 96: - loss: 2974.937121917861
learning rate: 0.00038104711810454966
epoch 97...
epoch 97: - loss: 2973.649562764915
learning rate: 0.00037723664692350416
epoch 98...
epoch 98: - loss: 2976.3038527671147
learning rate: 0.0003734642804542692
epoch 99...
epoch 99: - loss: 2975.0513040514534
learning rate: 0.00036972963764972643
epoch 100...
epoch 100: - loss: 2973.420850796495
learning rate: 0.0003660323412732292
testing...
====> Test set loss: 92.5641
epoch 101...
epoch 101: - loss: 2971.012854870816
learning rate: 0.0003623720178604969
epoch 102...
epoch 102: - loss: 2969.544462646953
learning rate: 0.00035874829768189193
epoch 103...
epoch 103: - loss: 2966.9861837961853
learning rate: 0.000355160814705073
epoch 104...
epoch 104: - loss: 2970.1648873141844
learning rate: 0.0003516092065580223
epoch 105...
epoch 105: - loss: 2967.4518784457723
learning rate: 0.000348093114492442
epoch 106...
epoch 106: - loss: 2965.167118553313
learning rate: 0.0003446121833475176
epoch 107...
epoch 107: - loss: 2961.711887039897
learning rate: 0.00034116606151404246
epoch 108...
epoch 108: - loss: 2963.1429642514395
learning rate: 0.000337754400898902
epoch 109...
epoch 109: - loss: 2961.275456697607
learning rate: 0.000334376856889913
epoch 110...
epoch 110: - loss: 2957.860735267839
learning rate: 0.00033103308832101386
epoch 111...
epoch 111: - loss: 2958.14580146853
learning rate: 0.00032772275743780374
epoch 112...
epoch 112: - loss: 2960.57958968755
learning rate: 0.0003244455298634257
epoch 113...
epoch 113: - loss: 2953.821798977452
learning rate: 0.0003212010745647914
epoch 114...
epoch 114: - loss: 2956.5700542232735
learning rate: 0.0003179890638191435
epoch 115...
epoch 115: - loss: 2952.7745002068086
learning rate: 0.00031480917318095204
epoch 116...
epoch 116: - loss: 2956.3533930079875
learning rate: 0.00031166108144914254
epoch 117...
epoch 117: - loss: 2954.046367037548
learning rate: 0.0003085444706346511
epoch 118...
epoch 118: - loss: 2951.969595823087
learning rate: 0.0003054590259283046
epoch 119...
epoch 119: - loss: 2953.3281528036027
learning rate: 0.0003024044356690215
epoch 120...
epoch 120: - loss: 2952.3003081201514
learning rate: 0.0002993803913123313
testing...
====> Test set loss: 93.7427
epoch 121...
epoch 121: - loss: 2950.7076709671655
learning rate: 0.000296386587399208
epoch 122...
epoch 122: - loss: 2954.768661762611
learning rate: 0.00029342272152521593
epoch 123...
epoch 123: - loss: 2950.9560895201034
learning rate: 0.00029048849430996377
epoch 124...
epoch 124: - loss: 2948.143670900312
learning rate: 0.0002875836093668641
epoch 125...
epoch 125: - loss: 2943.9262059578436
learning rate: 0.00028470777327319546
epoch 126...
epoch 126: - loss: 2949.5214104923925
learning rate: 0.0002818606955404635
epoch 127...
epoch 127: - loss: 2950.1806300889966
learning rate: 0.00027904208858505885
epoch 128...
epoch 128: - loss: 2944.7754744263084
learning rate: 0.0002762516676992083
epoch 129...
epoch 129: - loss: 2943.276230746786
learning rate: 0.00027348915102221624
epoch 130...
epoch 130: - loss: 2943.1192410616104
learning rate: 0.00027075425951199404
epoch 131...
epoch 131: - loss: 2942.754757461987
learning rate: 0.0002680467169168741
epoch 132...
epoch 132: - loss: 2942.984814937345
learning rate: 0.0002653662497477053
epoch 133...
epoch 133: - loss: 2941.747342725328
learning rate: 0.0002627125872502283
epoch 134...
epoch 134: - loss: 2938.394208853167
learning rate: 0.000260085461377726
epoch 135...
epoch 135: - loss: 2937.4149864230944
learning rate: 0.00025748460676394875
epoch 136...
epoch 136: - loss: 2939.2347141883347
learning rate: 0.00025490976069630927
epoch 137...
epoch 137: - loss: 2936.1645556234503
learning rate: 0.0002523606630893462
epoch 138...
epoch 138: - loss: 2938.564209374875
learning rate: 0.0002498370564584527
epoch 139...
epoch 139: - loss: 2937.063913532045
learning rate: 0.0002473386858938682
epoch 140...
epoch 140: - loss: 2939.9155032889475
learning rate: 0.0002448652990349295
testing...
====> Test set loss: 91.4187
epoch 141...
epoch 141: - loss: 2935.55224531275
learning rate: 0.00024241664604458018
epoch 142...
epoch 142: - loss: 2936.719714847499
learning rate: 0.00023999247958413438
epoch 143...
epoch 143: - loss: 2937.336689681177
learning rate: 0.00023759255478829304
epoch 144...
epoch 144: - loss: 2931.9813811142935
learning rate: 0.00023521662924041014
epoch 145...
epoch 145: - loss: 2932.97714590706
learning rate: 0.00023286446294800602
epoch 146...
epoch 146: - loss: 2932.372635756558
learning rate: 0.00023053581831852593
epoch 147...
epoch 147: - loss: 2931.2676816856106
learning rate: 0.0002282304601353407
epoch 148...
epoch 148: - loss: 2927.221345809966
learning rate: 0.00022594815553398729
epoch 149...
epoch 149: - loss: 2930.983648826126
learning rate: 0.0002236886739786474
epoch 150...
epoch 150: - loss: 2927.881882641305
learning rate: 0.0002214517872388609
epoch 151...
epoch 151: - loss: 2927.0540873795385
learning rate: 0.00021923726936647233
epoch 152...
epoch 152: - loss: 2928.287831331474
learning rate: 0.00021704489667280757
epoch 153...
epoch 153: - loss: 2931.0104061231655
learning rate: 0.0002148744477060795
epoch 154...
epoch 154: - loss: 2927.69384765625
learning rate: 0.00021272570322901873
epoch 155...
epoch 155: - loss: 2922.501885646593
learning rate: 0.0002105984461967285
epoch 156...
epoch 156: - loss: 2922.7064137913367
learning rate: 0.00020849246173476125
epoch 157...
epoch 157: - loss: 2923.086724904281
learning rate: 0.00020640753711741362
epoch 158...
epoch 158: - loss: 2927.1003649144773
learning rate: 0.0002043434617462395
epoch 159...
epoch 159: - loss: 2923.988602865833
learning rate: 0.0002023000271287771
epoch 160...
epoch 160: - loss: 2919.1790662925364
learning rate: 0.0002002770268574893
testing...
====> Test set loss: 92.3060
epoch 161...
epoch 161: - loss: 2923.4920347363845
learning rate: 0.00019827425658891444
epoch 162...
epoch 162: - loss: 2922.872527041347
learning rate: 0.00019629151402302528
epoch 163...
epoch 163: - loss: 2918.9710395798343
learning rate: 0.00019432859888279504
epoch 164...
epoch 164: - loss: 2923.429141268544
learning rate: 0.00019238531289396708
epoch 165...
epoch 165: - loss: 2918.753260987734
learning rate: 0.0001904614597650274
epoch 166...
epoch 166: - loss: 2919.961259350133
learning rate: 0.00018855684516737713
epoch 167...
epoch 167: - loss: 2920.8936588729107
learning rate: 0.00018667127671570335
epoch 168...
epoch 168: - loss: 2914.4812716180822
learning rate: 0.0001848045639485463
epoch 169...
epoch 169: - loss: 2916.16181454747
learning rate: 0.00018295651830906086
epoch 170...
epoch 170: - loss: 2920.18505968715
learning rate: 0.00018112695312597025
epoch 171...
epoch 171: - loss: 2915.0216525243172
learning rate: 0.00017931568359471053
epoch 172...
epoch 172: - loss: 2918.053546771283
learning rate: 0.00017752252675876342
epoch 173...
epoch 173: - loss: 2916.256279240643
learning rate: 0.0001757473014911758
epoch 174...
epoch 174: - loss: 2912.1098170460455
learning rate: 0.000173989828476264
epoch 175...
epoch 175: - loss: 2916.145633475413
learning rate: 0.0001722499301915014
epoch 176...
epoch 176: - loss: 2914.659334872216
learning rate: 0.00017052743088958637
epoch 177...
epoch 177: - loss: 2913.106105733665
learning rate: 0.0001688221565806905
epoch 178...
epoch 178: - loss: 2910.806072525542
learning rate: 0.0001671339350148836
epoch 179...
epoch 179: - loss: 2912.811962984345
learning rate: 0.00016546259566473475
epoch 180...
epoch 180: - loss: 2913.051797096804
learning rate: 0.00016380796970808743
testing...
====> Test set loss: 93.0714
epoch 181...
epoch 181: - loss: 2910.0962054642514
learning rate: 0.00016216989001100656
epoch 182...
epoch 182: - loss: 2910.9462670382977
learning rate: 0.00016054819111089647
epoch 183...
epoch 183: - loss: 2909.7625066228807
learning rate: 0.00015894270919978752
epoch 184...
epoch 184: - loss: 2906.2650434673405
learning rate: 0.00015735328210778963
epoch 185...
epoch 185: - loss: 2906.060393877084
learning rate: 0.00015577974928671174
epoch 186...
epoch 186: - loss: 2910.2910199986004
learning rate: 0.0001542219517938446
epoch 187...
epoch 187: - loss: 2908.8178464141474
learning rate: 0.00015267973227590616
epoch 188...
epoch 188: - loss: 2909.347414061875
learning rate: 0.00015115293495314712
epoch 189...
epoch 189: - loss: 2904.9892228236963
learning rate: 0.00014964140560361563
epoch 190...
epoch 190: - loss: 2904.981221634077
learning rate: 0.00014814499154757946
epoch 191...
epoch 191: - loss: 2907.2630637883376
learning rate: 0.0001466635416321037
epoch 192...
epoch 192: - loss: 2905.8020667761316
learning rate: 0.00014519690621578264
epoch 193...
epoch 193: - loss: 2903.7393202144062
learning rate: 0.0001437449371536248
epoch 194...
epoch 194: - loss: 2907.3798026818918
learning rate: 0.00014230748778208858
epoch 195...
epoch 195: - loss: 2907.072254534799
learning rate: 0.0001408844129042677
epoch 196...
epoch 196: - loss: 2903.405999611374
learning rate: 0.00013947556877522499
epoch 197...
epoch 197: - loss: 2901.398379705994
learning rate: 0.00013808081308747276
epoch 198...
epoch 198: - loss: 2903.7683438174786
learning rate: 0.000136700004956598
epoch 199...
epoch 199: - loss: 2899.9111178172984
learning rate: 0.00013533300490703204
Training Finished

Testing on training data...
testing...
====> Test on training set loss: 429.9286
Testing Finished

