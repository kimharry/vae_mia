{'async_loading': True,
 'batch_size': 32,
 'cuda': True,
 'dataloader_workers': 4,
 'dataset': 'CIFAR10',
 'experiment_dir': 'VAE_CIFAR10_mse_loss_ld_512',
 'generate_result': True,
 'input_shape': {'channels': 3, 'hight': 32, 'width': 32},
 'learning_rate': 0.001,
 'learning_rate_decay': 0.99,
 'loss': 'mse',
 'num_classes': 10,
 'num_epochs': 800,
 'pin_memory': True,
 'resume': True,
 'resume_from': '240306_2.pth.tar',
 'seed': 1,
 'shuffle': True,
 'test_every': 20,
 'to_test': True,
 'to_train': True,
 'weight_decay': 0.0005}


Experiment directories created!
Loading Data...
Files already downloaded and verified
Files already downloaded and verified
Data loaded successfully

Loading checkpoint '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/240306_2.pth.tar'
No checkpoint exists from '/home/work/main/vae_mia/utils/../experiments/VAE_CIFAR10_mse_loss_ld_512/checkpoints/'. Skipping...

Training...
epoch 0...
epoch 0: - loss: 6514.397611826716
learning rate: 0.001
testing...
====> Test set loss: 152.6092
epoch 1...
epoch 1: - loss: 4579.647688052323
learning rate: 0.00099
epoch 2...
epoch 2: - loss: 4253.749088729107
learning rate: 0.0009801
epoch 3...
epoch 3: - loss: 4091.85478615593
learning rate: 0.0009702990000000001
epoch 4...
epoch 4: - loss: 3907.3145559046106
learning rate: 0.0009605960099999999
epoch 5...
epoch 5: - loss: 3739.64511840586
learning rate: 0.0009509900498999999
epoch 6...
epoch 6: - loss: 3655.892891774632
learning rate: 0.000941480149401
epoch 7...
epoch 7: - loss: 3606.168025528706
learning rate: 0.0009320653479069899
epoch 8...
epoch 8: - loss: 3545.309533605496
learning rate: 0.0009227446944279201
epoch 9...
epoch 9: - loss: 3488.6061659487714
learning rate: 0.0009135172474836409
epoch 10...
epoch 10: - loss: 3451.490285608605
learning rate: 0.0009043820750088044
epoch 11...
epoch 11: - loss: 3424.9773996539857
learning rate: 0.0008953382542587164
epoch 12...
epoch 12: - loss: 3419.2089214263938
learning rate: 0.0008863848717161292
epoch 13...
epoch 13: - loss: 3395.2512077385236
learning rate: 0.0008775210229989679
epoch 14...
epoch 14: - loss: 3377.5988593806233
learning rate: 0.0008687458127689783
epoch 15...
epoch 15: - loss: 3365.0026614920725
learning rate: 0.0008600583546412885
epoch 16...
epoch 16: - loss: 3344.2301826696707
learning rate: 0.0008514577710948756
epoch 17...
epoch 17: - loss: 3342.632919809411
learning rate: 0.0008429431933839268
epoch 18...
epoch 18: - loss: 3327.5940752084334
learning rate: 0.0008345137614500875
epoch 19...
epoch 19: - loss: 3316.147834177438
learning rate: 0.0008261686238355867
epoch 20...
epoch 20: - loss: 3301.250976953
learning rate: 0.0008179069375972307
testing...
====> Test set loss: 98.7959
epoch 21...
epoch 21: - loss: 3282.3391664667306
learning rate: 0.0008097278682212584
epoch 22...
epoch 22: - loss: 3267.250701962872
learning rate: 0.0008016305895390458
epoch 23...
epoch 23: - loss: 3248.991395800219
learning rate: 0.0007936142836436554
epoch 24...
epoch 24: - loss: 3238.245745892564
learning rate: 0.0007856781408072188
epoch 25...
epoch 25: - loss: 3226.287332194323
learning rate: 0.0007778213593991467
epoch 26...
epoch 26: - loss: 3212.701080419891
learning rate: 0.0007700431458051552
epoch 27...
epoch 27: - loss: 3203.17304868692
learning rate: 0.0007623427143471036
epoch 28...
epoch 28: - loss: 3191.834015068303
learning rate: 0.0007547192872036326
epoch 29...
epoch 29: - loss: 3177.4453388197026
learning rate: 0.0007471720943315962
epoch 30...
epoch 30: - loss: 3168.030574044431
learning rate: 0.0007397003733882802
epoch 31...
epoch 31: - loss: 3159.552379722864
learning rate: 0.0007323033696543975
epoch 32...
epoch 32: - loss: 3151.784845958668
learning rate: 0.0007249803359578534
epoch 33...
epoch 33: - loss: 3155.3589754403592
learning rate: 0.0007177305325982749
epoch 34...
epoch 34: - loss: 3150.187763587527
learning rate: 0.0007105532272722921
epoch 35...
epoch 35: - loss: 3138.4182062521245
learning rate: 0.0007034476949995691
epoch 36...
epoch 36: - loss: 3135.1124683070166
learning rate: 0.0006964132180495735
epoch 37...
epoch 37: - loss: 3138.279677143939
learning rate: 0.0006894490858690778
epoch 38...
epoch 38: - loss: 3133.9712841890596
learning rate: 0.0006825545950103869
epoch 39...
epoch 39: - loss: 3122.454803681572
learning rate: 0.0006757290490602831
epoch 40...
epoch 40: - loss: 3123.5081184958312
learning rate: 0.0006689717585696802
testing...
====> Test set loss: 94.0448
epoch 41...
epoch 41: - loss: 3120.721314491863
learning rate: 0.0006622820409839835
epoch 42...
epoch 42: - loss: 3114.403213784089
learning rate: 0.0006556592205741436
epoch 43...
epoch 43: - loss: 3114.3092230017646
learning rate: 0.0006491026283684022
epoch 44...
epoch 44: - loss: 3107.938108477162
learning rate: 0.0006426116020847181
epoch 45...
epoch 45: - loss: 3105.490370581414
learning rate: 0.000636185486063871
epoch 46...
epoch 46: - loss: 3103.646550135207
learning rate: 0.0006298236312032323
epoch 47...
epoch 47: - loss: 3102.6977006420448
learning rate: 0.0006235253948911999
epoch 48...
epoch 48: - loss: 3097.871571253449
learning rate: 0.0006172901409422879
epoch 49...
epoch 49: - loss: 3097.3707198071615
learning rate: 0.000611117239532865
epoch 50...
epoch 50: - loss: 3090.039656684861
learning rate: 0.0006050060671375364
epoch 51...
epoch 51: - loss: 3088.3132242994743
learning rate: 0.000598956006466161
epoch 52...
epoch 52: - loss: 3083.870042523892
learning rate: 0.0005929664464014994
epoch 53...
epoch 53: - loss: 3085.9395747267126
learning rate: 0.0005870367819374845
epoch 54...
epoch 54: - loss: 3082.2420591816867
learning rate: 0.0005811664141181095
epoch 55...
epoch 55: - loss: 3075.2448554743733
learning rate: 0.0005753547499769285
epoch 56...
epoch 56: - loss: 3074.115536309631
learning rate: 0.0005696012024771592
epoch 57...
epoch 57: - loss: 3079.192148434376
learning rate: 0.0005639051904523875
epoch 58...
epoch 58: - loss: 3073.075749353957
learning rate: 0.0005582661385478637
epoch 59...
epoch 59: - loss: 3072.212628599473
learning rate: 0.0005526834771623851
epoch 60...
epoch 60: - loss: 3067.6246574533648
learning rate: 0.0005471566423907613
testing...
====> Test set loss: 94.0347
epoch 61...
epoch 61: - loss: 3061.9378965918404
learning rate: 0.0005416850759668536
epoch 62...
epoch 62: - loss: 3063.0994678577854
learning rate: 0.0005362682252071849
epoch 63...
epoch 63: - loss: 3057.941787534239
learning rate: 0.0005309055429551132
epoch 64...
epoch 64: - loss: 3055.002702885077
learning rate: 0.000525596487525562
epoch 65...
epoch 65: - loss: 3054.0454356949526
learning rate: 0.0005203405226503064
epoch 66...
epoch 66: - loss: 3053.105050758757
learning rate: 0.0005151371174238034
epoch 67...
epoch 67: - loss: 3048.7700401496522
learning rate: 0.0005099857462495653
epoch 68...
epoch 68: - loss: 3048.5548719722187
learning rate: 0.0005048858887870696
epoch 69...
epoch 69: - loss: 3045.307685603107
learning rate: 0.0004998370298991989
epoch 70...
epoch 70: - loss: 3041.5958538580153
learning rate: 0.000494838659600207
epoch 71...
epoch 71: - loss: 3041.009423156465
learning rate: 0.000489890273004205
epoch 72...
epoch 72: - loss: 3037.5111741586443
learning rate: 0.00048499137027416283
epoch 73...
epoch 73: - loss: 3038.2894198075364
learning rate: 0.0004801414565714212
epoch 74...
epoch 74: - loss: 3035.281376990613
learning rate: 0.00047534004200570695
epoch 75...
epoch 75: - loss: 3036.256472147663
learning rate: 0.0004705866415856499
epoch 76...
epoch 76: - loss: 3031.0537296034017
learning rate: 0.0004658807751697934
epoch 77...
epoch 77: - loss: 3025.914053206099
learning rate: 0.00046122196741809544
epoch 78...
epoch 78: - loss: 3027.969511006478
learning rate: 0.0004566097477439145
epoch 79...
epoch 79: - loss: 3025.0441364232197
learning rate: 0.0004520436502664754
epoch 80...
epoch 80: - loss: 3020.129216775632
learning rate: 0.0004475232137638106
testing...
====> Test set loss: 93.0131
epoch 81...
epoch 81: - loss: 3020.097479041082
learning rate: 0.0004430479816261725
epoch 82...
epoch 82: - loss: 3020.03740506163
learning rate: 0.00043861750180991077
epoch 83...
epoch 83: - loss: 3019.0166648235063
learning rate: 0.00043423132679181164
epoch 84...
epoch 84: - loss: 3019.462452405855
learning rate: 0.0004298890135238935
epoch 85...
epoch 85: - loss: 3013.556395000475
learning rate: 0.0004255901233886546
epoch 86...
epoch 86: - loss: 3019.0534617203743
learning rate: 0.00042133422215476804
epoch 87...
epoch 87: - loss: 3013.8018886300133
learning rate: 0.00041712087993322035
epoch 88...
epoch 88: - loss: 3012.3290945334993
learning rate: 0.0004129496711338882
epoch 89...
epoch 89: - loss: 3011.69257946832
learning rate: 0.00040882017442254927
epoch 90...
epoch 90: - loss: 3007.974131871551
learning rate: 0.0004047319726783238
epoch 91...
epoch 91: - loss: 3006.783580582339
learning rate: 0.00040068465295154055
epoch 92...
epoch 92: - loss: 3002.967891056112
learning rate: 0.0003966778064220251
epoch 93...
epoch 93: - loss: 3007.1051904796714
learning rate: 0.0003927110283578049
epoch 94...
epoch 94: - loss: 3002.438420174294
learning rate: 0.0003887839180742268
epoch 95...
epoch 95: - loss: 3006.8175373724157
learning rate: 0.00038489607889348454
epoch 96...
epoch 96: - loss: 3000.278993846969
learning rate: 0.00038104711810454966
epoch 97...
epoch 97: - loss: 2999.2982162895373
learning rate: 0.00037723664692350416
epoch 98...
epoch 98: - loss: 3002.483056593765
learning rate: 0.0003734642804542692
epoch 99...
epoch 99: - loss: 2998.0024540584513
learning rate: 0.00036972963764972643
epoch 100...
epoch 100: - loss: 2999.0881924815308
learning rate: 0.0003660323412732292
testing...
====> Test set loss: 93.2694
epoch 101...
epoch 101: - loss: 2994.751307784634
learning rate: 0.0003623720178604969
epoch 102...
epoch 102: - loss: 2997.128702565179
learning rate: 0.00035874829768189193
epoch 103...
epoch 103: - loss: 2991.775370865698
learning rate: 0.000355160814705073
epoch 104...
epoch 104: - loss: 2988.9109106960773
learning rate: 0.0003516092065580223
epoch 105...
epoch 105: - loss: 2991.882850378504
learning rate: 0.000348093114492442
epoch 106...
epoch 106: - loss: 2987.632404193158
learning rate: 0.0003446121833475176
epoch 107...
epoch 107: - loss: 2989.822970321372
learning rate: 0.00034116606151404246
epoch 108...
epoch 108: - loss: 2986.3280288588903
learning rate: 0.000337754400898902
epoch 109...
epoch 109: - loss: 2985.438060055157
learning rate: 0.000334376856889913
epoch 110...
epoch 110: - loss: 2984.1202484736136
learning rate: 0.00033103308832101386
epoch 111...
epoch 111: - loss: 2987.3278336869703
learning rate: 0.00032772275743780374
epoch 112...
epoch 112: - loss: 2980.4290289607325
learning rate: 0.0003244455298634257
epoch 113...
epoch 113: - loss: 2980.6893405828887
learning rate: 0.0003212010745647914
epoch 114...
epoch 114: - loss: 2979.8288331327726
learning rate: 0.0003179890638191435
epoch 115...
epoch 115: - loss: 2975.1959616672666
learning rate: 0.00031480917318095204
epoch 116...
epoch 116: - loss: 2976.641767446917
learning rate: 0.00031166108144914254
epoch 117...
epoch 117: - loss: 2976.4755315798943
learning rate: 0.0003085444706346511
epoch 118...
epoch 118: - loss: 2969.5031704698245
learning rate: 0.0003054590259283046
epoch 119...
epoch 119: - loss: 2973.6783628457642
learning rate: 0.0003024044356690215
epoch 120...
epoch 120: - loss: 2969.3872817729575
learning rate: 0.0002993803913123313
testing...
====> Test set loss: 93.1465
epoch 121...
epoch 121: - loss: 2969.010977112324
learning rate: 0.000296386587399208
epoch 122...
epoch 122: - loss: 2969.3170946234704
learning rate: 0.00029342272152521593
epoch 123...
epoch 123: - loss: 2965.2677360432162
learning rate: 0.00029048849430996377
epoch 124...
epoch 124: - loss: 2969.326913512676
learning rate: 0.0002875836093668641
epoch 125...
epoch 125: - loss: 2968.330233856416
learning rate: 0.00028470777327319546
epoch 126...
epoch 126: - loss: 2966.0309899269732
learning rate: 0.0002818606955404635
epoch 127...
epoch 127: - loss: 2966.506004875315
learning rate: 0.00027904208858505885
epoch 128...
epoch 128: - loss: 2964.1232861734247
learning rate: 0.0002762516676992083
epoch 129...
epoch 129: - loss: 2969.417244606726
learning rate: 0.00027348915102221624
epoch 130...
epoch 130: - loss: 2965.1014783081914
learning rate: 0.00027075425951199404
epoch 131...
epoch 131: - loss: 2961.1235515572516
learning rate: 0.0002680467169168741
epoch 132...
epoch 132: - loss: 2959.831310152626
learning rate: 0.0002653662497477053
epoch 133...
epoch 133: - loss: 2959.205194884512
learning rate: 0.0002627125872502283
epoch 134...
epoch 134: - loss: 2960.9375952820096
learning rate: 0.000260085461377726
epoch 135...
epoch 135: - loss: 2962.355975072352
learning rate: 0.00025748460676394875
epoch 136...
epoch 136: - loss: 2960.513614861994
learning rate: 0.00025490976069630927
epoch 137...
epoch 137: - loss: 2954.5625028116
learning rate: 0.0002523606630893462
epoch 138...
epoch 138: - loss: 2957.8903277513696
learning rate: 0.0002498370564584527
epoch 139...
epoch 139: - loss: 2961.0725420990284
learning rate: 0.0002473386858938682
epoch 140...
epoch 140: - loss: 2956.8966262827144
learning rate: 0.0002448652990349295
testing...
====> Test set loss: 92.7091
epoch 141...
epoch 141: - loss: 2955.6430457878478
learning rate: 0.00024241664604458018
epoch 142...
epoch 142: - loss: 2957.4766677788107
learning rate: 0.00023999247958413438
epoch 143...
epoch 143: - loss: 2955.3423961363615
learning rate: 0.00023759255478829304
epoch 144...
epoch 144: - loss: 2954.242767783059
learning rate: 0.00023521662924041014
epoch 145...
epoch 145: - loss: 2953.8501780992583
learning rate: 0.00023286446294800602
epoch 146...
epoch 146: - loss: 2951.6141843203923
learning rate: 0.00023053581831852593
epoch 147...
epoch 147: - loss: 2949.508796247701
learning rate: 0.0002282304601353407
epoch 148...
epoch 148: - loss: 2953.2043902201294
learning rate: 0.00022594815553398729
epoch 149...
epoch 149: - loss: 2950.6961871419894
learning rate: 0.0002236886739786474
epoch 150...
epoch 150: - loss: 2948.9538063444697
learning rate: 0.0002214517872388609
epoch 151...
epoch 151: - loss: 2947.785222947407
learning rate: 0.00021923726936647233
epoch 152...
epoch 152: - loss: 2950.7478057802755
learning rate: 0.00021704489667280757
epoch 153...
epoch 153: - loss: 2947.223887028026
learning rate: 0.0002148744477060795
epoch 154...
epoch 154: - loss: 2947.041497658249
learning rate: 0.00021272570322901873
epoch 155...
epoch 155: - loss: 2943.6194675516335
learning rate: 0.0002105984461967285
epoch 156...
epoch 156: - loss: 2944.970624478292
learning rate: 0.00020849246173476125
epoch 157...
epoch 157: - loss: 2944.751492569253
learning rate: 0.00020640753711741362
epoch 158...
epoch 158: - loss: 2943.95654414025
learning rate: 0.0002043434617462395
epoch 159...
epoch 159: - loss: 2945.8523206948776
learning rate: 0.0002023000271287771
epoch 160...
epoch 160: - loss: 2941.2223857115723
learning rate: 0.0002002770268574893
testing...
====> Test set loss: 91.9852
epoch 161...
epoch 161: - loss: 2944.269940025442
learning rate: 0.00019827425658891444
epoch 162...
epoch 162: - loss: 2941.5229451575497
learning rate: 0.00019629151402302528
epoch 163...
epoch 163: - loss: 2943.8443009955563
learning rate: 0.00019432859888279504
epoch 164...
epoch 164: - loss: 2939.176180887741
learning rate: 0.00019238531289396708
epoch 165...
epoch 165: - loss: 2940.9765489105985
learning rate: 0.0001904614597650274
epoch 166...
epoch 166: - loss: 2941.9229234926074
learning rate: 0.00018855684516737713
epoch 167...
epoch 167: - loss: 2939.271650649917
learning rate: 0.00018667127671570335
epoch 168...
epoch 168: - loss: 2936.781034287778
learning rate: 0.0001848045639485463
epoch 169...
epoch 169: - loss: 2937.296358446547
learning rate: 0.00018295651830906086
epoch 170...
epoch 170: - loss: 2937.2979186504067
learning rate: 0.00018112695312597025
epoch 171...
epoch 171: - loss: 2939.2916451110646
learning rate: 0.00017931568359471053
epoch 172...
epoch 172: - loss: 2940.764493721384
learning rate: 0.00017752252675876342
epoch 173...
epoch 173: - loss: 2932.6512858853916
learning rate: 0.0001757473014911758
epoch 174...
epoch 174: - loss: 2936.1583571382157
learning rate: 0.000173989828476264
epoch 175...
epoch 175: - loss: 2933.661474109535
learning rate: 0.0001722499301915014
epoch 176...
epoch 176: - loss: 2935.5908259357007
learning rate: 0.00017052743088958637
epoch 177...
epoch 177: - loss: 2934.8207272891423
learning rate: 0.0001688221565806905
epoch 178...
epoch 178: - loss: 2936.0707353334433
learning rate: 0.0001671339350148836
epoch 179...
epoch 179: - loss: 2932.8481581206515
learning rate: 0.00016546259566473475
epoch 180...
epoch 180: - loss: 2932.637999277731
learning rate: 0.00016380796970808743
testing...
====> Test set loss: 92.6195
epoch 181...
epoch 181: - loss: 2932.46152528066
learning rate: 0.00016216989001100656
epoch 182...
epoch 182: - loss: 2931.612380210208
learning rate: 0.00016054819111089647
epoch 183...
epoch 183: - loss: 2930.6880599770575
learning rate: 0.00015894270919978752
epoch 184...
epoch 184: - loss: 2929.7736797662246
learning rate: 0.00015735328210778963
epoch 185...
epoch 185: - loss: 2931.063785369932
learning rate: 0.00015577974928671174
epoch 186...
epoch 186: - loss: 2930.4521745229026
learning rate: 0.0001542219517938446
epoch 187...
epoch 187: - loss: 2927.5452812131366
learning rate: 0.00015267973227590616
epoch 188...
epoch 188: - loss: 2926.6803443210674
learning rate: 0.00015115293495314712
epoch 189...
epoch 189: - loss: 2928.037439269434
learning rate: 0.00014964140560361563
epoch 190...
epoch 190: - loss: 2923.3371432860235
learning rate: 0.00014814499154757946
epoch 191...
epoch 191: - loss: 2924.447883005563
learning rate: 0.0001466635416321037
epoch 192...
epoch 192: - loss: 2928.466926208613
learning rate: 0.00014519690621578264
epoch 193...
epoch 193: - loss: 2924.705818591176
learning rate: 0.0001437449371536248
epoch 194...
epoch 194: - loss: 2924.715061102322
learning rate: 0.00014230748778208858
epoch 195...
epoch 195: - loss: 2926.160704043456
learning rate: 0.0001408844129042677
epoch 196...
epoch 196: - loss: 2923.3336585417665
learning rate: 0.00013947556877522499
epoch 197...
epoch 197: - loss: 2924.9976253692566
learning rate: 0.00013808081308747276
epoch 198...
epoch 198: - loss: 2925.712196315929
learning rate: 0.000136700004956598
epoch 199...
epoch 199: - loss: 2923.2912069700196
learning rate: 0.00013533300490703204
epoch 200...
epoch 200: - loss: 2922.116173371396
learning rate: 0.00013397967485796172
testing...
====> Test set loss: 92.8524
epoch 201...
epoch 201: - loss: 2923.843595518184
learning rate: 0.0001326398781093821
epoch 202...
epoch 202: - loss: 2921.5391686379107
learning rate: 0.00013131347932828828
epoch 203...
epoch 203: - loss: 2917.315350728392
learning rate: 0.00013000034453500539
epoch 204...
epoch 204: - loss: 2919.4373003763794
learning rate: 0.00012870034108965534
epoch 205...
epoch 205: - loss: 2915.080455582339
learning rate: 0.00012741333767875878
epoch 206...
epoch 206: - loss: 2920.783181256998
learning rate: 0.00012613920430197117
epoch 207...
epoch 207: - loss: 2920.2374788505176
learning rate: 0.00012487781225895147
epoch 208...
epoch 208: - loss: 2919.87001971869
learning rate: 0.00012362903413636197
epoch 209...
epoch 209: - loss: 2921.173847884302
learning rate: 0.00012239274379499833
epoch 210...
epoch 210: - loss: 2917.393864588332
learning rate: 0.00012116881635704836
epoch 211...
epoch 211: - loss: 2919.252117447417
learning rate: 0.00011995712819347788
epoch 212...
epoch 212: - loss: 2918.5384223923343
learning rate: 0.00011875755691154309
epoch 213...
epoch 213: - loss: 2918.684123580454
learning rate: 0.00011756998134242766
epoch 214...
epoch 214: - loss: 2919.0730400646794
learning rate: 0.00011639428152900338
epoch 215...
epoch 215: - loss: 2916.200527237534
learning rate: 0.00011523033871371335
epoch 216...
epoch 216: - loss: 2918.863983134772
learning rate: 0.0001140780353265762
epoch 217...
epoch 217: - loss: 2913.8441164452374
learning rate: 0.00011293725497331044
epoch 218...
epoch 218: - loss: 2916.743791127464
learning rate: 0.00011180788242357735
epoch 219...
epoch 219: - loss: 2915.066904059451
learning rate: 0.00011068980359934157
epoch 220...
epoch 220: - loss: 2914.1408772630257
learning rate: 0.00010958290556334815
testing...
====> Test set loss: 94.4886
epoch 221...
epoch 221: - loss: 2916.6530506331724
learning rate: 0.00010848707650771467
epoch 222...
epoch 222: - loss: 2916.1838910767306
learning rate: 0.00010740220574263753
epoch 223...
epoch 223: - loss: 2915.1378526840163
learning rate: 0.00010632818368521114
epoch 224...
epoch 224: - loss: 2911.0019296949977
learning rate: 0.00010526490184835903
epoch 225...
epoch 225: - loss: 2913.888644539997
learning rate: 0.00010421225282987544
epoch 226...
epoch 226: - loss: 2911.0288249166515
learning rate: 0.0001031701303015767
epoch 227...
epoch 227: - loss: 2915.0206701043167
learning rate: 0.00010213842899856092
epoch 228...
epoch 228: - loss: 2908.7620550486345
learning rate: 0.00010111704470857532
epoch 229...
epoch 229: - loss: 2909.7781036630777
learning rate: 0.00010010587426148956
epoch 230...
epoch 230: - loss: 2910.4213124456423
learning rate: 9.910481551887467e-05
epoch 231...
epoch 231: - loss: 2908.7294792228986
learning rate: 9.811376736368591e-05
epoch 232...
epoch 232: - loss: 2914.120393505328
learning rate: 9.713262969004905e-05
epoch 233...
epoch 233: - loss: 2910.04355418766
learning rate: 9.616130339314857e-05
epoch 234...
epoch 234: - loss: 2910.3167313803333
learning rate: 9.519969035921708e-05
epoch 235...
epoch 235: - loss: 2908.2925256105545
learning rate: 9.424769345562491e-05
epoch 236...
epoch 236: - loss: 2908.512238427453
learning rate: 9.330521652106865e-05
epoch 237...
epoch 237: - loss: 2911.0698000077477
learning rate: 9.237216435585796e-05
epoch 238...
epoch 238: - loss: 2910.034187966101
learning rate: 9.144844271229938e-05
epoch 239...
epoch 239: - loss: 2910.0725028147244
learning rate: 9.05339582851764e-05
epoch 240...
epoch 240: - loss: 2905.580119361804
learning rate: 8.962861870232462e-05
testing...
====> Test set loss: 93.4233
epoch 241...
epoch 241: - loss: 2908.4278460580113
learning rate: 8.873233251530139e-05
epoch 242...
epoch 242: - loss: 2907.7987451827917
learning rate: 8.784500919014835e-05
epoch 243...
epoch 243: - loss: 2906.031853088262
learning rate: 8.696655909824689e-05
epoch 244...
epoch 244: - loss: 2902.824870572667
learning rate: 8.60968935072644e-05
epoch 245...
epoch 245: - loss: 2908.0001201178125
learning rate: 8.523592457219176e-05
epoch 246...
epoch 246: - loss: 2907.41982698349
learning rate: 8.438356532646985e-05
epoch 247...
epoch 247: - loss: 2907.9879552605667
learning rate: 8.353972967320516e-05
epoch 248...
epoch 248: - loss: 2905.9434815234126
learning rate: 8.270433237647309e-05
epoch 249...
epoch 249: - loss: 2906.6183744639216
learning rate: 8.187728905270835e-05
epoch 250...
epoch 250: - loss: 2905.0421512772164
learning rate: 8.105851616218128e-05
epoch 251...
epoch 251: - loss: 2903.2246633421055
learning rate: 8.024793100055946e-05
epoch 252...
epoch 252: - loss: 2904.9957373796633
learning rate: 7.944545169055387e-05
epoch 253...
epoch 253: - loss: 2904.6038106087303
learning rate: 7.865099717364833e-05
epoch 254...
epoch 254: - loss: 2901.0939669618224
learning rate: 7.786448720191184e-05
epoch 255...
epoch 255: - loss: 2903.740856285364
learning rate: 7.708584232989272e-05
epoch 256...
epoch 256: - loss: 2902.8048650994183
learning rate: 7.63149839065938e-05
epoch 257...
epoch 257: - loss: 2904.7134101462534
learning rate: 7.555183406752786e-05
epoch 258...
epoch 258: - loss: 2904.000058653106
learning rate: 7.479631572685259e-05
epoch 259...
epoch 259: - loss: 2904.215177393234
learning rate: 7.404835256958406e-05
epoch 260...
epoch 260: - loss: 2902.2490461646025
learning rate: 7.330786904388821e-05
testing...
====> Test set loss: 92.7609
epoch 261...
epoch 261: - loss: 2901.126348709038
learning rate: 7.257479035344933e-05
epoch 262...
epoch 262: - loss: 2902.7152696293438
learning rate: 7.184904244991484e-05
epoch 263...
epoch 263: - loss: 2902.772687739923
learning rate: 7.113055202541569e-05
epoch 264...
epoch 264: - loss: 2901.4296133049925
learning rate: 7.041924650516153e-05
epoch 265...
epoch 265: - loss: 2903.871229565914
learning rate: 6.971505404010992e-05
epoch 266...
epoch 266: - loss: 2900.708700169071
learning rate: 6.901790349970881e-05
epoch 267...
epoch 267: - loss: 2900.2278750487344
learning rate: 6.832772446471172e-05
epoch 268...
epoch 268: - loss: 2897.9922209268034
learning rate: 6.76444472200646e-05
epoch 269...
epoch 269: - loss: 2896.713835010297
learning rate: 6.696800274786396e-05
epoch 270...
epoch 270: - loss: 2900.676435806167
learning rate: 6.629832272038532e-05
epoch 271...
epoch 271: - loss: 2899.9385524757076
learning rate: 6.563533949318147e-05
epoch 272...
epoch 272: - loss: 2900.5958704933173
learning rate: 6.497898609824965e-05
epoch 273...
epoch 273: - loss: 2897.1877392984247
learning rate: 6.432919623726716e-05
epoch 274...
epoch 274: - loss: 2899.4989484614925
learning rate: 6.368590427489449e-05
epoch 275...
epoch 275: - loss: 2899.8898311915186
learning rate: 6.304904523214554e-05
epoch 276...
epoch 276: - loss: 2897.900748713537
learning rate: 6.241855477982409e-05
epoch 277...
epoch 277: - loss: 2900.2108061357867
learning rate: 6.179436923202584e-05
epoch 278...
epoch 278: - loss: 2899.117890087672
learning rate: 6.117642553970558e-05
epoch 279...
epoch 279: - loss: 2894.7026817043547
learning rate: 6.0564661284308526e-05
epoch 280...
epoch 280: - loss: 2892.9072604579032
learning rate: 5.995901467146544e-05
testing...
====> Test set loss: 94.3700
epoch 281...
epoch 281: - loss: 2896.0781226569998
learning rate: 5.935942452475079e-05
epoch 282...
epoch 282: - loss: 2896.4334798801883
learning rate: 5.8765830279503276e-05
epoch 283...
epoch 283: - loss: 2896.922207549834
learning rate: 5.817817197670824e-05
epoch 284...
epoch 284: - loss: 2898.0345720619403
learning rate: 5.759639025694116e-05
epoch 285...
epoch 285: - loss: 2900.4451738724856
learning rate: 5.702042635437175e-05
epoch 286...
epoch 286: - loss: 2893.7710238973527
learning rate: 5.645022209082803e-05
epoch 287...
epoch 287: - loss: 2894.265730122611
learning rate: 5.588571986991975e-05
epoch 288...
epoch 288: - loss: 2896.066521057012
learning rate: 5.532686267122055e-05
epoch 289...
epoch 289: - loss: 2895.740605193838
learning rate: 5.4773594044508346e-05
epoch 290...
epoch 290: - loss: 2893.6197097397585
learning rate: 5.422585810406326e-05
epoch 291...
epoch 291: - loss: 2893.6788215271113
learning rate: 5.368359952302263e-05
epoch 292...
epoch 292: - loss: 2896.232006226757
learning rate: 5.31467635277924e-05
epoch 293...
epoch 293: - loss: 2895.188155415267
learning rate: 5.261529589251448e-05
epoch 294...
epoch 294: - loss: 2893.6608908586754
learning rate: 5.208914293358933e-05
epoch 295...
epoch 295: - loss: 2896.1072213141792
learning rate: 5.156825150425344e-05
epoch 296...
epoch 296: - loss: 2895.3127174304223
learning rate: 5.10525689892109e-05
epoch 297...
epoch 297: - loss: 2892.3039967835293
learning rate: 5.054204329931879e-05
epoch 298...
epoch 298: - loss: 2891.4525388594398
learning rate: 5.003662286632561e-05
epoch 299...
epoch 299: - loss: 2889.5956104983907
learning rate: 4.953625663766235e-05
epoch 300...
epoch 300: - loss: 2893.665615284359
learning rate: 4.904089407128572e-05
testing...
====> Test set loss: 93.0045
epoch 301...
epoch 301: - loss: 2891.7553436025473
learning rate: 4.855048513057287e-05
epoch 302...
epoch 302: - loss: 2892.5972227168554
learning rate: 4.8064980279267135e-05
epoch 303...
epoch 303: - loss: 2894.077472864933
learning rate: 4.7584330476474464e-05
epoch 304...
epoch 304: - loss: 2895.7484205054384
learning rate: 4.710848717170972e-05
epoch 305...
epoch 305: - loss: 2893.0529564914227
learning rate: 4.663740229999262e-05
epoch 306...
epoch 306: - loss: 2893.9853670263014
learning rate: 4.6171028276992695e-05
epoch 307...
epoch 307: - loss: 2891.014667025302
learning rate: 4.570931799422277e-05
epoch 308...
epoch 308: - loss: 2892.702463492932
learning rate: 4.525222481428054e-05
epoch 309...
epoch 309: - loss: 2891.339765571892
learning rate: 4.4799702566137736e-05
epoch 310...
epoch 310: - loss: 2891.459055289807
learning rate: 4.435170554047636e-05
epoch 311...
epoch 311: - loss: 2892.653163175284
learning rate: 4.390818848507159e-05
epoch 312...
epoch 312: - loss: 2893.383738141295
learning rate: 4.346910660022087e-05
epoch 313...
epoch 313: - loss: 2890.9607253803783
learning rate: 4.303441553421867e-05
epoch 314...
epoch 314: - loss: 2893.191237944483
learning rate: 4.260407137887648e-05
epoch 315...
epoch 315: - loss: 2889.1051774369703
learning rate: 4.217803066508771e-05
epoch 316...
epoch 316: - loss: 2893.113269534999
learning rate: 4.175625035843684e-05
epoch 317...
epoch 317: - loss: 2891.144095373855
learning rate: 4.133868785485247e-05
epoch 318...
epoch 318: - loss: 2892.2334245229026
learning rate: 4.0925300976303944e-05
epoch 319...
epoch 319: - loss: 2889.120908418681
learning rate: 4.0516047966540905e-05
epoch 320...
epoch 320: - loss: 2889.5341737518993
learning rate: 4.0110887486875494e-05
testing...
====> Test set loss: 93.6098
epoch 321...
epoch 321: - loss: 2890.254677878079
learning rate: 3.970977861200674e-05
epoch 322...
epoch 322: - loss: 2886.978662140615
learning rate: 3.9312680825886674e-05
epoch 323...
epoch 323: - loss: 2890.491036930682
learning rate: 3.8919554017627806e-05
epoch 324...
epoch 324: - loss: 2892.3071523362523
learning rate: 3.8530358477451525e-05
epoch 325...
epoch 325: - loss: 2890.57148384392
learning rate: 3.8145054892677014e-05
epoch 326...
epoch 326: - loss: 2891.2075157043496
learning rate: 3.7763604343750246e-05
epoch 327...
epoch 327: - loss: 2890.960814414387
learning rate: 3.7385968300312736e-05
epoch 328...
epoch 328: - loss: 2890.6115297011206
learning rate: 3.701210861730961e-05
epoch 329...
epoch 329: - loss: 2890.7123606383457
learning rate: 3.664198753113651e-05
epoch 330...
epoch 330: - loss: 2891.1610979798966
learning rate: 3.6275567655825144e-05
epoch 331...
epoch 331: - loss: 2885.7742729357856
learning rate: 3.59128119792669e-05
epoch 332...
epoch 332: - loss: 2887.6937235553373
learning rate: 3.5553683859474226e-05
epoch 333...
epoch 333: - loss: 2887.3657752175554
learning rate: 3.5198147020879484e-05
epoch 334...
epoch 334: - loss: 2890.7952402887327
learning rate: 3.484616555067069e-05
epoch 335...
epoch 335: - loss: 2885.882678089886
learning rate: 3.449770389516398e-05
epoch 336...
epoch 336: - loss: 2886.8825341515717
learning rate: 3.415272685621234e-05
epoch 337...
epoch 337: - loss: 2892.081718537568
learning rate: 3.381119958765022e-05
epoch 338...
epoch 338: - loss: 2886.3784339011518
learning rate: 3.347308759177372e-05
epoch 339...
epoch 339: - loss: 2888.266728865513
learning rate: 3.313835671585598e-05
epoch 340...
epoch 340: - loss: 2888.598860161623
learning rate: 3.280697314869742e-05
testing...
====> Test set loss: 93.1139
epoch 341...
epoch 341: - loss: 2889.5001224608127
learning rate: 3.247890341721044e-05
epoch 342...
epoch 342: - loss: 2886.142500415492
learning rate: 3.2154114383038344e-05
epoch 343...
epoch 343: - loss: 2887.0422705359283
learning rate: 3.1832573239207956e-05
epoch 344...
epoch 344: - loss: 2885.378958655105
learning rate: 3.1514247506815875e-05
epoch 345...
epoch 345: - loss: 2887.30781571772
learning rate: 3.1199105031747714e-05
epoch 346...
epoch 346: - loss: 2883.82157881353
learning rate: 3.088711398143024e-05
epoch 347...
epoch 347: - loss: 2887.502040128409
learning rate: 3.0578242841615934e-05
epoch 348...
epoch 348: - loss: 2883.3914983142895
learning rate: 3.0272460413199778e-05
epoch 349...
epoch 349: - loss: 2886.7182481293485
learning rate: 2.996973580906778e-05
epoch 350...
epoch 350: - loss: 2886.969694385297
learning rate: 2.96700384509771e-05
epoch 351...
epoch 351: - loss: 2886.203846878374
learning rate: 2.9373338066467332e-05
epoch 352...
epoch 352: - loss: 2884.357732322532
learning rate: 2.9079604685802658e-05
epoch 353...
epoch 353: - loss: 2887.2916458920645
learning rate: 2.878880863894463e-05
epoch 354...
epoch 354: - loss: 2884.2408334020615
learning rate: 2.8500920552555182e-05
epoch 355...
epoch 355: - loss: 2888.780878790662
learning rate: 2.821591134702963e-05
epoch 356...
epoch 356: - loss: 2884.2025536984415
learning rate: 2.7933752233559336e-05
epoch 357...
epoch 357: - loss: 2886.9528853110755
learning rate: 2.7654414711223742e-05
epoch 358...
epoch 358: - loss: 2883.0221027708635
learning rate: 2.7377870564111504e-05
epoch 359...
epoch 359: - loss: 2890.652370225903
learning rate: 2.7104091858470388e-05
epoch 360...
epoch 360: - loss: 2883.4832252897822
learning rate: 2.6833050939885684e-05
testing...
====> Test set loss: 91.2327
epoch 361...
epoch 361: - loss: 2886.111310786798
learning rate: 2.6564720430486828e-05
epoch 362...
epoch 362: - loss: 2885.8549429807463
learning rate: 2.6299073226181957e-05
epoch 363...
epoch 363: - loss: 2885.2602488297493
learning rate: 2.6036082493920138e-05
epoch 364...
epoch 364: - loss: 2885.1350019556244
learning rate: 2.5775721668980935e-05
epoch 365...
epoch 365: - loss: 2884.0587440925156
learning rate: 2.5517964452291125e-05
epoch 366...
epoch 366: - loss: 2882.324601908639
learning rate: 2.5262784807768214e-05
epoch 367...
epoch 367: - loss: 2885.0737456201514
learning rate: 2.5010156959690534e-05
epoch 368...
epoch 368: - loss: 2884.5094970390724
learning rate: 2.4760055390093628e-05
epoch 369...
epoch 369: - loss: 2886.4301192368443
learning rate: 2.451245483619269e-05
epoch 370...
epoch 370: - loss: 2884.2070268763996
learning rate: 2.4267330287830763e-05
epoch 371...
epoch 371: - loss: 2885.4132173017133
learning rate: 2.4024656984952456e-05
epoch 372...
epoch 372: - loss: 2883.630438259757
learning rate: 2.3784410415102932e-05
epoch 373...
epoch 373: - loss: 2884.909131265495
learning rate: 2.3546566310951903e-05
epoch 374...
epoch 374: - loss: 2883.50087542299
learning rate: 2.3311100647842383e-05
epoch 375...
epoch 375: - loss: 2884.265594540997
learning rate: 2.307798964136396e-05
epoch 376...
epoch 376: - loss: 2883.9829449888534
learning rate: 2.2847209744950317e-05
epoch 377...
epoch 377: - loss: 2886.353739850123
learning rate: 2.2618737647500813e-05
epoch 378...
epoch 378: - loss: 2882.9462900778003
learning rate: 2.2392550271025806e-05
epoch 379...
epoch 379: - loss: 2882.8488726576247
learning rate: 2.216862476831555e-05
epoch 380...
epoch 380: - loss: 2884.646880654441
learning rate: 2.1946938520632395e-05
testing...
====> Test set loss: 93.4564
epoch 381...
epoch 381: - loss: 2884.4935990795448
learning rate: 2.172746913542607e-05
epoch 382...
epoch 382: - loss: 2882.0458939857995
learning rate: 2.1510194444071808e-05
epoch 383...
epoch 383: - loss: 2881.3080426763436
learning rate: 2.1295092499631088e-05
epoch 384...
epoch 384: - loss: 2882.5807285418664
learning rate: 2.108214157463478e-05
epoch 385...
epoch 385: - loss: 2879.1756283301843
learning rate: 2.087132015888843e-05
epoch 386...
epoch 386: - loss: 2885.6877553870263
learning rate: 2.0662606957299545e-05
epoch 387...
epoch 387: - loss: 2880.8494970671886
learning rate: 2.0455980887726552e-05
epoch 388...
epoch 388: - loss: 2885.6570269388794
learning rate: 2.0251421078849285e-05
epoch 389...
epoch 389: - loss: 2885.0446020554673
learning rate: 2.004890686806079e-05
epoch 390...
epoch 390: - loss: 2882.9453548302045
learning rate: 1.9848417799380183e-05
epoch 391...
epoch 391: - loss: 2879.337179602527
learning rate: 1.9649933621386382e-05
epoch 392...
epoch 392: - loss: 2881.506270181042
learning rate: 1.9453434285172516e-05
epoch 393...
epoch 393: - loss: 2880.673555477872
learning rate: 1.925889994232079e-05
epoch 394...
epoch 394: - loss: 2884.3674773291295
learning rate: 1.9066310942897583e-05
epoch 395...
epoch 395: - loss: 2881.57509823419
learning rate: 1.887564783346861e-05
epoch 396...
epoch 396: - loss: 2884.476990722344
learning rate: 1.8686891355133923e-05
epoch 397...
epoch 397: - loss: 2881.3525392187
learning rate: 1.850002244158258e-05
epoch 398...
epoch 398: - loss: 2878.926084668531
learning rate: 1.8315022217166756e-05
epoch 399...
epoch 399: - loss: 2884.407830744162
learning rate: 1.8131871994995087e-05
epoch 400...
epoch 400: - loss: 2882.2931364307174
learning rate: 1.795055327504514e-05
testing...
====> Test set loss: 93.9650
epoch 401...
epoch 401: - loss: 2883.230292243982
learning rate: 1.7771047742294686e-05
epoch 402...
epoch 402: - loss: 2882.7614611761737
learning rate: 1.759333726487174e-05
epoch 403...
epoch 403: - loss: 2879.0066276447787
learning rate: 1.7417403892223024e-05
epoch 404...
epoch 404: - loss: 2882.325448981326
learning rate: 1.724322985330079e-05
epoch 405...
epoch 405: - loss: 2877.785031211887
learning rate: 1.7070797554767784e-05
epoch 406...
epoch 406: - loss: 2878.3733528708312
learning rate: 1.6900089579220107e-05
epoch 407...
epoch 407: - loss: 2882.725818128824
learning rate: 1.6731088683427904e-05
epoch 408...
epoch 408: - loss: 2878.7117912892872
learning rate: 1.6563777796593625e-05
epoch 409...
epoch 409: - loss: 2879.9086129157417
learning rate: 1.639814001862769e-05
epoch 410...
epoch 410: - loss: 2881.4198389327917
learning rate: 1.623415861844141e-05
epoch 411...
epoch 411: - loss: 2883.1163922076184
learning rate: 1.6071817032256997e-05
epoch 412...
epoch 412: - loss: 2882.848259963062
learning rate: 1.5911098861934424e-05
epoch 413...
epoch 413: - loss: 2879.880672794081
learning rate: 1.575198787331508e-05
epoch 414...
epoch 414: - loss: 2882.27714693798
learning rate: 1.559446799458193e-05
epoch 415...
epoch 415: - loss: 2880.4547554938667
learning rate: 1.5438523314636112e-05
epoch 416...
epoch 416: - loss: 2880.050646136986
learning rate: 1.528413808148975e-05
epoch 417...
epoch 417: - loss: 2877.8187858010438
learning rate: 1.5131296700674854e-05
epoch 418...
epoch 418: - loss: 2882.0365870421465
learning rate: 1.4979983733668105e-05
epoch 419...
epoch 419: - loss: 2880.1973117040047
learning rate: 1.4830183896331423e-05
epoch 420...
epoch 420: - loss: 2881.5482850175445
learning rate: 1.468188205736811e-05
testing...
====> Test set loss: 95.1365
epoch 421...
epoch 421: - loss: 2883.299746112494
learning rate: 1.4535063236794428e-05
epoch 422...
epoch 422: - loss: 2880.2365399322216
learning rate: 1.4389712604426484e-05
epoch 423...
epoch 423: - loss: 2880.3365744055654
learning rate: 1.4245815478382217e-05
epoch 424...
epoch 424: - loss: 2879.1058953322436
learning rate: 1.4103357323598397e-05
epoch 425...
epoch 425: - loss: 2883.2514145473447
learning rate: 1.3962323750362412e-05
epoch 426...
epoch 426: - loss: 2883.6170258329835
learning rate: 1.3822700512858787e-05
epoch 427...
epoch 427: - loss: 2879.6287822271875
learning rate: 1.3684473507730199e-05
epoch 428...
epoch 428: - loss: 2877.2342469159867
learning rate: 1.3547628772652898e-05
epoch 429...
epoch 429: - loss: 2879.779112871381
learning rate: 1.3412152484926368e-05
epoch 430...
epoch 430: - loss: 2881.56630956219
learning rate: 1.3278030960077105e-05
epoch 431...
epoch 431: - loss: 2882.21220756233
learning rate: 1.3145250650476334e-05
epoch 432...
epoch 432: - loss: 2881.707970168296
learning rate: 1.3013798143971571e-05
epoch 433...
epoch 433: - loss: 2877.532277483705
learning rate: 1.2883660162531854e-05
epoch 434...
epoch 434: - loss: 2877.254513399462
learning rate: 1.2754823560906535e-05
epoch 435...
epoch 435: - loss: 2878.4178395725867
learning rate: 1.262727532529747e-05
epoch 436...
epoch 436: - loss: 2881.9952373053125
learning rate: 1.2501002572044495e-05
epoch 437...
epoch 437: - loss: 2880.3004569787668
learning rate: 1.2375992546324052e-05
epoch 438...
epoch 438: - loss: 2879.1024558078916
learning rate: 1.2252232620860809e-05
epoch 439...
epoch 439: - loss: 2879.103582088107
learning rate: 1.2129710294652202e-05
epoch 440...
epoch 440: - loss: 2879.9423768768993
learning rate: 1.200841319170568e-05
testing...
====> Test set loss: 92.7407
epoch 441...
epoch 441: - loss: 2878.7113617392433
learning rate: 1.1888329059788622e-05
epoch 442...
epoch 442: - loss: 2877.7921644761177
learning rate: 1.1769445769190736e-05
epoch 443...
epoch 443: - loss: 2877.0798877171806
learning rate: 1.165175131149883e-05
epoch 444...
epoch 444: - loss: 2879.8269605288806
learning rate: 1.1535233798383842e-05
epoch 445...
epoch 445: - loss: 2876.783752636656
learning rate: 1.1419881460400002e-05
epoch 446...
epoch 446: - loss: 2880.218039446127
learning rate: 1.1305682645796001e-05
epoch 447...
epoch 447: - loss: 2877.2178844176115
learning rate: 1.1192625819338041e-05
epoch 448...
epoch 448: - loss: 2884.0630724730586
learning rate: 1.1080699561144661e-05
epoch 449...
epoch 449: - loss: 2876.9435014389146
learning rate: 1.0969892565533214e-05
epoch 450...
epoch 450: - loss: 2879.358849074546
learning rate: 1.0860193639877883e-05
epoch 451...
epoch 451: - loss: 2883.3277374677605
learning rate: 1.0751591703479104e-05
epoch 452...
epoch 452: - loss: 2880.382347023952
learning rate: 1.0644075786444311e-05
epoch 453...
epoch 453: - loss: 2881.4705781649873
learning rate: 1.053763502857987e-05
epoch 454...
epoch 454: - loss: 2876.69247684491
learning rate: 1.043225867829407e-05
epoch 455...
epoch 455: - loss: 2882.2273291296783
learning rate: 1.032793609151113e-05
epoch 456...
epoch 456: - loss: 2879.4267907707035
learning rate: 1.0224656730596019e-05
epoch 457...
epoch 457: - loss: 2880.1537434583433
learning rate: 1.0122410163290057e-05
epoch 458...
epoch 458: - loss: 2878.785989264685
learning rate: 1.0021186061657156e-05
epoch 459...
epoch 459: - loss: 2878.719061384732
learning rate: 9.920974201040586e-06
epoch 460...
epoch 460: - loss: 2878.9382071174723
learning rate: 9.82176445903018e-06
testing...
====> Test set loss: 92.0285
epoch 461...
epoch 461: - loss: 2878.233780424639
learning rate: 9.723546814439879e-06
epoch 462...
epoch 462: - loss: 2881.1431207638557
learning rate: 9.626311346295478e-06
epoch 463...
epoch 463: - loss: 2879.4528046337673
learning rate: 9.530048232832523e-06
epoch 464...
epoch 464: - loss: 2881.0096826827917
learning rate: 9.4347477505042e-06
epoch 465...
epoch 465: - loss: 2878.0855872214643
learning rate: 9.340400272999157e-06
epoch 466...
epoch 466: - loss: 2876.158274586507
learning rate: 9.246996270269166e-06
epoch 467...
epoch 467: - loss: 2877.9152484486212
learning rate: 9.154526307566474e-06
epoch 468...
epoch 468: - loss: 2880.762086835338
learning rate: 9.062981044490808e-06
epoch 469...
epoch 469: - loss: 2881.82040848491
learning rate: 8.972351234045901e-06
epoch 470...
epoch 470: - loss: 2878.0110950433364
learning rate: 8.882627721705442e-06
epoch 471...
epoch 471: - loss: 2878.9636052400733
learning rate: 8.793801444488386e-06
epoch 472...
epoch 472: - loss: 2878.508545546675
learning rate: 8.705863430043502e-06
epoch 473...
epoch 473: - loss: 2877.709816218185
learning rate: 8.618804795743068e-06
epoch 474...
epoch 474: - loss: 2876.942029644264
learning rate: 8.532616747785637e-06
epoch 475...
epoch 475: - loss: 2879.523839090241
learning rate: 8.44729058030778e-06
epoch 476...
epoch 476: - loss: 2878.839962774412
learning rate: 8.362817674504701e-06
epoch 477...
epoch 477: - loss: 2878.3612140989885
learning rate: 8.279189497759655e-06
epoch 478...
epoch 478: - loss: 2876.6280912764164
learning rate: 8.196397602782057e-06
epoch 479...
epoch 479: - loss: 2875.777468866213
learning rate: 8.114433626754238e-06
epoch 480...
epoch 480: - loss: 2876.3090590698475
learning rate: 8.033289290486696e-06
testing...
====> Test set loss: 92.4472
epoch 481...
epoch 481: - loss: 2879.948157605191
learning rate: 7.952956397581829e-06
epoch 482...
epoch 482: - loss: 2877.5592599430684
learning rate: 7.87342683360601e-06
epoch 483...
epoch 483: - loss: 2877.479271398777
learning rate: 7.79469256526995e-06
epoch 484...
epoch 484: - loss: 2877.9587770975786
learning rate: 7.71674563961725e-06
epoch 485...
epoch 485: - loss: 2879.736952612664
learning rate: 7.639578183221077e-06
epoch 486...
epoch 486: - loss: 2877.410809244167
learning rate: 7.563182401388867e-06
epoch 487...
epoch 487: - loss: 2878.197988206274
learning rate: 7.487550577374979e-06
epoch 488...
epoch 488: - loss: 2873.3136787634207
learning rate: 7.412675071601228e-06
epoch 489...
epoch 489: - loss: 2882.362529927923
learning rate: 7.338548320885216e-06
epoch 490...
epoch 490: - loss: 2875.4607969980857
learning rate: 7.2651628376763635e-06
epoch 491...
epoch 491: - loss: 2879.1975019556244
learning rate: 7.1925112092996e-06
epoch 492...
epoch 492: - loss: 2879.2183604371603
learning rate: 7.120586097206604e-06
epoch 493...
epoch 493: - loss: 2876.2988578811032
learning rate: 7.049380236234538e-06
epoch 494...
epoch 494: - loss: 2876.563655489618
learning rate: 6.978886433872193e-06
epoch 495...
epoch 495: - loss: 2876.9019948772643
learning rate: 6.90909756953347e-06
epoch 496...
epoch 496: - loss: 2877.9326785741064
learning rate: 6.840006593838136e-06
epoch 497...
epoch 497: - loss: 2876.8384941037616
learning rate: 6.771606527899755e-06
epoch 498...
epoch 498: - loss: 2876.3171631952773
learning rate: 6.703890462620756e-06
epoch 499...
epoch 499: - loss: 2875.5772442662096
learning rate: 6.636851557994549e-06
epoch 500...
epoch 500: - loss: 2876.1810704949417
learning rate: 6.570483042414603e-06
testing...
====> Test set loss: 94.5349
epoch 501...
epoch 501: - loss: 2877.169257556332
learning rate: 6.5047782119904574e-06
epoch 502...
epoch 502: - loss: 2876.2478376450786
learning rate: 6.439730429870553e-06
epoch 503...
epoch 503: - loss: 2878.3743697329355
learning rate: 6.3753331255718476e-06
epoch 504...
epoch 504: - loss: 2876.999276325326
learning rate: 6.311579794316129e-06
epoch 505...
epoch 505: - loss: 2878.492880403271
learning rate: 6.248463996372967e-06
epoch 506...
epoch 506: - loss: 2877.321317803303
learning rate: 6.185979356409238e-06
epoch 507...
epoch 507: - loss: 2878.5554354637766
learning rate: 6.124119562845146e-06
epoch 508...
epoch 508: - loss: 2872.719279518054
learning rate: 6.062878367216694e-06
epoch 509...
epoch 509: - loss: 2878.1925315930152
learning rate: 6.002249583544527e-06
epoch 510...
epoch 510: - loss: 2880.1215276736443
learning rate: 5.942227087709081e-06
epoch 511...
epoch 511: - loss: 2878.34921629766
learning rate: 5.88280481683199e-06
epoch 512...
epoch 512: - loss: 2879.0024825649543
learning rate: 5.823976768663671e-06
epoch 513...
epoch 513: - loss: 2879.8450344327316
learning rate: 5.765737000977034e-06
epoch 514...
epoch 514: - loss: 2876.4627654306873
learning rate: 5.708079630967263e-06
epoch 515...
epoch 515: - loss: 2879.3746301183623
learning rate: 5.65099883465759e-06
epoch 516...
epoch 516: - loss: 2877.912393971429
learning rate: 5.594488846311015e-06
epoch 517...
epoch 517: - loss: 2879.9915196668317
learning rate: 5.538543957847904e-06
epoch 518...
epoch 518: - loss: 2877.9714307046747
learning rate: 5.483158518269426e-06
epoch 519...
epoch 519: - loss: 2876.3411597351346
learning rate: 5.4283269330867315e-06
epoch 520...
epoch 520: - loss: 2878.4169225222927
learning rate: 5.374043663755864e-06
testing...
====> Test set loss: 91.9399
epoch 521...
epoch 521: - loss: 2879.805674840301
learning rate: 5.320303227118306e-06
epoch 522...
epoch 522: - loss: 2875.4202211542306
learning rate: 5.267100194847122e-06
epoch 523...
epoch 523: - loss: 2879.203681853057
learning rate: 5.214429192898651e-06
epoch 524...
epoch 524: - loss: 2878.7113639260438
learning rate: 5.162284900969664e-06
epoch 525...
epoch 525: - loss: 2875.713949504908
learning rate: 5.1106620519599676e-06
epoch 526...
epoch 526: - loss: 2875.154861850458
learning rate: 5.059555431440369e-06
epoch 527...
epoch 527: - loss: 2876.445791018749
learning rate: 5.008959877125965e-06
epoch 528...
epoch 528: - loss: 2878.8650798150843
learning rate: 4.958870278354704e-06
epoch 529...
epoch 529: - loss: 2880.13760128009
learning rate: 4.909281575571157e-06
epoch 530...
epoch 530: - loss: 2877.9255255505736
learning rate: 4.8601887598154455e-06
epoch 531...
epoch 531: - loss: 2877.222385633472
learning rate: 4.8115868722172915e-06
epoch 532...
epoch 532: - loss: 2875.644446667691
learning rate: 4.763471003495118e-06
epoch 533...
epoch 533: - loss: 2876.1746341951825
learning rate: 4.715836293460167e-06
epoch 534...
epoch 534: - loss: 2876.7185233537766
learning rate: 4.668677930525565e-06
epoch 535...
epoch 535: - loss: 2876.739022262876
learning rate: 4.62199115122031e-06
epoch 536...
epoch 536: - loss: 2876.4355111051964
learning rate: 4.575771239708106e-06
epoch 537...
epoch 537: - loss: 2878.3701704517052
learning rate: 4.530013527311025e-06
epoch 538...
epoch 538: - loss: 2875.92656389018
learning rate: 4.484713392037915e-06
epoch 539...
epoch 539: - loss: 2878.0765107509346
learning rate: 4.439866258117536e-06
epoch 540...
epoch 540: - loss: 2876.8888401024174
learning rate: 4.395467595536361e-06
testing...
====> Test set loss: 94.1308
epoch 541...
epoch 541: - loss: 2874.4608437799902
learning rate: 4.3515129195809966e-06
epoch 542...
epoch 542: - loss: 2877.301894565614
learning rate: 4.307997790385187e-06
epoch 543...
epoch 543: - loss: 2877.632389978957
learning rate: 4.264917812481335e-06
epoch 544...
epoch 544: - loss: 2876.1077114698296
learning rate: 4.222268634356522e-06
epoch 545...
epoch 545: - loss: 2873.975398575581
learning rate: 4.180045948012957e-06
epoch 546...
epoch 546: - loss: 2878.3277470740613
learning rate: 4.138245488532826e-06
epoch 547...
epoch 547: - loss: 2873.5837164138725
learning rate: 4.096863033647498e-06
epoch 548...
epoch 548: - loss: 2879.215312974848
learning rate: 4.0558944033110234e-06
epoch 549...
epoch 549: - loss: 2876.0216078511125
learning rate: 4.015335459277913e-06
epoch 550...
epoch 550: - loss: 2876.45029270321
learning rate: 3.9751821046851336e-06
epoch 551...
epoch 551: - loss: 2872.310538127799
learning rate: 3.935430283638282e-06
epoch 552...
epoch 552: - loss: 2876.586992865408
learning rate: 3.896075980801899e-06
epoch 553...
epoch 553: - loss: 2879.556767303213
learning rate: 3.857115220993881e-06
epoch 554...
epoch 554: - loss: 2876.7273300668785
learning rate: 3.818544068783942e-06
epoch 555...
epoch 555: - loss: 2877.7652980733665
learning rate: 3.7803586280961024e-06
epoch 556...
epoch 556: - loss: 2874.9448998195576
learning rate: 3.7425550418151416e-06
epoch 557...
epoch 557: - loss: 2874.662057282295
learning rate: 3.7051294913969898e-06
epoch 558...
epoch 558: - loss: 2881.5287737611466
learning rate: 3.66807819648302e-06
epoch 559...
epoch 559: - loss: 2877.5501423919345
learning rate: 3.6313974145181896e-06
epoch 560...
epoch 560: - loss: 2877.086220222029
learning rate: 3.595083440373008e-06
testing...
====> Test set loss: 92.2907
epoch 561...
epoch 561: - loss: 2875.7327314634317
learning rate: 3.559132605969278e-06
epoch 562...
epoch 562: - loss: 2874.2400367819796
learning rate: 3.5235412799095848e-06
epoch 563...
epoch 563: - loss: 2874.59384848411
learning rate: 3.488305867110489e-06
epoch 564...
epoch 564: - loss: 2874.3956287113124
learning rate: 3.453422808439384e-06
epoch 565...
epoch 565: - loss: 2875.8547589771274
learning rate: 3.4188885803549903e-06
epoch 566...
epoch 566: - loss: 2877.3669808473787
learning rate: 3.3846996945514404e-06
epoch 567...
epoch 567: - loss: 2875.93632631308
learning rate: 3.3508526976059257e-06
epoch 568...
epoch 568: - loss: 2876.1394492824797
learning rate: 3.3173441706298663e-06
epoch 569...
epoch 569: - loss: 2875.792226565624
learning rate: 3.284170728923568e-06
epoch 570...
epoch 570: - loss: 2872.991493815729
learning rate: 3.251329021634332e-06
epoch 571...
epoch 571: - loss: 2876.9468398237564
learning rate: 3.2188157314179887e-06
epoch 572...
epoch 572: - loss: 2877.7768829599527
learning rate: 3.186627574103809e-06
epoch 573...
epoch 573: - loss: 2879.3829035646095
learning rate: 3.1547612983627705e-06
epoch 574...
epoch 574: - loss: 2878.292911424594
learning rate: 3.123213685379143e-06
epoch 575...
epoch 575: - loss: 2873.1517519081394
learning rate: 3.0919815485253516e-06
epoch 576...
epoch 576: - loss: 2875.9491552546933
learning rate: 3.0610617330400983e-06
epoch 577...
epoch 577: - loss: 2876.779054764975
learning rate: 3.030451115709697e-06
epoch 578...
epoch 578: - loss: 2873.8951390242623
learning rate: 3.0001466045526e-06
epoch 579...
epoch 579: - loss: 2873.453779321867
learning rate: 2.970145138507074e-06
epoch 580...
epoch 580: - loss: 2874.8671278315937
learning rate: 2.9404436871220033e-06
testing...
====> Test set loss: 95.2951
epoch 581...
epoch 581: - loss: 2878.3091354516555
learning rate: 2.911039250250783e-06
epoch 582...
epoch 582: - loss: 2874.5294947804205
learning rate: 2.8819288577482755e-06
epoch 583...
epoch 583: - loss: 2876.0147692582123
learning rate: 2.8531095691707925e-06
epoch 584...
epoch 584: - loss: 2875.959979212902
learning rate: 2.8245784734790846e-06
epoch 585...
epoch 585: - loss: 2874.1929894933623
learning rate: 2.7963326887442936e-06
epoch 586...
epoch 586: - loss: 2873.876680555972
learning rate: 2.7683693618568507e-06
epoch 587...
epoch 587: - loss: 2875.8076387431024
learning rate: 2.740685668238282e-06
epoch 588...
epoch 588: - loss: 2874.2583639641566
learning rate: 2.7132788115558995e-06
epoch 589...
epoch 589: - loss: 2876.8013656723597
learning rate: 2.6861460234403404e-06
epoch 590...
epoch 590: - loss: 2879.395433148892
learning rate: 2.6592845632059367e-06
epoch 591...
epoch 591: - loss: 2878.4875651510265
learning rate: 2.6326917175738777e-06
epoch 592...
epoch 592: - loss: 2875.889755512611
learning rate: 2.606364800398139e-06
epoch 593...
epoch 593: - loss: 2876.8971004278633
learning rate: 2.5803011523941575e-06
epoch 594...
epoch 594: - loss: 2876.2108062919865
learning rate: 2.5544981408702157e-06
epoch 595...
epoch 595: - loss: 2876.168038337107
learning rate: 2.5289531594615134e-06
epoch 596...
epoch 596: - loss: 2879.624393162938
learning rate: 2.5036636278668986e-06
epoch 597...
epoch 597: - loss: 2872.7472099553142
learning rate: 2.4786269915882293e-06
epoch 598...
epoch 598: - loss: 2874.111306803698
learning rate: 2.453840721672347e-06
epoch 599...
epoch 599: - loss: 2876.0546123677923
learning rate: 2.4293023144556236e-06
epoch 600...
epoch 600: - loss: 2875.2886333404563
learning rate: 2.4050092913110675e-06
testing...
====> Test set loss: 94.3115
epoch 601...
epoch 601: - loss: 2878.070038368972
learning rate: 2.3809591983979566e-06
epoch 602...
epoch 602: - loss: 2877.1969388545667
learning rate: 2.357149606413977e-06
epoch 603...
epoch 603: - loss: 2875.5414422072436
learning rate: 2.3335781103498373e-06
epoch 604...
epoch 604: - loss: 2877.7195092882775
learning rate: 2.310242329246339e-06
epoch 605...
epoch 605: - loss: 2873.1981676800924
learning rate: 2.2871399059538755e-06
epoch 606...
epoch 606: - loss: 2875.2830258379818
learning rate: 2.2642685068943367e-06
epoch 607...
epoch 607: - loss: 2878.2295581820067
learning rate: 2.241625821825393e-06
epoch 608...
epoch 608: - loss: 2875.905556471929
learning rate: 2.2192095636071396e-06
epoch 609...
epoch 609: - loss: 2876.9537945513684
learning rate: 2.197017467971068e-06
epoch 610...
epoch 610: - loss: 2873.471074334338
learning rate: 2.175047293291357e-06
epoch 611...
epoch 611: - loss: 2875.8103786475826
learning rate: 2.1532968203584437e-06
epoch 612...
epoch 612: - loss: 2880.7569492606117
learning rate: 2.1317638521548595e-06
epoch 613...
epoch 613: - loss: 2879.434729246016
learning rate: 2.1104462136333104e-06
epoch 614...
epoch 614: - loss: 2877.460263106431
learning rate: 2.0893417514969775e-06
epoch 615...
epoch 615: - loss: 2874.113721109245
learning rate: 2.0684483339820075e-06
epoch 616...
epoch 616: - loss: 2875.0043891423493
learning rate: 2.0477638506421874e-06
epoch 617...
epoch 617: - loss: 2873.7509613329985
learning rate: 2.027286212135766e-06
epoch 618...
epoch 618: - loss: 2872.9693870617652
learning rate: 2.007013350014408e-06
epoch 619...
epoch 619: - loss: 2875.4077226537506
learning rate: 1.986943216514264e-06
epoch 620...
epoch 620: - loss: 2872.041163702615
learning rate: 1.967073784349121e-06
testing...
====> Test set loss: 92.7068
epoch 621...
epoch 621: - loss: 2874.162217153011
learning rate: 1.94740304650563e-06
epoch 622...
epoch 622: - loss: 2874.23369193733
learning rate: 1.9279290160405737e-06
epoch 623...
epoch 623: - loss: 2876.0347308392566
learning rate: 1.908649725880168e-06
epoch 624...
epoch 624: - loss: 2874.687330522983
learning rate: 1.8895632286213661e-06
epoch 625...
epoch 625: - loss: 2877.4799734397493
learning rate: 1.8706675963351526e-06
epoch 626...
epoch 626: - loss: 2874.606376350193
learning rate: 1.851960920371801e-06
epoch 627...
epoch 627: - loss: 2877.3027881078056
learning rate: 1.833441311168083e-06
epoch 628...
epoch 628: - loss: 2876.3895359734884
learning rate: 1.8151068980564023e-06
epoch 629...
epoch 629: - loss: 2873.7265655459005
learning rate: 1.796955829075838e-06
epoch 630...
epoch 630: - loss: 2877.5849062674943
learning rate: 1.7789862707850797e-06
epoch 631...
epoch 631: - loss: 2876.844259368252
learning rate: 1.761196408077229e-06
epoch 632...
epoch 632: - loss: 2876.5169273176334
learning rate: 1.7435844439964567e-06
epoch 633...
epoch 633: - loss: 2878.6253587914366
learning rate: 1.726148599556492e-06
epoch 634...
epoch 634: - loss: 2875.821796400152
learning rate: 1.708887113560927e-06
epoch 635...
epoch 635: - loss: 2873.6425430580966
learning rate: 1.6917982424253177e-06
epoch 636...
epoch 636: - loss: 2871.286285810416
learning rate: 1.6748802600010647e-06
epoch 637...
epoch 637: - loss: 2876.97275223491
learning rate: 1.658131457401054e-06
epoch 638...
epoch 638: - loss: 2877.4435238536166
learning rate: 1.6415501428270433e-06
epoch 639...
epoch 639: - loss: 2874.0757006195518
learning rate: 1.625134641398773e-06
epoch 640...
epoch 640: - loss: 2873.6942322987893
learning rate: 1.608883294984785e-06
testing...
====> Test set loss: 93.6799
epoch 641...
epoch 641: - loss: 2877.588613987274
learning rate: 1.5927944620349372e-06
epoch 642...
epoch 642: - loss: 2877.066083696967
learning rate: 1.576866517414588e-06
epoch 643...
epoch 643: - loss: 2879.2969975389124
learning rate: 1.5610978522404422e-06
epoch 644...
epoch 644: - loss: 2875.4856794263337
learning rate: 1.5454868737180377e-06
epoch 645...
epoch 645: - loss: 2876.3914294300826
learning rate: 1.5300320049808574e-06
epoch 646...
epoch 646: - loss: 2873.772900562445
learning rate: 1.5147316849310487e-06
epoch 647...
epoch 647: - loss: 2874.502509665657
learning rate: 1.499584368081738e-06
epoch 648...
epoch 648: - loss: 2875.4166279290625
learning rate: 1.4845885244009206e-06
epoch 649...
epoch 649: - loss: 2875.9894392388187
learning rate: 1.4697426391569114e-06
epoch 650...
epoch 650: - loss: 2875.596397121671
learning rate: 1.4550452127653423e-06
epoch 651...
epoch 651: - loss: 2873.7538836009976
learning rate: 1.440494760637689e-06
epoch 652...
epoch 652: - loss: 2874.5506895605904
learning rate: 1.426089813031312e-06
epoch 653...
epoch 653: - loss: 2875.185408637986
learning rate: 1.411828914900999e-06
epoch 654...
epoch 654: - loss: 2872.6346147357845
learning rate: 1.3977106257519887e-06
epoch 655...
epoch 655: - loss: 2876.724372888176
learning rate: 1.383733519494469e-06
epoch 656...
epoch 656: - loss: 2874.7576525511836
learning rate: 1.3698961842995243e-06
epoch 657...
epoch 657: - loss: 2877.226963153041
learning rate: 1.356197222456529e-06
epoch 658...
epoch 658: - loss: 2875.3488557099226
learning rate: 1.3426352502319636e-06
epoch 659...
epoch 659: - loss: 2876.963152650527
learning rate: 1.329208897729644e-06
epoch 660...
epoch 660: - loss: 2875.428487571477
learning rate: 1.3159168087523475e-06
testing...
====> Test set loss: 92.7315
epoch 661...
epoch 661: - loss: 2875.390896241328
learning rate: 1.3027576406648242e-06
epoch 662...
epoch 662: - loss: 2874.8534799332965
learning rate: 1.2897300642581758e-06
epoch 663...
epoch 663: - loss: 2874.8827080802894
learning rate: 1.276832763615594e-06
epoch 664...
epoch 664: - loss: 2876.098478096384
learning rate: 1.2640644359794381e-06
epoch 665...
epoch 665: - loss: 2875.0876193055724
learning rate: 1.2514237916196438e-06
epoch 666...
epoch 666: - loss: 2874.007893099208
learning rate: 1.2389095537034472e-06
epoch 667...
epoch 667: - loss: 2875.1237099440677
learning rate: 1.2265204581664129e-06
epoch 668...
epoch 668: - loss: 2874.3341617401184
learning rate: 1.2142552535847487e-06
epoch 669...
epoch 669: - loss: 2873.214786502694
learning rate: 1.2021127010489012e-06
epoch 670...
epoch 670: - loss: 2878.211408677348
learning rate: 1.1900915740384123e-06
epoch 671...
epoch 671: - loss: 2875.9963585090272
learning rate: 1.1781906582980281e-06
epoch 672...
epoch 672: - loss: 2875.006778690194
learning rate: 1.1664087517150477e-06
epoch 673...
epoch 673: - loss: 2874.5639678115504
learning rate: 1.1547446641978973e-06
epoch 674...
epoch 674: - loss: 2875.7319181299486
learning rate: 1.1431972175559182e-06
epoch 675...
epoch 675: - loss: 2874.662924114283
learning rate: 1.1317652453803592e-06
epoch 676...
epoch 676: - loss: 2874.6757795318
learning rate: 1.1204475929265555e-06
epoch 677...
epoch 677: - loss: 2878.818222309486
learning rate: 1.1092431169972898e-06
epoch 678...
epoch 678: - loss: 2874.4248385829032
learning rate: 1.098150685827317e-06
epoch 679...
epoch 679: - loss: 2875.9720551142386
learning rate: 1.0871691789690438e-06
epoch 680...
epoch 680: - loss: 2876.176011723124
learning rate: 1.0762974871793534e-06
testing...
====> Test set loss: 95.7602
epoch 681...
epoch 681: - loss: 2873.7532685634346
learning rate: 1.0655345123075598e-06
epoch 682...
epoch 682: - loss: 2874.671912878504
learning rate: 1.0548791671844842e-06
epoch 683...
epoch 683: - loss: 2878.1089527132567
learning rate: 1.0443303755126394e-06
epoch 684...
epoch 684: - loss: 2875.9569477610917
learning rate: 1.033887071757513e-06
epoch 685...
epoch 685: - loss: 2875.858626880023
learning rate: 1.0235482010399377e-06
epoch 686...
epoch 686: - loss: 2876.525968018359
learning rate: 1.0133127190295386e-06
epoch 687...
epoch 687: - loss: 2873.6448513038326
learning rate: 1.0031795918392432e-06
epoch 688...
epoch 688: - loss: 2876.18125285846
learning rate: 9.931477959208507e-07
epoch 689...
epoch 689: - loss: 2877.3491397596517
learning rate: 9.832163179616422e-07
epoch 690...
epoch 690: - loss: 2872.2235323758896
learning rate: 9.733841547820257e-07
epoch 691...
epoch 691: - loss: 2877.757089996826
learning rate: 9.636503132342055e-07
epoch 692...
epoch 692: - loss: 2875.719148544341
learning rate: 9.540138101018633e-07
epoch 693...
epoch 693: - loss: 2878.1520458765694
learning rate: 9.444736720008447e-07
epoch 694...
epoch 694: - loss: 2875.4884844662206
learning rate: 9.350289352808363e-07
epoch 695...
epoch 695: - loss: 2873.7270620276513
learning rate: 9.256786459280278e-07
epoch 696...
epoch 696: - loss: 2875.5605145415966
learning rate: 9.164218594687476e-07
epoch 697...
epoch 697: - loss: 2877.548097108925
learning rate: 9.0725764087406e-07
epoch 698...
epoch 698: - loss: 2879.189411575796
learning rate: 8.981850644653195e-07
epoch 699...
epoch 699: - loss: 2875.8161360239724
learning rate: 8.892032138206664e-07
epoch 700...
epoch 700: - loss: 2874.6816422651
learning rate: 8.803111816824596e-07
testing...
====> Test set loss: 91.6925
epoch 701...
epoch 701: - loss: 2876.1622613576155
learning rate: 8.71508069865635e-07
epoch 702...
epoch 702: - loss: 2872.235710197737
learning rate: 8.627929891669787e-07
epoch 703...
epoch 703: - loss: 2877.3669803006787
learning rate: 8.541650592753089e-07
epoch 704...
epoch 704: - loss: 2875.289495252144
learning rate: 8.456234086825558e-07
epoch 705...
epoch 705: - loss: 2875.323370115313
learning rate: 8.371671745957303e-07
epoch 706...
epoch 706: - loss: 2877.327100796495
learning rate: 8.287955028497729e-07
epoch 707...
epoch 707: - loss: 2876.242311991413
learning rate: 8.205075478212752e-07
epoch 708...
epoch 708: - loss: 2879.354309042981
learning rate: 8.123024723430624e-07
epoch 709...
epoch 709: - loss: 2878.8176905265314
learning rate: 8.041794476196319e-07
epoch 710...
epoch 710: - loss: 2875.1489578022533
learning rate: 7.961376531434355e-07
epoch 711...
epoch 711: - loss: 2876.4188608863915
learning rate: 7.881762766120012e-07
epoch 712...
epoch 712: - loss: 2873.2342904957914
learning rate: 7.802945138458811e-07
epoch 713...
epoch 713: - loss: 2876.0628362986345
learning rate: 7.724915687074223e-07
epoch 714...
epoch 714: - loss: 2879.567003871261
learning rate: 7.647666530203481e-07
epoch 715...
epoch 715: - loss: 2875.964023621816
learning rate: 7.571189864901446e-07
epoch 716...
epoch 716: - loss: 2873.739855199461
learning rate: 7.49547796625243e-07
epoch 717...
epoch 717: - loss: 2873.540587793156
learning rate: 7.420523186589907e-07
epoch 718...
epoch 718: - loss: 2872.6414405202836
learning rate: 7.346317954724008e-07
epoch 719...
epoch 719: - loss: 2879.5977463774093
learning rate: 7.272854775176767e-07
epoch 720...
epoch 720: - loss: 2874.285439831129
learning rate: 7.200126227425e-07
testing...
====> Test set loss: 92.9645
epoch 721...
epoch 721: - loss: 2874.799854437205
learning rate: 7.128124965150749e-07
epoch 722...
epoch 722: - loss: 2877.4662876629477
learning rate: 7.056843715499242e-07
epoch 723...
epoch 723: - loss: 2878.03867254666
learning rate: 6.986275278344249e-07
epoch 724...
epoch 724: - loss: 2874.1998205886616
learning rate: 6.916412525560806e-07
epoch 725...
epoch 725: - loss: 2871.682569390295
learning rate: 6.847248400305199e-07
epoch 726...
epoch 726: - loss: 2874.2616076917884
learning rate: 6.778775916302147e-07
epoch 727...
epoch 727: - loss: 2875.1211574796066
learning rate: 6.710988157139125e-07
epoch 728...
epoch 728: - loss: 2875.6764800107717
learning rate: 6.643878275567733e-07
epoch 729...
epoch 729: - loss: 2869.5277376083404
learning rate: 6.577439492812057e-07
epoch 730...
epoch 730: - loss: 2874.6187449703593
learning rate: 6.511665097883936e-07
epoch 731...
epoch 731: - loss: 2874.325330113114
learning rate: 6.446548446905097e-07
epoch 732...
epoch 732: - loss: 2874.218086696632
learning rate: 6.382082962436046e-07
epoch 733...
epoch 733: - loss: 2878.524600721519
learning rate: 6.318262132811685e-07
epoch 734...
epoch 734: - loss: 2876.134608331584
learning rate: 6.255079511483568e-07
epoch 735...
epoch 735: - loss: 2877.139706778206
learning rate: 6.192528716368731e-07
epoch 736...
epoch 736: - loss: 2874.131465118662
learning rate: 6.130603429205045e-07
epoch 737...
epoch 737: - loss: 2875.629364540847
learning rate: 6.069297394912995e-07
epoch 738...
epoch 738: - loss: 2876.913810939874
learning rate: 6.008604420963864e-07
epoch 739...
epoch 739: - loss: 2876.690341981191
learning rate: 5.948518376754226e-07
epoch 740...
epoch 740: - loss: 2877.6045760669085
learning rate: 5.889033192986683e-07
testing...
====> Test set loss: 91.9848
epoch 741...
epoch 741: - loss: 2872.0090988071315
learning rate: 5.830142861056817e-07
epoch 742...
epoch 742: - loss: 2875.475625612304
learning rate: 5.771841432446248e-07
epoch 743...
epoch 743: - loss: 2876.203726682462
learning rate: 5.714123018121786e-07
epoch 744...
epoch 744: - loss: 2874.953855781775
learning rate: 5.656981787940569e-07
epoch 745...
epoch 745: - loss: 2875.9432465985883
learning rate: 5.600411970061162e-07
epoch 746...
epoch 746: - loss: 2872.9237754074948
learning rate: 5.544407850360551e-07
epoch 747...
epoch 747: - loss: 2876.412257296415
learning rate: 5.488963771856944e-07
epoch 748...
epoch 748: - loss: 2879.1591325150953
learning rate: 5.434074134138376e-07
epoch 749...
epoch 749: - loss: 2875.046133362324
learning rate: 5.379733392796991e-07
epoch 750...
epoch 750: - loss: 2875.6767414114984
learning rate: 5.325936058869021e-07
epoch 751...
epoch 751: - loss: 2874.2578752924064
learning rate: 5.272676698280331e-07
epoch 752...
epoch 752: - loss: 2876.9429542702587
learning rate: 5.219949931297528e-07
epoch 753...
epoch 753: - loss: 2877.4981373929095
learning rate: 5.167750431984552e-07
epoch 754...
epoch 754: - loss: 2875.5143368965682
learning rate: 5.116072927664707e-07
epoch 755...
epoch 755: - loss: 2873.8747713231764
learning rate: 5.06491219838806e-07
epoch 756...
epoch 756: - loss: 2876.1284116426496
learning rate: 5.014263076404179e-07
epoch 757...
epoch 757: - loss: 2874.9078047368594
learning rate: 4.964120445640137e-07
epoch 758...
epoch 758: - loss: 2876.181982000135
learning rate: 4.914479241183737e-07
epoch 759...
epoch 759: - loss: 2877.6233933266353
learning rate: 4.865334448771899e-07
epoch 760...
epoch 760: - loss: 2873.3354527332503
learning rate: 4.81668110428418e-07
testing...
====> Test set loss: 93.5157
epoch 761...
epoch 761: - loss: 2877.186544212102
learning rate: 4.768514293241338e-07
epoch 762...
epoch 762: - loss: 2875.0676399177264
learning rate: 4.7208291503089247e-07
epoch 763...
epoch 763: - loss: 2875.2594087860634
learning rate: 4.673620858805835e-07
epoch 764...
epoch 764: - loss: 2873.9664783050675
learning rate: 4.6268846502177765e-07
epoch 765...
epoch 765: - loss: 2875.7282172829696
learning rate: 4.580615803715599e-07
epoch 766...
epoch 766: - loss: 2876.5509504146175
learning rate: 4.5348096456784433e-07
epoch 767...
epoch 767: - loss: 2874.8588221300433
learning rate: 4.4894615492216586e-07
epoch 768...
epoch 768: - loss: 2871.1466744704194
learning rate: 4.444566933729442e-07
epoch 769...
epoch 769: - loss: 2875.9423576642976
learning rate: 4.400121264392147e-07
epoch 770...
epoch 770: - loss: 2875.130494179363
learning rate: 4.356120051748226e-07
epoch 771...
epoch 771: - loss: 2876.4758745170298
learning rate: 4.312558851230744e-07
epoch 772...
epoch 772: - loss: 2874.3394174801565
learning rate: 4.269433262718436e-07
epoch 773...
epoch 773: - loss: 2875.2136379639765
learning rate: 4.226738930091252e-07
epoch 774...
epoch 774: - loss: 2874.584485230351
learning rate: 4.184471540790339e-07
epoch 775...
epoch 775: - loss: 2876.258408949761
learning rate: 4.142626825382436e-07
epoch 776...
epoch 776: - loss: 2873.655321547105
learning rate: 4.1012005571286114e-07
epoch 777...
epoch 777: - loss: 2875.113935571867
learning rate: 4.0601885515573247e-07
epoch 778...
epoch 778: - loss: 2877.718195333743
learning rate: 4.0195866660417517e-07
epoch 779...
epoch 779: - loss: 2873.3667215553523
learning rate: 3.9793907993813343e-07
epoch 780...
epoch 780: - loss: 2875.732724122031
learning rate: 3.939596891387521e-07
testing...
====> Test set loss: 92.8520
epoch 781...
epoch 781: - loss: 2878.241075433986
learning rate: 3.900200922473646e-07
epoch 782...
epoch 782: - loss: 2872.2025553385415
learning rate: 3.861198913248909e-07
epoch 783...
epoch 783: - loss: 2872.334659315269
learning rate: 3.82258692411642e-07
epoch 784...
epoch 784: - loss: 2877.305701706704
learning rate: 3.784361054875256e-07
epoch 785...
epoch 785: - loss: 2875.8018095928055
learning rate: 3.7465174443265036e-07
epoch 786...
epoch 786: - loss: 2873.626317859535
learning rate: 3.709052269883238e-07
epoch 787...
epoch 787: - loss: 2874.3436786165926
learning rate: 3.671961747184406e-07
epoch 788...
epoch 788: - loss: 2875.1649161330874
learning rate: 3.6352421297125615e-07
epoch 789...
epoch 789: - loss: 2872.429921956224
learning rate: 3.598889708415436e-07
epoch 790...
epoch 790: - loss: 2875.350554306997
learning rate: 3.5629008113312817e-07
epoch 791...
epoch 791: - loss: 2874.2460923442
learning rate: 3.5272718032179687e-07
epoch 792...
epoch 792: - loss: 2873.8247303050525
learning rate: 3.491999085185789e-07
epoch 793...
epoch 793: - loss: 2875.6411374922523
learning rate: 3.457079094333931e-07
epoch 794...
epoch 794: - loss: 2876.1740768735253
learning rate: 3.4225083033905917e-07
epoch 795...
epoch 795: - loss: 2875.2594372925664
learning rate: 3.388283220356686e-07
epoch 796...
epoch 796: - loss: 2873.994642573751
learning rate: 3.3544003881531185e-07
epoch 797...
epoch 797: - loss: 2879.9052293109953
learning rate: 3.320856384271588e-07
epoch 798...
epoch 798: - loss: 2875.510077009732
learning rate: 3.2876478204288715e-07
epoch 799...
epoch 799: - loss: 2875.710682034874
learning rate: 3.2547713422245833e-07
Training Finished

Testing on training data...
testing...
====> Test on training set loss: 424.7314
Testing Finished

